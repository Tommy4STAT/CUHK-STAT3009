{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('shiing': conda)"
  },
  "interpreter": {
   "hash": "414c3711fdd48b2f544ed65b2d7540fc36858fd70ee4f390e2b75c8d3b465c57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook2: Correlation-based Recommender Systems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load and pro-processed dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtrain = pd.read_csv('./dataset/train.csv')\n",
    "dtest = pd.read_csv('./dataset/test.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_ratings = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "\n",
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "# pre-process for training data\n",
    "train_pair = dtrain[['user_id', 'movie_id']].values\n",
    "train_ratings = dtrain['rating'].values\n",
    "# pre-process for testing set\n",
    "test_pair = dtest[['user_id', 'movie_id']].values\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "## Implement Correlation-based (user-based) recommender systems\n",
    "- Inpout: training set.\n",
    "\n",
    "- Output: return predicted ratings for (user id, item id) user-item pairs in testing set.\n",
    "\n",
    "- Goal: make prediction for testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Algo 1: Correlation-based (user-based) recommender systems (stored sim-matrix)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1  0  0 ...  0  0 -1]\n"
     ]
    }
   ],
   "source": [
    "pred_algo1 = np.zeros(len(test_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2(a): compute pairwise cosine similarity between all users\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cossim_user(index_u,index_v,train_pair,train_ratings):\n",
    "    # index_u = np.where(train_pair[:,0] == u)[0]\n",
    "    # index_v = np.where(train_pair[:,0] == v)[0]\n",
    "    item_u = train_pair[index_u][:,1]\n",
    "    item_v = train_pair[index_v][:,1]\n",
    "    # find co-rating items by `set`\n",
    "    item_co = list(set(item_u).intersection(set(item_v)))\n",
    "    if len(item_co) <= 3:\n",
    "        # a tuning parameter\n",
    "        return 0.0\n",
    "    else:\n",
    "        # find the co-rating vectors by using `np.isin`\n",
    "        vec_u, vec_v = train_ratings[index_u], train_ratings[index_v]\n",
    "        vec_co_u, vec_co_v = vec_u[np.isin(item_u, item_co)], vec_v[np.isin(item_v, item_co)]\n",
    "        return np.dot(vec_co_u, vec_co_v) / norm(vec_co_u) / norm(vec_co_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "# dense sim_matrix\n",
    "# S = np.zeros((n_user,n_user))\n",
    "# sparse matrix \n",
    "S = lil_matrix((n_user, n_user))\n",
    "for u in range(n_user):\n",
    "    print('predict for user_id %d' %u)\n",
    "    for v in range(u):\n",
    "        if (len(index_user[u]) == 0) or (len(index_user[u]) == 0):\n",
    "            continue\n",
    "        S[u,v] = cossim_user(index_user[u],index_user[v],train_pair,train_ratings)\n",
    "S = S + S.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7fade43fa9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpred_algo1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglb_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msim_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrated_users\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# find top 5 rated-users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msim_weight_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "## Step 3: make prediction if S is stored\n",
    "glb_mean = train_ratings.mean()\n",
    "\n",
    "for j in range(len(test_pair)):\n",
    "    user_tmp, item_tmp = test_pair[j,0], test_pair[j,1]\n",
    "    index_tmp = index_item[item_tmp]\n",
    "    rated_users = train_pair[index_tmp][:,0]\n",
    "    rated_ratings = train_ratings[index_tmp]\n",
    "    if len(rated_users) == 0:\n",
    "        # if no rated users\n",
    "        pred_algo1[j] = glb_mean\n",
    "    else:\n",
    "        sim_weight = S[user_tmp, rated_users].toarray()[0]\n",
    "        # find top 5 rated-users\n",
    "        # sim_weight_knn = np.zeros(len(sim_weight))\n",
    "        # top_index = np.argsort(sim_weight)[-5:]\n",
    "        # sim_weight_knn[top_index] = sim_weight[top_index]\n",
    "        # sim_weight = S[user_tmp, rated_users]\n",
    "        # print(sim_weight)\n",
    "        if max(sim_weight) == 0:\n",
    "            pred_algo1[j] = glb_mean\n",
    "        else:\n",
    "            pred_algo1[j] = np.sum(sim_weight*rated_ratings) / np.sum(sim_weight)"
   ]
  },
  {
   "source": [
    "## Algo 2: Correlation-based (user-based) recommender systems (without stored sim-matrix)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-6-d3c004e0fb2e>:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.dot(vec_co_u, vec_co_v) / norm(vec_co_u) / norm(vec_co_v)\n",
      "<ipython-input-6-d3c004e0fb2e>:18: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.dot(vec_co_u, vec_co_v) / norm(vec_co_u) / norm(vec_co_v)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-52c822172cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpred_algo2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglb_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0msim_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcossim_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_tmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMC_ratings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrated_ratings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# print(sim_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-52c822172cda>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpred_algo2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglb_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0msim_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcossim_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_tmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMC_ratings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrated_ratings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# print(sim_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d3c004e0fb2e>\u001b[0m in \u001b[0;36mcossim_user\u001b[0;34m(u, v, train_pair, train_ratings)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcossim_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mindex_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mitem_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_u\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mitem_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_v\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_algo2 = np.zeros(len(test_ratings))\n",
    "\n",
    "## Step 2(b): use `dict` to store rated users for all items\n",
    "index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "## Updated Step 3: make prediction if S is stored\n",
    "glb_mean = train_ratings.mean()\n",
    "\n",
    "for u in range(n_user):\n",
    "    print('predict for user_id %d' %u)\n",
    "    index_list_tmp = np.where(test_pair[:,0] == u)[0]\n",
    "    if len(index_list_tmp) == 0:\n",
    "        # no record to predict for this user.\n",
    "        continue\n",
    "    for record in index_list_tmp:\n",
    "        user_tmp, item_tmp = test_pair[record,0], test_pair[record,1]\n",
    "        index_tmp = index_item[item_tmp]\n",
    "        rated_users = train_pair[index_tmp][:,0]\n",
    "        rated_ratings = train_ratings[index_tmp]\n",
    "        if len(rated_users) == 0:\n",
    "            # if no rated users\n",
    "            pred_algo2[record] = glb_mean\n",
    "        else:\n",
    "            sim_weight = [cossim_user(index_user[user_tmp],index_user[v],train_pair,train_ratings) for v in rated_users]\n",
    "            # print(sim_weight)\n",
    "            if max(sim_weight) == 0:\n",
    "                pred_algo2[record] = glb_mean\n",
    "            else:\n",
    "                pred_algo2[record] = np.sum(sim_weight*rated_ratings) / np.sum(sim_weight)"
   ]
  },
  {
   "source": [
    "## Baseline + correlation\n",
    "\n",
    "- Pre-processed ratings by Baseline methods.\n",
    "\n",
    "- Prediction by correlation-based algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evaluation: compute RMSE for baseline methods "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for correlation-base RS (ALGO1): 3.769\n"
     ]
    }
   ],
   "source": [
    "## RMSE for ALGO1\n",
    "rmse_crs = np.sqrt(np.mean((pred_algo1 - test_ratings)**2))\n",
    "print('RMSE for correlation-base RS (ALGO1): %.3f' %rmse_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for correlation-base RS (ALGO2): 2.588\n"
     ]
    }
   ],
   "source": [
    "## RMSE for ALGO2\n",
    "rmse_crs_new = np.sqrt(np.mean((pred_algo2 - test_ratings)**2))\n",
    "print('RMSE for correlation-base RS (ALGO2): %.3f' %rmse_crs_new)"
   ]
  }
 ]
}