{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CUHK-STAT3009**: Notebook - Neural Collaborative Filtering"
      ],
      "metadata": {
        "id": "ala6VNd9lP8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Latent factor model (matrix factorization) by `tf.keras`\n",
        "\n",
        "- Before introduce NCF model for recommender systems, we first develop `LFM` by `tf.keras`\n",
        "- `LFM` is **NOT** a sequential model, it is difficult to construct `LFM` by `keras.Sequential`\n",
        "- First define `layers` -> `Keras.Model.call` to connect `input` to `output`\n",
        "- Illustrate based on [MovieLens-latest-small](https://grouplens.org/datasets/movielens/) dataset"
      ],
      "metadata": {
        "id": "4xZJ2SzCmnhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip -d ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxOv1CWRglr4",
        "outputId": "d4380efd-a058-4bfe-f3a0-c0f0a60e7206"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-09 08:31:01--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  5.77MB/s    in 0.8s    \n",
            "\n",
            "2022-11-09 08:31:02 (5.77 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ./ml-100k/\n",
            "  inflating: ./ml-100k/allbut.pl     \n",
            "  inflating: ./ml-100k/mku.sh        \n",
            "  inflating: ./ml-100k/README        \n",
            "  inflating: ./ml-100k/u.data        \n",
            "  inflating: ./ml-100k/u.genre       \n",
            "  inflating: ./ml-100k/u.info        \n",
            "  inflating: ./ml-100k/u.item        \n",
            "  inflating: ./ml-100k/u.occupation  \n",
            "  inflating: ./ml-100k/u.user        \n",
            "  inflating: ./ml-100k/u1.base       \n",
            "  inflating: ./ml-100k/u1.test       \n",
            "  inflating: ./ml-100k/u2.base       \n",
            "  inflating: ./ml-100k/u2.test       \n",
            "  inflating: ./ml-100k/u3.base       \n",
            "  inflating: ./ml-100k/u3.test       \n",
            "  inflating: ./ml-100k/u4.base       \n",
            "  inflating: ./ml-100k/u4.test       \n",
            "  inflating: ./ml-100k/u5.base       \n",
            "  inflating: ./ml-100k/u5.test       \n",
            "  inflating: ./ml-100k/ua.base       \n",
            "  inflating: ./ml-100k/ua.test       \n",
            "  inflating: ./ml-100k/ub.base       \n",
            "  inflating: ./ml-100k/ub.test       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "## train read_csv\n",
        "train = pd.read_csv('./ml-100k/u1.base', delimiter='\\t',\n",
        "                    names = ['user_id', 'item_id', 'rating', 'timestamp'],\n",
        "                    header=None)\n",
        "## test - read_csv\n",
        "test = pd.read_csv('./ml-100k/u1.test', delimiter='\\t',\n",
        "                    names = ['user_id', 'item_id', 'rating', 'timestamp'],\n",
        "                    header=None)"
      ],
      "metadata": {
        "id": "Q_HYtO8ygpW6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LFM (MF) of MovieLens dataset based on `tf.keras`\n",
        "\n",
        "- The code is adapted from [Keras Code Example](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n"
      ],
      "metadata": {
        "id": "DfRdcnF4pZTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-process the ML-100K raw data\n",
        "\n",
        "- check the `user_id` and `item_id`: mapping `item_id` to a continuous sequence based on `sklean.preprocessing`\n",
        "- use `sklearn.model_selection.train_test_split` to generate train and test dataset"
      ],
      "metadata": {
        "id": "m_rnG5PNpv-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mapping \n",
        "from sklearn import preprocessing\n",
        "le_item = preprocessing.LabelEncoder()\n",
        "le_item.fit(train['item_id'].append(test['item_id']))\n",
        "\n",
        "train['item_id'] = le_item.transform(train['item_id'])\n",
        "test['item_id'] = le_item.transform(test['item_id'])"
      ],
      "metadata": {
        "id": "radg98BipOlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3635fb-0400-4e8a-ce35-6917ee0c69c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le_user = preprocessing.LabelEncoder()\n",
        "le_user.fit(train['user_id'].append(test['user_id']))\n",
        "\n",
        "train['user_id'] = le_user.transform(train['user_id'])\n",
        "test['user_id'] = le_user.transform(test['user_id'])"
      ],
      "metadata": {
        "id": "pkFBZLxQiUjg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save real ratings for test set for evaluation.\n",
        "test_rating = np.array(test['rating'])\n",
        "## remove the ratings in the test set to simulate prediction\n",
        "test = test.drop(columns='rating')"
      ],
      "metadata": {
        "id": "p5Y4K_pxhUuO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.sample(5).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "MURDRZsfqF99",
        "outputId": "3aab73ea-7b4f-49fa-eee9-abe02ab7479f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               33206      67939      79463      32650      43366\n",
              "user_id          470        829        936        462        561\n",
              "item_id          432        625        864       1033        118\n",
              "rating             1          3          3          2          3\n",
              "timestamp  889827822  891561541  876769530  890530703  879196483"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3774a05-3c19-4382-ba5e-5610086065f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>33206</th>\n",
              "      <th>67939</th>\n",
              "      <th>79463</th>\n",
              "      <th>32650</th>\n",
              "      <th>43366</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <td>470</td>\n",
              "      <td>829</td>\n",
              "      <td>936</td>\n",
              "      <td>462</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>item_id</th>\n",
              "      <td>432</td>\n",
              "      <td>625</td>\n",
              "      <td>864</td>\n",
              "      <td>1033</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>889827822</td>\n",
              "      <td>891561541</td>\n",
              "      <td>876769530</td>\n",
              "      <td>890530703</td>\n",
              "      <td>879196483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3774a05-3c19-4382-ba5e-5610086065f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3774a05-3c19-4382-ba5e-5610086065f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3774a05-3c19-4382-ba5e-5610086065f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tran_pair, train_rating\n",
        "train_pair = train[['user_id', 'item_id']].values\n",
        "train_rating = train['rating'].values\n",
        "\n",
        "# test_pair\n",
        "test_pair = test[['user_id', 'item_id']].values\n",
        "# get descriptive parameters for the dataset\n",
        "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1\n",
        "print('total number of users: %d; total number of items: %d' %(n_user, n_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJXogyYXqdNn",
        "outputId": "ab60e723-25cf-4081-d0dc-484ae40b3620"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of users: 943; total number of items: 1683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define LFM by `tf.keras`\n",
        "- Define the layers: embedding layers: embed both users and movies in to 50-dimensional vectors.\n",
        "- Connect from `input` to `output`: LFM computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias."
      ],
      "metadata": {
        "id": "SeLc7oHgrIHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a close look to [tf.keras.layers.Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)\n",
        "\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim,\n",
        "        output_dim,\n",
        "        embeddings_initializer='uniform',\n",
        "        embeddings_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        embeddings_constraint=None,\n",
        "        mask_zero=False,\n",
        "        input_length=None,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "- `input_dim`: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "\n",
        "- `output_dim`: Integer. Dimension of the dense embedding.\n",
        "\n",
        "- `embeddings_initializer`: Initializer for the embeddings matrix (see keras.initializers).\n",
        "\n",
        "- `embeddings_regularizer`: Regularizer function applied to the embeddings matrix (see keras.regularizers).\n",
        "\n",
        "- `embeddings_constraint`: Constraint function applied to the embeddings matrix (see keras.constraints).\n",
        "\n",
        "- `mask_zero`: Boolean, whether or not the input value 0 is a special \"padding\" value that should be masked out. This is useful when using recurrent layers which may take variable length input. If this is True, then all subsequent layers in the model need to support masking or an exception will be raised. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).\n",
        "\n",
        "- `input_length`: Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed). "
      ],
      "metadata": {
        "id": "-DoEIt8ZrjMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "meuv0NXXrHEd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class LFactorNet(keras.Model):\n",
        "#     ## r_{u,i} = p_u @ q_i\n",
        "#     def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "#         super(LFactorNet, self).__init__(**kwargs)\n",
        "#         self.num_users = num_users\n",
        "#         self.num_movies = num_movies\n",
        "#         self.embedding_size = embedding_size\n",
        "#         self.user_embedding = layers.Embedding(\n",
        "#             num_users,\n",
        "#             embedding_size,\n",
        "#             embeddings_initializer=\"he_normal\",\n",
        "#             embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "#         )\n",
        "#         self.movie_embedding = layers.Embedding(\n",
        "#             num_movies,\n",
        "#             embedding_size,\n",
        "#             embeddings_initializer=\"he_normal\",\n",
        "#             embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "#         )\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         user_vector = self.user_embedding(inputs[:, 0])\n",
        "#         movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "#         dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "#         x = dot_user_movie\n",
        "#         return x"
      ],
      "metadata": {
        "id": "6CTI-FbHs63A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LFactorNet(keras.Model):\n",
        "    ## r_{u,i} = p_u @ q_i + a_u + b_i + mu\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(LFactorNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.glb_bias = tf.Variable(0., trainable=True)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias + self.glb_bias\n",
        "        return x"
      ],
      "metadata": {
        "id": "StdGO26ysXQG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick **memo**\n",
        "\n",
        "- `Model`: `LFactorNet`\n",
        "- `Loss`: MSE \n",
        "- `Algo`: SGD, Adam, ... + `callback`\n",
        "- `Data`: [u,i] -> rating\n",
        "- `metric`: RMSE, MAE"
      ],
      "metadata": {
        "id": "1qgLVf7UujQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LFactorNet(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
        "\n",
        "metrics = [\n",
        "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
        "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(1e-3), \n",
        "    loss=tf.keras.losses.MeanSquaredError(), \n",
        "    metrics=metrics\n",
        ")"
      ],
      "metadata": {
        "id": "zDYqII3attNs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping( \n",
        "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
        "    mode='min', baseline=None, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_pair,\n",
        "    y=train_rating,\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_split=.2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH8tFYkOu5QC",
        "outputId": "856de33d-31ca-41fe-b0ed-b8e1533be13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 5s 4ms/step - loss: 6.2574 - mae: 1.7376 - rmse: 2.0765 - val_loss: 3.3753 - val_mae: 0.9883 - val_rmse: 1.2117\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3.1874 - mae: 0.9624 - rmse: 1.1480 - val_loss: 3.0435 - val_mae: 0.9311 - val_rmse: 1.1005\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3.0604 - mae: 0.9433 - rmse: 1.1244 - val_loss: 2.9577 - val_mae: 0.9248 - val_rmse: 1.0944\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.9844 - mae: 0.9391 - rmse: 1.1221 - val_loss: 2.8851 - val_mae: 0.9234 - val_rmse: 1.0929\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.9129 - mae: 0.9382 - rmse: 1.1206 - val_loss: 2.8157 - val_mae: 0.9222 - val_rmse: 1.0917\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.8422 - mae: 0.9360 - rmse: 1.1183 - val_loss: 2.7497 - val_mae: 0.9215 - val_rmse: 1.0908\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.7765 - mae: 0.9353 - rmse: 1.1169 - val_loss: 2.6863 - val_mae: 0.9208 - val_rmse: 1.0899\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.7122 - mae: 0.9337 - rmse: 1.1151 - val_loss: 2.6249 - val_mae: 0.9197 - val_rmse: 1.0888\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.6496 - mae: 0.9321 - rmse: 1.1130 - val_loss: 2.5664 - val_mae: 0.9191 - val_rmse: 1.0880\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 2.5906 - mae: 0.9308 - rmse: 1.1115 - val_loss: 2.5101 - val_mae: 0.9184 - val_rmse: 1.0872\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.5327 - mae: 0.9288 - rmse: 1.1095 - val_loss: 2.4569 - val_mae: 0.9183 - val_rmse: 1.0868\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.4779 - mae: 0.9280 - rmse: 1.1079 - val_loss: 2.4045 - val_mae: 0.9173 - val_rmse: 1.0858\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.4257 - mae: 0.9266 - rmse: 1.1065 - val_loss: 2.3543 - val_mae: 0.9163 - val_rmse: 1.0849\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3741 - mae: 0.9251 - rmse: 1.1046 - val_loss: 2.3067 - val_mae: 0.9160 - val_rmse: 1.0843\n",
            "Epoch 15/50\n",
            " 524/1000 [==============>...............] - ETA: 1s - loss: 2.3326 - mae: 0.9214 - rmse: 1.1016"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make prediction\n",
        "pred_rating = model.predict(test_pair).flatten()\n",
        "print(pred_rating)\n",
        "print('rmse: LFactorNet: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7SRuyE3vnM5",
        "outputId": "dcf068c2-eb80-4a07-971d-1d9cb9fddbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.638312  3.3905618 2.786836  ... 3.619333  3.4383523 3.6299665]\n",
            "rmse: LFactorNet: 0.989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define NCF by `tf.keras`\n",
        "- Recall the figure\n",
        "- Define the layers: `layers.Embedding` + `layers.concatenate` + `layers.Dense`\n",
        "- Connect from `input` to `output`..."
      ],
      "metadata": {
        "id": "3SSblV39vxEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `layers.concatnate`\n",
        "\n",
        "```python\n",
        ">>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n",
        ">>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n",
        ">>> concatted = tf.keras.layers.Concatenate()([x1, x2])\n",
        ">>> concatted.shape\n",
        "TensorShape([5, 16])\n",
        "```"
      ],
      "metadata": {
        "id": "2xAGnFdqxMRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Flatten, Input, Dropout, Dense, Concatenate\n",
        "from IPython.display import SVG\n",
        "\n",
        "class NCF(keras.Model):\n",
        "    ## r_{u,i} = net([p_u, q_i])\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(NCF, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.concatenate = layers.Concatenate()\n",
        "        self.dense1 = layers.Dense(100, name='fc-1', activation='relu')\n",
        "        self.dense2 = layers.Dense(50, name='fc-2', activation='relu')\n",
        "        self.dense3 = layers.Dense(1, name='fc-3', activation='relu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        concatted_vec = self.concatenate([user_vector, movie_vector])\n",
        "        fc_1 = self.dense1(concatted_vec)\n",
        "        fc_2 = self.dense2(fc_1)\n",
        "        fc_3 = self.dense3(fc_2)\n",
        "        return fc_3"
      ],
      "metadata": {
        "id": "DAYZkEJvv2io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NCF(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
        "\n",
        "metrics = [\n",
        "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
        "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3), \n",
        "    loss=tf.keras.losses.MeanSquaredError(), \n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping( \n",
        "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
        "    mode='min', baseline=None, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_pair,\n",
        "    y=train_rating,\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_split=.2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6ktO-vuyFIJ",
        "outputId": "ce023eb7-10de-46af-fb41-e63ec9355c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "845/845 [==============================] - 4s 4ms/step - loss: 1.6219 - mae: 0.8433 - rmse: 1.1569 - val_loss: 0.9988 - val_mae: 0.7163 - val_rmse: 0.9223\n",
            "Epoch 2/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.9362 - mae: 0.6970 - rmse: 0.8978 - val_loss: 0.9607 - val_mae: 0.7239 - val_rmse: 0.9218\n",
            "Epoch 3/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.9015 - mae: 0.6853 - rmse: 0.8840 - val_loss: 0.9389 - val_mae: 0.6864 - val_rmse: 0.8989\n",
            "Epoch 4/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8735 - mae: 0.6708 - rmse: 0.8665 - val_loss: 0.9182 - val_mae: 0.6842 - val_rmse: 0.8971\n",
            "Epoch 5/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8543 - mae: 0.6614 - rmse: 0.8541 - val_loss: 0.8952 - val_mae: 0.6829 - val_rmse: 0.8887\n",
            "Epoch 6/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8365 - mae: 0.6533 - rmse: 0.8448 - val_loss: 0.9005 - val_mae: 0.6876 - val_rmse: 0.8872\n",
            "Epoch 7/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.8317 - mae: 0.6501 - rmse: 0.8407 - val_loss: 0.8964 - val_mae: 0.6784 - val_rmse: 0.8833\n",
            "Epoch 8/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8198 - mae: 0.6462 - rmse: 0.8358 - val_loss: 0.9198 - val_mae: 0.7023 - val_rmse: 0.8970\n",
            "Epoch 9/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8166 - mae: 0.6446 - rmse: 0.8340 - val_loss: 0.9107 - val_mae: 0.6760 - val_rmse: 0.8860\n",
            "Epoch 10/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8189 - mae: 0.6427 - rmse: 0.8321 - val_loss: 0.9149 - val_mae: 0.6773 - val_rmse: 0.8841\n",
            "Epoch 11/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8164 - mae: 0.6419 - rmse: 0.8298 - val_loss: 0.8993 - val_mae: 0.6801 - val_rmse: 0.8822\n",
            "Epoch 12/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8084 - mae: 0.6372 - rmse: 0.8259 - val_loss: 0.8932 - val_mae: 0.6745 - val_rmse: 0.8821\n",
            "Epoch 13/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8019 - mae: 0.6361 - rmse: 0.8241 - val_loss: 0.9342 - val_mae: 0.6953 - val_rmse: 0.8901\n",
            "Epoch 14/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.8082 - mae: 0.6350 - rmse: 0.8221 - val_loss: 0.9069 - val_mae: 0.6766 - val_rmse: 0.8793\n",
            "Epoch 15/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7979 - mae: 0.6330 - rmse: 0.8191 - val_loss: 0.9156 - val_mae: 0.6737 - val_rmse: 0.8850\n",
            "Epoch 16/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7949 - mae: 0.6315 - rmse: 0.8175 - val_loss: 0.9054 - val_mae: 0.6758 - val_rmse: 0.8806\n",
            "Epoch 17/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7978 - mae: 0.6304 - rmse: 0.8160 - val_loss: 0.9168 - val_mae: 0.6769 - val_rmse: 0.8861\n",
            "Epoch 18/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7956 - mae: 0.6287 - rmse: 0.8137 - val_loss: 0.9066 - val_mae: 0.6743 - val_rmse: 0.8842\n",
            "Epoch 19/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7885 - mae: 0.6269 - rmse: 0.8115 - val_loss: 0.9257 - val_mae: 0.6810 - val_rmse: 0.8856\n",
            "Epoch 20/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7927 - mae: 0.6259 - rmse: 0.8095 - val_loss: 0.9225 - val_mae: 0.6777 - val_rmse: 0.8882\n",
            "Epoch 21/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7894 - mae: 0.6243 - rmse: 0.8073 - val_loss: 0.9330 - val_mae: 0.6790 - val_rmse: 0.8872\n",
            "Epoch 22/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7852 - mae: 0.6224 - rmse: 0.8052 - val_loss: 0.9235 - val_mae: 0.6830 - val_rmse: 0.8859\n",
            "Epoch 23/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7837 - mae: 0.6222 - rmse: 0.8041 - val_loss: 0.9165 - val_mae: 0.6796 - val_rmse: 0.8849\n",
            "Epoch 24/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7797 - mae: 0.6212 - rmse: 0.8032 - val_loss: 0.9424 - val_mae: 0.6799 - val_rmse: 0.8896\n",
            "Epoch 25/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7866 - mae: 0.6200 - rmse: 0.8019 - val_loss: 0.9337 - val_mae: 0.6802 - val_rmse: 0.8897\n",
            "Epoch 26/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7818 - mae: 0.6199 - rmse: 0.8012 - val_loss: 0.9364 - val_mae: 0.6879 - val_rmse: 0.8890\n",
            "Epoch 27/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7821 - mae: 0.6190 - rmse: 0.7993 - val_loss: 0.9339 - val_mae: 0.6790 - val_rmse: 0.8910\n",
            "Epoch 28/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7818 - mae: 0.6174 - rmse: 0.7986 - val_loss: 0.9322 - val_mae: 0.6824 - val_rmse: 0.8877\n",
            "Epoch 29/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7753 - mae: 0.6163 - rmse: 0.7963 - val_loss: 0.9451 - val_mae: 0.6814 - val_rmse: 0.8952\n",
            "Epoch 30/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7804 - mae: 0.6157 - rmse: 0.7971 - val_loss: 0.9354 - val_mae: 0.6906 - val_rmse: 0.8920\n",
            "Epoch 31/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7774 - mae: 0.6165 - rmse: 0.7970 - val_loss: 0.9537 - val_mae: 0.6819 - val_rmse: 0.9013\n",
            "Epoch 32/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7790 - mae: 0.6153 - rmse: 0.7969 - val_loss: 0.9446 - val_mae: 0.6835 - val_rmse: 0.8950\n",
            "Epoch 33/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7753 - mae: 0.6146 - rmse: 0.7945 - val_loss: 0.9321 - val_mae: 0.6818 - val_rmse: 0.8903\n",
            "Epoch 34/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7752 - mae: 0.6138 - rmse: 0.7936 - val_loss: 0.9561 - val_mae: 0.6790 - val_rmse: 0.8926\n",
            "Epoch 35/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7768 - mae: 0.6134 - rmse: 0.7932 - val_loss: 0.9484 - val_mae: 0.6873 - val_rmse: 0.8971\n",
            "Epoch 36/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7740 - mae: 0.6134 - rmse: 0.7930 - val_loss: 0.9434 - val_mae: 0.6826 - val_rmse: 0.8923\n",
            "Epoch 37/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7757 - mae: 0.6143 - rmse: 0.7934 - val_loss: 0.9374 - val_mae: 0.6818 - val_rmse: 0.8899\n",
            "Epoch 38/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7765 - mae: 0.6135 - rmse: 0.7923 - val_loss: 0.9439 - val_mae: 0.6844 - val_rmse: 0.8942\n",
            "Epoch 39/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7703 - mae: 0.6128 - rmse: 0.7925 - val_loss: 0.9432 - val_mae: 0.6839 - val_rmse: 0.8903\n",
            "Epoch 40/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7722 - mae: 0.6122 - rmse: 0.7911 - val_loss: 0.9717 - val_mae: 0.7053 - val_rmse: 0.9058\n",
            "Epoch 41/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7708 - mae: 0.6125 - rmse: 0.7910 - val_loss: 0.9600 - val_mae: 0.6892 - val_rmse: 0.8979\n",
            "Epoch 42/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7761 - mae: 0.6123 - rmse: 0.7908 - val_loss: 0.9643 - val_mae: 0.6838 - val_rmse: 0.9026\n",
            "Epoch 43/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7729 - mae: 0.6129 - rmse: 0.7916 - val_loss: 0.9544 - val_mae: 0.6812 - val_rmse: 0.8968\n",
            "Epoch 44/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7749 - mae: 0.6114 - rmse: 0.7893 - val_loss: 0.9535 - val_mae: 0.6863 - val_rmse: 0.8945\n",
            "Epoch 45/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7748 - mae: 0.6123 - rmse: 0.7899 - val_loss: 0.9652 - val_mae: 0.6852 - val_rmse: 0.9031\n",
            "Epoch 46/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7693 - mae: 0.6098 - rmse: 0.7888 - val_loss: 0.9583 - val_mae: 0.6852 - val_rmse: 0.8987\n",
            "Epoch 47/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7709 - mae: 0.6102 - rmse: 0.7879 - val_loss: 0.9642 - val_mae: 0.6876 - val_rmse: 0.8950\n",
            "Epoch 48/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7721 - mae: 0.6091 - rmse: 0.7870 - val_loss: 0.9641 - val_mae: 0.6850 - val_rmse: 0.9007\n",
            "Epoch 49/50\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.7707 - mae: 0.6074 - rmse: 0.7860 - val_loss: 0.9573 - val_mae: 0.6854 - val_rmse: 0.8998\n",
            "Epoch 50/50\n",
            "845/845 [==============================] - 3s 3ms/step - loss: 0.7699 - mae: 0.6082 - rmse: 0.7859 - val_loss: 0.9581 - val_mae: 0.6869 - val_rmse: 0.8972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make prediction\n",
        "pred_rating = model.predict(test_pair).flatten()\n",
        "print(pred_rating)\n",
        "print('rmse: NCF: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsmhqTlwyxpw",
        "outputId": "fb61106b-14eb-4670-f28f-c78f198179f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.3204513 3.652381  1.8998168 ... 3.9807856 3.5982878 4.2914233]\n",
            "rmse: NCF: 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additive NCF (A-NCF):\n",
        "\n",
        "- Recall the figure\n",
        "- Define the layers: layers.Embedding + layers.concatenate + layers.Dense\n",
        "- Connect from input to output..."
      ],
      "metadata": {
        "id": "Pp9-e9C96-VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANCF(keras.Model):\n",
        "    ## r_{u,i} = net([a_u, b_i]) + p_u @ q_i\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(ANCF, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.fc_user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.fc_movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.concatenate = layers.Concatenate()\n",
        "        self.last_concatenate = layers.Concatenate()\n",
        "        self.dense1 = layers.Dense(100, name='fc-1', activation='relu')\n",
        "        self.dense2 = layers.Dense(50, name='fc-2', activation='relu')\n",
        "        self.dense3 = layers.Dense(1, name='fc-3', activation='relu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        fc_user_vector = self.fc_user_embedding(inputs[:, 0])\n",
        "        fc_movie_vector = self.fc_movie_embedding(inputs[:, 1])\n",
        "        \n",
        "        ## MF\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "\n",
        "        ## fc\n",
        "        fc_concatted_vec = self.concatenate([fc_user_vector, fc_movie_vector])\n",
        "        fc_1 = self.dense1(fc_concatted_vec)\n",
        "        fc_2 = self.dense2(fc_1)\n",
        "        fc_3 = self.dense3(fc_2)\n",
        "\n",
        "        ## outcome\n",
        "        out = fc_3 + dot_user_movie\n",
        "        return out"
      ],
      "metadata": {
        "id": "v_9RfUHd7Lbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANCF(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
        "\n",
        "metrics = [\n",
        "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
        "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3), \n",
        "    loss=tf.keras.losses.MeanSquaredError(), \n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping( \n",
        "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
        "    mode='min', baseline=None, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_pair,\n",
        "    y=train_rating,\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_split=.2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cli4bwc8CCx",
        "outputId": "8c7498e5-b2e4-453b-8eea-d44f324e7758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "845/845 [==============================] - 12s 13ms/step - loss: 1.8200 - mae: 0.8420 - rmse: 1.1580 - val_loss: 1.0178 - val_mae: 0.7073 - val_rmse: 0.9213\n",
            "Epoch 2/50\n",
            "845/845 [==============================] - 13s 15ms/step - loss: 0.9364 - mae: 0.6968 - rmse: 0.8967 - val_loss: 0.9480 - val_mae: 0.7176 - val_rmse: 0.9160\n",
            "Epoch 3/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.8821 - mae: 0.6806 - rmse: 0.8783 - val_loss: 0.9083 - val_mae: 0.6894 - val_rmse: 0.8980\n",
            "Epoch 4/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8570 - mae: 0.6648 - rmse: 0.8600 - val_loss: 0.8972 - val_mae: 0.6815 - val_rmse: 0.8880\n",
            "Epoch 5/50\n",
            "845/845 [==============================] - 10s 11ms/step - loss: 0.8358 - mae: 0.6549 - rmse: 0.8466 - val_loss: 0.9031 - val_mae: 0.6849 - val_rmse: 0.8877\n",
            "Epoch 6/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8255 - mae: 0.6489 - rmse: 0.8402 - val_loss: 0.9027 - val_mae: 0.6758 - val_rmse: 0.8860\n",
            "Epoch 7/50\n",
            "845/845 [==============================] - 12s 14ms/step - loss: 0.8176 - mae: 0.6462 - rmse: 0.8351 - val_loss: 0.8910 - val_mae: 0.6790 - val_rmse: 0.8846\n",
            "Epoch 8/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8122 - mae: 0.6428 - rmse: 0.8322 - val_loss: 0.8938 - val_mae: 0.6812 - val_rmse: 0.8826\n",
            "Epoch 9/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8149 - mae: 0.6421 - rmse: 0.8313 - val_loss: 0.9021 - val_mae: 0.6780 - val_rmse: 0.8840\n",
            "Epoch 10/50\n",
            "845/845 [==============================] - 10s 11ms/step - loss: 0.8099 - mae: 0.6392 - rmse: 0.8276 - val_loss: 0.9077 - val_mae: 0.6797 - val_rmse: 0.8843\n",
            "Epoch 11/50\n",
            "845/845 [==============================] - 12s 14ms/step - loss: 0.8112 - mae: 0.6378 - rmse: 0.8268 - val_loss: 0.9083 - val_mae: 0.6739 - val_rmse: 0.8824\n",
            "Epoch 12/50\n",
            "845/845 [==============================] - 12s 15ms/step - loss: 0.8101 - mae: 0.6377 - rmse: 0.8254 - val_loss: 0.9147 - val_mae: 0.6727 - val_rmse: 0.8843\n",
            "Epoch 13/50\n",
            "845/845 [==============================] - 12s 14ms/step - loss: 0.8116 - mae: 0.6361 - rmse: 0.8244 - val_loss: 0.9098 - val_mae: 0.6833 - val_rmse: 0.8843\n",
            "Epoch 14/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8063 - mae: 0.6347 - rmse: 0.8220 - val_loss: 0.9265 - val_mae: 0.6759 - val_rmse: 0.8928\n",
            "Epoch 15/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8098 - mae: 0.6330 - rmse: 0.8208 - val_loss: 0.9143 - val_mae: 0.6797 - val_rmse: 0.8830\n",
            "Epoch 16/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8115 - mae: 0.6332 - rmse: 0.8205 - val_loss: 0.9123 - val_mae: 0.6721 - val_rmse: 0.8799\n",
            "Epoch 17/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8068 - mae: 0.6316 - rmse: 0.8187 - val_loss: 0.9293 - val_mae: 0.6771 - val_rmse: 0.8892\n",
            "Epoch 18/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8029 - mae: 0.6308 - rmse: 0.8170 - val_loss: 0.9133 - val_mae: 0.6769 - val_rmse: 0.8809\n",
            "Epoch 19/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8062 - mae: 0.6299 - rmse: 0.8149 - val_loss: 0.9093 - val_mae: 0.6765 - val_rmse: 0.8798\n",
            "Epoch 20/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.8020 - mae: 0.6279 - rmse: 0.8131 - val_loss: 0.9271 - val_mae: 0.6786 - val_rmse: 0.8839\n",
            "Epoch 21/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8129 - mae: 0.6286 - rmse: 0.8131 - val_loss: 0.9428 - val_mae: 0.6803 - val_rmse: 0.8895\n",
            "Epoch 22/50\n",
            "845/845 [==============================] - 12s 14ms/step - loss: 0.8044 - mae: 0.6274 - rmse: 0.8120 - val_loss: 0.9436 - val_mae: 0.6803 - val_rmse: 0.8882\n",
            "Epoch 23/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.8030 - mae: 0.6238 - rmse: 0.8083 - val_loss: 0.9241 - val_mae: 0.6791 - val_rmse: 0.8828\n",
            "Epoch 24/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8006 - mae: 0.6238 - rmse: 0.8081 - val_loss: 0.9404 - val_mae: 0.6746 - val_rmse: 0.8863\n",
            "Epoch 25/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8005 - mae: 0.6226 - rmse: 0.8061 - val_loss: 0.9710 - val_mae: 0.6814 - val_rmse: 0.9006\n",
            "Epoch 26/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.7982 - mae: 0.6226 - rmse: 0.8050 - val_loss: 0.9509 - val_mae: 0.6739 - val_rmse: 0.8848\n",
            "Epoch 27/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8013 - mae: 0.6212 - rmse: 0.8036 - val_loss: 0.9414 - val_mae: 0.6849 - val_rmse: 0.8861\n",
            "Epoch 28/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8030 - mae: 0.6209 - rmse: 0.8030 - val_loss: 0.9545 - val_mae: 0.6787 - val_rmse: 0.8882\n",
            "Epoch 29/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8000 - mae: 0.6176 - rmse: 0.8002 - val_loss: 0.9518 - val_mae: 0.6750 - val_rmse: 0.8856\n",
            "Epoch 30/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8010 - mae: 0.6183 - rmse: 0.7996 - val_loss: 0.9754 - val_mae: 0.6804 - val_rmse: 0.8954\n",
            "Epoch 31/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8033 - mae: 0.6161 - rmse: 0.7975 - val_loss: 0.9752 - val_mae: 0.6886 - val_rmse: 0.8967\n",
            "Epoch 32/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8008 - mae: 0.6171 - rmse: 0.7978 - val_loss: 0.9690 - val_mae: 0.6774 - val_rmse: 0.8959\n",
            "Epoch 33/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7929 - mae: 0.6136 - rmse: 0.7938 - val_loss: 0.9633 - val_mae: 0.6778 - val_rmse: 0.8892\n",
            "Epoch 34/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7941 - mae: 0.6148 - rmse: 0.7949 - val_loss: 0.9675 - val_mae: 0.6872 - val_rmse: 0.8932\n",
            "Epoch 35/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7937 - mae: 0.6123 - rmse: 0.7933 - val_loss: 0.9858 - val_mae: 0.6815 - val_rmse: 0.8969\n",
            "Epoch 36/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7996 - mae: 0.6121 - rmse: 0.7934 - val_loss: 0.9678 - val_mae: 0.6830 - val_rmse: 0.8967\n",
            "Epoch 37/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7949 - mae: 0.6103 - rmse: 0.7911 - val_loss: 0.9851 - val_mae: 0.6791 - val_rmse: 0.8949\n",
            "Epoch 38/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.7938 - mae: 0.6105 - rmse: 0.7890 - val_loss: 0.9829 - val_mae: 0.6837 - val_rmse: 0.8968\n",
            "Epoch 39/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7922 - mae: 0.6080 - rmse: 0.7881 - val_loss: 0.9945 - val_mae: 0.6855 - val_rmse: 0.9057\n",
            "Epoch 40/50\n",
            "845/845 [==============================] - 10s 11ms/step - loss: 0.7958 - mae: 0.6086 - rmse: 0.7886 - val_loss: 0.9820 - val_mae: 0.6879 - val_rmse: 0.8947\n",
            "Epoch 41/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7957 - mae: 0.6066 - rmse: 0.7853 - val_loss: 0.9988 - val_mae: 0.6930 - val_rmse: 0.9009\n",
            "Epoch 42/50\n",
            "845/845 [==============================] - 10s 11ms/step - loss: 0.7940 - mae: 0.6083 - rmse: 0.7882 - val_loss: 0.9920 - val_mae: 0.6867 - val_rmse: 0.8972\n",
            "Epoch 43/50\n",
            "845/845 [==============================] - 10s 11ms/step - loss: 0.7943 - mae: 0.6080 - rmse: 0.7858 - val_loss: 0.9905 - val_mae: 0.6858 - val_rmse: 0.8951\n",
            "Epoch 44/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.7944 - mae: 0.6055 - rmse: 0.7836 - val_loss: 1.0228 - val_mae: 0.7009 - val_rmse: 0.9097\n",
            "Epoch 45/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7974 - mae: 0.6061 - rmse: 0.7847 - val_loss: 1.0024 - val_mae: 0.6902 - val_rmse: 0.9030\n",
            "Epoch 46/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8014 - mae: 0.6055 - rmse: 0.7840 - val_loss: 1.0039 - val_mae: 0.6884 - val_rmse: 0.8979\n",
            "Epoch 47/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7960 - mae: 0.6040 - rmse: 0.7831 - val_loss: 0.9952 - val_mae: 0.6833 - val_rmse: 0.8944\n",
            "Epoch 48/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7947 - mae: 0.6024 - rmse: 0.7798 - val_loss: 1.0286 - val_mae: 0.7080 - val_rmse: 0.9137\n",
            "Epoch 49/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7976 - mae: 0.6028 - rmse: 0.7806 - val_loss: 1.0087 - val_mae: 0.6856 - val_rmse: 0.9041\n",
            "Epoch 50/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7999 - mae: 0.6036 - rmse: 0.7812 - val_loss: 0.9982 - val_mae: 0.6810 - val_rmse: 0.8956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make prediction\n",
        "pred_rating = model.predict(test_pair).flatten()\n",
        "print(pred_rating)\n",
        "print('rmse: ANCF: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3ShS_PI8ue7",
        "outputId": "e7d208c4-499f-4f0a-cc89-f544d08dda16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.0393822 3.5689142 1.9841704 ... 4.1937647 3.6621404 4.036018 ]\n",
            "rmse: ANCF: 0.885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural NCF (NeuMF):\n",
        "- Recall the figure\n",
        "- Define the layers: `layers.Embedding` + `layers.concatenate` + `layers.Dense`\n",
        "- Connect from `input` to `output`..."
      ],
      "metadata": {
        "id": "egNyJvj62Oy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF(keras.Model):\n",
        "    ## r_{u,i} = net([a_u, b_i, p_u * q_i])\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(NeuMF, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.fc_user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.fc_movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
        "        )\n",
        "        self.concatenate = layers.Concatenate()\n",
        "        self.last_concatenate = layers.Concatenate()\n",
        "        self.dense1 = layers.Dense(100, name='fc-1', activation='relu')\n",
        "        self.dense2 = layers.Dense(50, name='fc-2', activation='relu')\n",
        "        self.dense3 = layers.Dense(1, name='fc-3', activation='relu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        fc_user_vector = self.fc_user_embedding(inputs[:, 0])\n",
        "        fc_movie_vector = self.fc_movie_embedding(inputs[:, 1])\n",
        "        \n",
        "        ## MF\n",
        "        dot_user_movie = user_vector * movie_vector\n",
        "\n",
        "        ## fc\n",
        "        fc_concatted_vec = self.concatenate([fc_user_vector, fc_movie_vector])\n",
        "        fc_1 = self.dense1(fc_concatted_vec)\n",
        "        fc_2 = self.dense2(fc_1)\n",
        "\n",
        "        ## concat\n",
        "        neu_vec = self.concatenate([dot_user_movie, fc_concatted_vec])\n",
        "\n",
        "        ## outcome\n",
        "        fc_3 = self.dense3(neu_vec)\n",
        "        return fc_3"
      ],
      "metadata": {
        "id": "FdmilngM2KmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuMF(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
        "\n",
        "metrics = [\n",
        "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
        "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3), \n",
        "    loss=tf.keras.losses.MeanSquaredError(), \n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping( \n",
        "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
        "    mode='min', baseline=None, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_pair,\n",
        "    y=train_rating,\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_split=.2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhzNMcjA39zg",
        "outputId": "87da49e4-2c6f-437c-85a2-2509845aa907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['neu_mf/fc-1/kernel:0', 'neu_mf/fc-1/bias:0', 'neu_mf/fc-2/kernel:0', 'neu_mf/fc-2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['neu_mf/fc-1/kernel:0', 'neu_mf/fc-1/bias:0', 'neu_mf/fc-2/kernel:0', 'neu_mf/fc-2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "845/845 [==============================] - 10s 11ms/step - loss: 4.8671 - mae: 1.4676 - rmse: 1.8789 - val_loss: 2.4506 - val_mae: 0.8997 - val_rmse: 1.1334\n",
            "Epoch 2/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 2.0276 - mae: 0.8325 - rmse: 1.0499 - val_loss: 1.8119 - val_mae: 0.8156 - val_rmse: 1.0311\n",
            "Epoch 3/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 1.6174 - mae: 0.7848 - rmse: 0.9939 - val_loss: 1.5368 - val_mae: 0.7877 - val_rmse: 0.9977\n",
            "Epoch 4/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 1.4095 - mae: 0.7614 - rmse: 0.9693 - val_loss: 1.3771 - val_mae: 0.7632 - val_rmse: 0.9800\n",
            "Epoch 5/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 1.2834 - mae: 0.7522 - rmse: 0.9600 - val_loss: 1.2729 - val_mae: 0.7570 - val_rmse: 0.9705\n",
            "Epoch 6/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 1.1986 - mae: 0.7452 - rmse: 0.9525 - val_loss: 1.1929 - val_mae: 0.7452 - val_rmse: 0.9620\n",
            "Epoch 7/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 1.1265 - mae: 0.7366 - rmse: 0.9436 - val_loss: 1.1585 - val_mae: 0.7529 - val_rmse: 0.9692\n",
            "Epoch 8/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 1.0820 - mae: 0.7325 - rmse: 0.9399 - val_loss: 1.1029 - val_mae: 0.7488 - val_rmse: 0.9601\n",
            "Epoch 9/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 1.0354 - mae: 0.7256 - rmse: 0.9303 - val_loss: 1.0549 - val_mae: 0.7350 - val_rmse: 0.9450\n",
            "Epoch 10/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.9966 - mae: 0.7189 - rmse: 0.9219 - val_loss: 1.0115 - val_mae: 0.7263 - val_rmse: 0.9338\n",
            "Epoch 11/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.9583 - mae: 0.7083 - rmse: 0.9104 - val_loss: 0.9910 - val_mae: 0.7231 - val_rmse: 0.9300\n",
            "Epoch 12/50\n",
            "845/845 [==============================] - 11s 13ms/step - loss: 0.9346 - mae: 0.7038 - rmse: 0.9034 - val_loss: 0.9631 - val_mae: 0.7140 - val_rmse: 0.9206\n",
            "Epoch 13/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.9180 - mae: 0.6971 - rmse: 0.8978 - val_loss: 0.9487 - val_mae: 0.7095 - val_rmse: 0.9152\n",
            "Epoch 14/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.9098 - mae: 0.6964 - rmse: 0.8951 - val_loss: 0.9480 - val_mae: 0.7123 - val_rmse: 0.9171\n",
            "Epoch 15/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.9011 - mae: 0.6929 - rmse: 0.8921 - val_loss: 0.9365 - val_mae: 0.7057 - val_rmse: 0.9122\n",
            "Epoch 16/50\n",
            "845/845 [==============================] - 10s 11ms/step - loss: 0.8966 - mae: 0.6920 - rmse: 0.8910 - val_loss: 0.9386 - val_mae: 0.7079 - val_rmse: 0.9163\n",
            "Epoch 17/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8905 - mae: 0.6895 - rmse: 0.8891 - val_loss: 0.9299 - val_mae: 0.7018 - val_rmse: 0.9108\n",
            "Epoch 18/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8847 - mae: 0.6877 - rmse: 0.8864 - val_loss: 0.9244 - val_mae: 0.7020 - val_rmse: 0.9090\n",
            "Epoch 19/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8795 - mae: 0.6865 - rmse: 0.8850 - val_loss: 0.9202 - val_mae: 0.7026 - val_rmse: 0.9078\n",
            "Epoch 20/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8770 - mae: 0.6855 - rmse: 0.8837 - val_loss: 0.9185 - val_mae: 0.7028 - val_rmse: 0.9090\n",
            "Epoch 21/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8714 - mae: 0.6840 - rmse: 0.8818 - val_loss: 0.9161 - val_mae: 0.7036 - val_rmse: 0.9087\n",
            "Epoch 22/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8677 - mae: 0.6835 - rmse: 0.8808 - val_loss: 0.9136 - val_mae: 0.6990 - val_rmse: 0.9070\n",
            "Epoch 23/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8636 - mae: 0.6812 - rmse: 0.8785 - val_loss: 0.9053 - val_mae: 0.6998 - val_rmse: 0.9032\n",
            "Epoch 24/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8633 - mae: 0.6824 - rmse: 0.8790 - val_loss: 0.9090 - val_mae: 0.7001 - val_rmse: 0.9039\n",
            "Epoch 25/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8583 - mae: 0.6802 - rmse: 0.8770 - val_loss: 0.9077 - val_mae: 0.7005 - val_rmse: 0.9053\n",
            "Epoch 26/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8567 - mae: 0.6797 - rmse: 0.8760 - val_loss: 0.9062 - val_mae: 0.6986 - val_rmse: 0.9052\n",
            "Epoch 27/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8517 - mae: 0.6785 - rmse: 0.8743 - val_loss: 0.9048 - val_mae: 0.6986 - val_rmse: 0.9039\n",
            "Epoch 28/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8484 - mae: 0.6761 - rmse: 0.8729 - val_loss: 0.8980 - val_mae: 0.6967 - val_rmse: 0.9023\n",
            "Epoch 29/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8446 - mae: 0.6756 - rmse: 0.8717 - val_loss: 0.8972 - val_mae: 0.6948 - val_rmse: 0.9018\n",
            "Epoch 30/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.8427 - mae: 0.6740 - rmse: 0.8698 - val_loss: 0.8952 - val_mae: 0.6933 - val_rmse: 0.9007\n",
            "Epoch 31/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8367 - mae: 0.6735 - rmse: 0.8687 - val_loss: 0.8996 - val_mae: 0.6967 - val_rmse: 0.9041\n",
            "Epoch 32/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8326 - mae: 0.6719 - rmse: 0.8669 - val_loss: 0.8855 - val_mae: 0.6931 - val_rmse: 0.8983\n",
            "Epoch 33/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8288 - mae: 0.6711 - rmse: 0.8655 - val_loss: 0.8883 - val_mae: 0.6944 - val_rmse: 0.9007\n",
            "Epoch 34/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8254 - mae: 0.6697 - rmse: 0.8638 - val_loss: 0.8808 - val_mae: 0.6932 - val_rmse: 0.8961\n",
            "Epoch 35/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8210 - mae: 0.6681 - rmse: 0.8625 - val_loss: 0.8765 - val_mae: 0.6923 - val_rmse: 0.8955\n",
            "Epoch 36/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8185 - mae: 0.6678 - rmse: 0.8608 - val_loss: 0.8855 - val_mae: 0.6906 - val_rmse: 0.8975\n",
            "Epoch 37/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8159 - mae: 0.6665 - rmse: 0.8600 - val_loss: 0.8810 - val_mae: 0.6915 - val_rmse: 0.8981\n",
            "Epoch 38/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8136 - mae: 0.6659 - rmse: 0.8596 - val_loss: 0.8748 - val_mae: 0.6914 - val_rmse: 0.8956\n",
            "Epoch 39/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8118 - mae: 0.6655 - rmse: 0.8588 - val_loss: 0.8747 - val_mae: 0.6919 - val_rmse: 0.8956\n",
            "Epoch 40/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8120 - mae: 0.6655 - rmse: 0.8587 - val_loss: 0.8805 - val_mae: 0.6926 - val_rmse: 0.8983\n",
            "Epoch 41/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8095 - mae: 0.6651 - rmse: 0.8578 - val_loss: 0.8751 - val_mae: 0.6903 - val_rmse: 0.8939\n",
            "Epoch 42/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8082 - mae: 0.6636 - rmse: 0.8566 - val_loss: 0.8741 - val_mae: 0.6904 - val_rmse: 0.8961\n",
            "Epoch 43/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8074 - mae: 0.6637 - rmse: 0.8564 - val_loss: 0.8847 - val_mae: 0.6918 - val_rmse: 0.8983\n",
            "Epoch 44/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8084 - mae: 0.6631 - rmse: 0.8557 - val_loss: 0.8736 - val_mae: 0.6910 - val_rmse: 0.8963\n",
            "Epoch 45/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.8031 - mae: 0.6621 - rmse: 0.8549 - val_loss: 0.8727 - val_mae: 0.6906 - val_rmse: 0.8931\n",
            "Epoch 46/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8036 - mae: 0.6623 - rmse: 0.8550 - val_loss: 0.8760 - val_mae: 0.6909 - val_rmse: 0.8950\n",
            "Epoch 47/50\n",
            "845/845 [==============================] - 9s 11ms/step - loss: 0.8015 - mae: 0.6620 - rmse: 0.8542 - val_loss: 0.8693 - val_mae: 0.6888 - val_rmse: 0.8947\n",
            "Epoch 48/50\n",
            "845/845 [==============================] - 10s 12ms/step - loss: 0.7986 - mae: 0.6607 - rmse: 0.8532 - val_loss: 0.8724 - val_mae: 0.6914 - val_rmse: 0.8959\n",
            "Epoch 49/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.7998 - mae: 0.6612 - rmse: 0.8527 - val_loss: 0.8681 - val_mae: 0.6880 - val_rmse: 0.8926\n",
            "Epoch 50/50\n",
            "845/845 [==============================] - 9s 10ms/step - loss: 0.7960 - mae: 0.6598 - rmse: 0.8515 - val_loss: 0.8690 - val_mae: 0.6889 - val_rmse: 0.8938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make prediction\n",
        "pred_rating = model.predict(test_pair).flatten()\n",
        "print(pred_rating)\n",
        "print('rmse: NeuMF: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXgjCS624q4R",
        "outputId": "3bff3b32-d7cb-4b64-aed9-8e5e3f6a5638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.9664671 3.333763  2.204947  ... 3.8826873 3.4663348 3.7612767]\n",
            "rmse: NeuMF: 0.887\n"
          ]
        }
      ]
    }
  ]
}