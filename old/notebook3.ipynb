{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook3: ALS for Latent Factor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-Oriented Programming (OOP) in Python\n",
    "\n",
    "- define an RS as a `class` with `parameters` in Python\n",
    "- define `fit`, `predict` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm-up with baseline methods\n",
    "\n",
    "class glb_mean(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.glb_mean = 0\n",
    "\t\n",
    "\tdef fit(self, train_rating):\n",
    "\t\tself.glb_mean = np.mean(train_rating)\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))\n",
    "\t\tpred = pred*self.glb_mean\n",
    "\t\treturn pred\n",
    "\n",
    "class user_mean(object):\n",
    "\tdef __init__(self, n_user):\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.user_mean = np.zeros(n_user)\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_rating):\n",
    "\t\tself.glb_mean = train_rating.mean()\n",
    "\t\tfor u in range(self.n_user):\n",
    "\t\t\tind_train = np.where(train_pair[:,0] == u)[0]\n",
    "\t\t\tif len(ind_train) == 0:\n",
    "\t\t\t\tself.user_mean[u] = self.glb_mean\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.user_mean[u] = train_rating[ind_train].mean()\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))*self.glb_mean\n",
    "\t\tj = 0\n",
    "\t\tfor row in test_pair:\n",
    "\t\t\tuser_tmp, item_tmp = row[0], row[1]\n",
    "\t\t\tpred[j] = self.user_mean[user_tmp]\n",
    "\t\t\tj = j + 1\n",
    "\t\treturn pred\n",
    "\n",
    "class item_mean(object):\n",
    "\tdef __init__(self, n_item):\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.item_mean = np.zeros(n_item)\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_rating):\n",
    "\t\tself.glb_mean = train_rating.mean()\n",
    "\t\tfor i in range(self.n_item):\n",
    "\t\t\tind_train = np.where(train_pair[:,1] == i)[0]\n",
    "\t\t\tif len(ind_train) == 0:\n",
    "\t\t\t\tself.item_mean[i] = self.glb_mean\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.item_mean[i] = train_rating[ind_train].mean()\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))*self.glb_mean\n",
    "\t\tj = 0\n",
    "\t\tfor row in test_pair:\n",
    "\t\t\tuser_tmp, item_tmp = row[0], row[1]\n",
    "\t\t\tpred[j] = self.item_mean[item_tmp]\n",
    "\t\t\tj = j + 1\n",
    "\t\treturn pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class for correlation based RS\n",
    "from numpy.linalg import norm\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "class cor_rs_user(object):\n",
    "\tdef __init__(self, n_user, n_item):\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.user_mean = np.zeros(n_user)\n",
    "\t\tself.S = lil_matrix((n_user, n_user))\n",
    "\t\tself.index_item = []\n",
    "\t\tself.index_user = []\n",
    "\t\tself.min_co = 3\n",
    "\t\n",
    "\tdef cossim(self, index_u, index_v, train_pair, train_rating):\n",
    "\t\titem_u = train_pair[index_u][:,1]\n",
    "\t\titem_v = train_pair[index_v][:,1]\n",
    "\t\t# find co-rating items by `set`\n",
    "\t\titem_co = list(set(item_u).intersection(set(item_v)))\n",
    "\t\tif len(item_co) < self.min_co:\n",
    "\t\t\t# a tuning parameter\n",
    "\t\t\treturn 0.0\n",
    "\t\telse:\n",
    "\t\t\tvec_u, vec_v = train_rating[index_u], train_rating[index_v]\n",
    "\t\t\t# find the co-rating vectors by using `np.isin`\n",
    "\t\t\tind_co_u = [np.where(item_u == item_co_tmp)[0][0] for item_co_tmp in item_co]\n",
    "\t\t\tind_co_v = [np.where(item_v == item_co_tmp)[0][0] for item_co_tmp in item_co]\n",
    "\t\t\tvec_co_u, vec_co_v = vec_u[ind_co_u], vec_v[ind_co_v]\t\t\t\n",
    "\t\t\treturn np.dot(vec_co_u, vec_co_v) / (norm(vec_co_u)+1e-5) / (norm(vec_co_v)+1e-5)\n",
    "\t\n",
    "\tdef sim_mat(self, train_pair, train_rating):\n",
    "\t\tself.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "\t\tself.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "\t\tfor u in range(self.n_user):\n",
    "\t\t\tfor v in range(u):\n",
    "\t\t\t\tif (len(self.index_user[u]) == 0) or (len(self.index_user[v]) == 0):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tweight_tmp = self.cossim(self.index_user[u],self.index_user[v],train_pair,train_rating)\n",
    "\t\t\t\tif weight_tmp > 0:\n",
    "\t\t\t\t\tself.S[u,v] = weight_tmp\n",
    "\t\tself.S = self.S + self.S.T\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_rating):\n",
    "\t\tself.glb_mean = train_rating.mean()\n",
    "\t\t# use another class to predict the user mean\n",
    "\t\tuser_ave_method = user_mean(self.n_user)\n",
    "\t\tuser_ave_method.fit(train_pair, train_rating)\n",
    "\t\tself.user_mean = user_ave_method.user_mean\n",
    "\t\tself.sim_mat(train_pair, train_rating)\n",
    "\t\n",
    "\tdef predict(self, test_pair, train_pair, train_rating, top=10):\n",
    "\t\tpred = np.zeros(len(test_pair))\n",
    "\t\tfor j in range(len(test_pair)):\n",
    "\t\t\tuser_tmp, item_tmp = test_pair[j,0], test_pair[j,1]\n",
    "\t\t\tindex_tmp = self.index_item[item_tmp]\n",
    "\t\t\trated_users = train_pair[index_tmp][:,0]\n",
    "\t\t\trated_ratings = train_rating[index_tmp]\n",
    "\t\t\tsim_weight = self.S[user_tmp, rated_users].toarray()[0]\n",
    "\t\t\t## only keep top 10 closest users\n",
    "\t\t\ttop_ind = sim_weight.argsort()[-top:][::-1]\n",
    "\t\t\tsim_weight_knn = np.zeros(len(sim_weight))\n",
    "\t\t\tsim_weight_knn[top_ind] = sim_weight[top_ind]\n",
    "\t\t\tif (len(rated_users) == 0) or (max(sim_weight_knn) == 0):\n",
    "\t\t\t\t# if no rated users or no similar users\n",
    "\t\t\t\tpred[j] = self.user_mean[user_tmp]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpred[j] = np.sum(sim_weight_knn*rated_ratings) / np.sum(sim_weight_knn)\n",
    "\t\treturn pred\n",
    "\n",
    "\n",
    "class cor_rs_item(object):\n",
    "\tdef __init__(self, n_user, n_item):\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.item_mean = np.zeros(n_item)\n",
    "\t\tself.S = lil_matrix((n_item, n_item))\n",
    "\t\tself.index_item = []\n",
    "\t\tself.index_user = []\n",
    "\t\tself.min_co = 3\n",
    "\n",
    "\tdef cossim(self, index_i, index_j, train_pair, train_rating):\n",
    "\t\t# index_u = np.where(train_pair[:,0] == u)[0]\n",
    "\t\t# index_v = np.where(train_pair[:,0] == v)[0]\n",
    "\t\tuser_i = train_pair[index_i][:,0]\n",
    "\t\tuser_j = train_pair[index_j][:,0]\n",
    "\t\t# find co-rating items by `set`\n",
    "\t\tuser_co = list(set(user_i).intersection(set(user_j)))\n",
    "\t\tif len(user_co) < self.min_co:\n",
    "\t\t\t# a tuning parameter\n",
    "\t\t\treturn 0.0\n",
    "\t\telse:\n",
    "\t\t\t# find the co-rating vectors by using `np.where`\n",
    "\t\t\tvec_i, vec_j = train_rating[index_i], train_rating[index_j]\n",
    "\t\t\tind_co_i = [np.where(user_i == user_co_tmp)[0][0] for user_co_tmp in user_co]\n",
    "\t\t\tind_co_j = [np.where(user_j == user_co_tmp)[0][0] for user_co_tmp in user_co]\n",
    "\t\t\tvec_co_i, vec_co_j = vec_i[ind_co_i], vec_j[ind_co_j]\n",
    "\t\t\treturn np.dot(vec_co_i, vec_co_j) / (norm(vec_co_i)+1e-5) / (norm(vec_co_j)+1e-5)\n",
    "\t\n",
    "\tdef sim_mat(self, train_pair, train_rating):\n",
    "\t\tself.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "\t\tself.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "\t\tfor i in range(self.n_item):\n",
    "\t\t\tfor j in range(i):\n",
    "\t\t\t\tif (len(self.index_item[i]) == 0) or (len(self.index_item[j]) == 0):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tweight_tmp = self.cossim(self.index_item[i],self.index_item[j],train_pair,train_rating)\n",
    "\t\t\t\tif weight_tmp > 0:\n",
    "\t\t\t\t\tself.S[i,j] = weight_tmp\n",
    "\t\tself.S = self.S + self.S.T\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_rating):\n",
    "\t\tself.glb_mean = train_rating.mean()\n",
    "\t\t# use another class to predict the item mean\n",
    "\t\titem_ave_method = item_mean(self.n_item)\n",
    "\t\titem_ave_method.fit(train_pair, train_rating)\n",
    "\t\tself.item_mean = item_ave_method.item_mean\n",
    "\t\tself.sim_mat(train_pair, train_rating)\n",
    "\t\n",
    "\tdef predict(self, test_pair, train_pair, train_rating, top=10):\n",
    "\t\tpred = np.zeros(len(test_pair))\n",
    "\t\tfor j in range(len(test_pair)):\n",
    "\t\t\tuser_tmp, item_tmp = test_pair[j,0], test_pair[j,1]\n",
    "\t\t\tindex_tmp = self.index_user[user_tmp]\n",
    "\t\t\trated_items = train_pair[index_tmp][:,1]\n",
    "\t\t\trated_ratings = train_rating[index_tmp]\n",
    "\t\t\tsim_weight = self.S[item_tmp, rated_items].toarray()[0]\n",
    "\t\t\t## only keep top 10 closest users\n",
    "\t\t\ttop_ind = sim_weight.argsort()[-top:][::-1]\n",
    "\t\t\tsim_weight_knn = np.zeros(len(sim_weight))\n",
    "\t\t\tsim_weight_knn[top_ind] = sim_weight[top_ind]\n",
    "\t\t\tif (len(rated_items) == 0) or (max(sim_weight_knn) == 0):\n",
    "\t\t\t\t# if no rated items or no similar items\n",
    "\t\t\t\tpred[j] = self.item_mean[item_tmp]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpred[j] = np.sum(sim_weight_knn*rated_ratings) / np.sum(sim_weight_knn)\n",
    "\t\treturn pred\n",
    "\n",
    "def rmse(true, pred):\n",
    "\treturn np.sqrt(np.mean((pred - true)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pro-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtrain = pd.read_csv('./dataset/train.csv')\n",
    "dtest = pd.read_csv('./dataset/test.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "\n",
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "# pre-process for training data\n",
    "train_pair = dtrain[['user_id', 'movie_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# pre-process for testing set\n",
    "test_pair = dtest[['user_id', 'movie_id']].values\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and training the predictive models based on `class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for user_mean: 1.017\n"
     ]
    }
   ],
   "source": [
    "## baseline user mean methods\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_rating=train_rating)\n",
    "pred_user = user_ave.predict(test_pair)\n",
    "print('RMSE for user_mean: %.3f' %rmse(test_rating, pred_user) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for item_mean: 1.052\n"
     ]
    }
   ],
   "source": [
    "## baseline item mean methods\n",
    "item_ave = item_mean(n_item=n_item)\n",
    "item_ave.fit(train_pair=train_pair, train_rating=train_rating)\n",
    "pred_item = item_ave.predict(test_pair)\n",
    "print('RMSE for item_mean: %.3f' %rmse(test_rating, pred_item) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for corr_user: 1.065\n"
     ]
    }
   ],
   "source": [
    "## Correlation-based RS (user)\n",
    "cor_user = cor_rs_user(n_user=n_user, n_item=n_item)\n",
    "cor_user.fit(train_pair=train_pair, train_rating=train_rating)\n",
    "pred_cor_user = cor_user.predict(test_pair, train_pair, train_rating)\n",
    "print('RMSE for corr_user: %.3f' %rmse(test_rating, pred_cor_user) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for corr_item: 1.059\n"
     ]
    }
   ],
   "source": [
    "## Correlation-based RS (item)\n",
    "cor_item = cor_rs_item(n_user=n_user, n_item=n_item)\n",
    "cor_item.fit(train_pair=train_pair, train_rating=train_rating)\n",
    "pred_cor_item = cor_item.predict(test_pair, train_pair, train_rating)\n",
    "print('RMSE for corr_item: %.3f' %rmse(test_rating, pred_cor_item) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for glb + user_mean + cor_rs(user): 1.004\n"
     ]
    }
   ],
   "source": [
    "## Baseline + Correlation-based RS\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_rating=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit correlation-based RS by residual ratings \n",
    "cor_user = cor_rs_user(n_user=n_user, n_item=n_item)\n",
    "cor_user.fit(train_pair=train_pair, train_rating=train_rating_res)\n",
    "pred = pred + cor_user.predict(test_pair, train_pair, train_rating_res, top=10)\n",
    "\n",
    "print('RMSE for glb + user_mean + cor_rs(user): %.3f' %rmse(test_rating, pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for glb + user_mean + cor_rs(item): 1.017\n"
     ]
    }
   ],
   "source": [
    "## Baseline + Correlation-based RS\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# item_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "item_ave = item_mean(n_item=n_item)\n",
    "item_ave.fit(train_pair=train_pair, train_rating=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - item_ave.predict(train_pair)\n",
    "pred = pred + item_ave.predict(test_pair)\n",
    "# fit correlation-based RS by residual ratings \n",
    "cor_item = cor_rs_item(n_user=n_user, n_item=n_item)\n",
    "cor_item.fit(train_pair=train_pair, train_rating=train_rating_res)\n",
    "pred = pred + cor_item.predict(test_pair, train_pair, train_rating_res, top=10)\n",
    "\n",
    "print('RMSE for glb + item_mean + cor_rs(item): %.3f' %rmse(test_rating, pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation for glb + user_mean + cor_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_RMSE for glb + user_mean + cor_rs(user) with top = 5: 1.066\n",
      "Valid_RMSE for glb + user_mean + cor_rs(user) with top = 5: 1.066\n",
      "Valid_RMSE for glb + user_mean + cor_rs(user) with top = 5: 1.052\n",
      "Valid_RMSE for glb + user_mean + cor_rs(user) with top = 10: 1.048\n",
      "Valid_RMSE for glb + user_mean + cor_rs(user) with top = 10: 1.036\n",
      "Valid_RMSE for glb + user_mean + cor_rs(user) with top = 10: 1.038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "\n",
    "cv=3\n",
    "kf = KFold(n_splits=cv, shuffle=True)\n",
    "df = {'top': [], 'valid_rmse': []}\n",
    "for top_tmp in [5, 10]:\n",
    "    valid_rmse_tmp = 0.0\n",
    "    for train_index, valid_index in kf.split(train_pair):\n",
    "        train_pair_cv, train_rating_cv = train_pair[train_index], train_rating[train_index]\n",
    "        valid_pair_cv, valid_rating_cv = train_pair[valid_index], train_rating[valid_index]\n",
    "\n",
    "        # glb mean\n",
    "        glb_ave = glb_mean()\n",
    "        glb_ave.fit(train_rating_cv)\n",
    "        pred = glb_ave.predict(valid_pair_cv)\n",
    "        # user_mean\n",
    "        train_rating_cm = train_rating_cv - glb_ave.predict(train_pair_cv)\n",
    "        user_ave = user_mean(n_user=n_user)\n",
    "        user_ave.fit(train_pair=train_pair_cv, train_rating=train_rating_cm)\n",
    "        train_rating_res = train_rating_cm - user_ave.predict(train_pair_cv)\n",
    "        pred = pred + user_ave.predict(valid_pair_cv)\n",
    "        # fit correlation-based RS by residual ratings \n",
    "        cor_user = cor_rs_user(n_user=n_user, n_item=n_item)\n",
    "        cor_user.fit(train_pair=train_pair_cv, train_rating=train_rating_res)\n",
    "        pred = pred + cor_user.predict(valid_pair_cv, train_pair_cv, train_rating_res, top=top_tmp)\n",
    "        score_tmp = rmse(valid_rating_cv, pred)\n",
    "        valid_rmse_tmp += score_tmp / cv\n",
    "        print('Valid_RMSE for glb + user_mean + cor_rs(user) with top = %d: %.3f' %(top_tmp, score_tmp))\n",
    "    df['top'].append(top_tmp)\n",
    "    df['valid_rmse'].append(valid_rmse_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best model is top: 10\n"
     ]
    }
   ],
   "source": [
    "best_top = df['top'][np.argmin(df['valid_rmse'])]\n",
    "print('the best model is top: %d' %best_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for glb + user_mean + cor_rs(user): 1.004\n"
     ]
    }
   ],
   "source": [
    "## refit with the full train set\n",
    "## Baseline + Correlation-based RS\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_rating=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit correlation-based RS by residual ratings \n",
    "cor_user = cor_rs_user(n_user=n_user, n_item=n_item)\n",
    "cor_user.fit(train_pair=train_pair, train_rating=train_rating_res)\n",
    "pred = pred + cor_user.predict(test_pair, train_pair, train_rating_res, top=best_top)\n",
    "\n",
    "print('RMSE for glb + user_mean + cor_rs(user): %.3f' %rmse(test_rating, pred) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "414c3711fdd48b2f544ed65b2d7540fc36858fd70ee4f390e2b75c8d3b465c57"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
