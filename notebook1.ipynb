{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook1: Baseline methods for Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software prepare\n",
    "- `Code Editor`: VS Code; Sublime; or Atom\n",
    "\n",
    "- `Terminal`: Iterm2 in Mac; Deepin terminal in Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating virtual environments\n",
    "- If you have multiple versions of Python on your system, you can select a specific Python version by running python3 or whichever version you want.\n",
    "\n",
    "- To create a virtual environment, decide upon a directory where you want to place it, and run the venv module as a script with the directory path:\n",
    "\n",
    "- How to create and activate a virtual environment, see Section 12.2 in the [Document]((https://docs.python.org/3/tutorial/venv.html)).\n",
    "\n",
    "- Install packages via `pip`, see `Installing packages` section in the [Document]((https://docs.python.org/3/tutorial/venv.html)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle competition about recommender systems: user and item can be extended to more general cases.\n",
    "- [Elo Merchant Category Recommendation](https://www.kaggle.com/c/elo-merchant-category-recommendation/data?select=Data+Dictionary.xlsx): `merchant_id` and `card_id`.\n",
    "\n",
    "- [WSDM - KKBox's Music Recommendation Challenge](https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data): `user` and `music`.\n",
    "\n",
    "- [Event Recommendation Engine Challenge](https://www.kaggle.com/c/event-recommendation-engine-challenge/overview/evaluation): `user` and `event`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into Python\n",
    "- Dowload [Netflix Prize Data](https://www.kaggle.com/netflix-inc/netflix-prize-data). (For illustration, we only take the first subset.)\n",
    "\n",
    "- Load data into Python.\n",
    "\n",
    "- Re-orginize the data structure as a standard form.\n",
    "\n",
    "- For testing set, we hide the real ratings.\n",
    "\n",
    "- We only take the first subset for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37984</th>\n",
       "      <td>3333</td>\n",
       "      <td>1960</td>\n",
       "      <td>4</td>\n",
       "      <td>2003-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40504</th>\n",
       "      <td>3081</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>3094</td>\n",
       "      <td>538</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27699</th>\n",
       "      <td>267</td>\n",
       "      <td>1591</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>1389</td>\n",
       "      <td>983</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-11-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id  user_id  rating        date\n",
       "37984      3333     1960       4  2003-12-08\n",
       "40504      3081      135       4  2004-12-03\n",
       "7029       3094      538       5  2005-01-19\n",
       "27699       267     1591       5  2004-09-22\n",
       "11851      1389      983       4  2004-11-20"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtrain = pd.read_csv('./dataset/train.csv')\n",
    "dtrain.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>602</td>\n",
       "      <td>968</td>\n",
       "      <td>2003-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14265</th>\n",
       "      <td>2828</td>\n",
       "      <td>103</td>\n",
       "      <td>2005-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31870</th>\n",
       "      <td>1297</td>\n",
       "      <td>360</td>\n",
       "      <td>2005-08-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42554</th>\n",
       "      <td>769</td>\n",
       "      <td>425</td>\n",
       "      <td>2003-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13153</th>\n",
       "      <td>2716</td>\n",
       "      <td>1894</td>\n",
       "      <td>2005-02-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id  user_id        date\n",
       "15170       602      968  2003-06-10\n",
       "14265      2828      103  2005-09-09\n",
       "31870      1297      360  2005-08-21\n",
       "42554       769      425  2003-05-09\n",
       "13153      2716     1894  2005-02-07"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest = pd.read_csv('./dataset/test.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "dtest.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data as a `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "# pre-process for training data\n",
    "train_pair = dtrain[['user_id', 'movie_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# pre-process for testing set\n",
    "test_pair = dtest[['user_id', 'movie_id']].values\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Baseline methods: global\\_average, user\\_average and item\\_average (For your practice)\n",
    "- Inpout: training set.\n",
    "\n",
    "- Output: return predicted ratings for (user id, item id) user-item pairs in testing set.\n",
    "\n",
    "- Goal: make prediction for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(len(test_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.62115674 3.62115674 3.62115674 3.62115674 3.62115674 3.62115674\n",
      " 3.62115674 3.62115674 3.62115674 3.62115674]\n"
     ]
    }
   ],
   "source": [
    "## Global average\n",
    "global_pred = pred.copy()\n",
    "global_mean = train_rating.mean()\n",
    "global_pred = global_mean*np.ones(len(pred))\n",
    "print(global_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user\\_average\n",
    "- Loop for all users\n",
    "    - Find all records for this user in both training and testing sets.\n",
    "    - Compute the average ratings for this user in the training set.\n",
    "    - Predict the ratings for this users in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.73684211 3.35714286 3.66037736 2.84931507 3.70909091 3.27419355\n",
      " 3.16666667 3.57142857 4.1        3.375     ]\n"
     ]
    }
   ],
   "source": [
    "## user average\n",
    "UA_pred = pred.copy()\n",
    "for u in range(n_user):\n",
    "    # find the index for both train and test for user_id = u\n",
    "    ind_test = np.where(test_pair[:,0] == u)[0]\n",
    "    ind_train = np.where(train_pair[:,0] == u)[0]\n",
    "    if len(ind_test) == 0:\n",
    "        continue\n",
    "    if len(ind_train) < 3:\n",
    "        UA_pred[ind_test] = global_mean\n",
    "    else:\n",
    "        # predict as user average\n",
    "        UA_pred[ind_test] = train_rating[ind_train].mean()\n",
    "print(UA_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: compute RMSE for baseline methods\n",
    "- Input: (1) predicted testing ratings (2) real testing ratings\n",
    "\n",
    "- Output: RMSE for the prediction\n",
    "\n",
    "- Goal: evaluate the prediction performance for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for GLB average: 1.085\n"
     ]
    }
   ],
   "source": [
    "## RMSE for Global average\n",
    "rmse_glb = np.sqrt(np.mean((global_pred - test_rating)**2))\n",
    "print('RMSE for GLB average: %.3f' %rmse_glb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for user average: 1.013\n"
     ]
    }
   ],
   "source": [
    "## RMSE for user average\n",
    "rmse_usr = np.sqrt(np.mean((UA_pred - test_rating)**2))\n",
    "print('RMSE for user average: %.3f' %rmse_usr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize `glb_average` and `user_average` methods as Python functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `glb_average`\n",
    "\n",
    "- *Input*: 'train_rating', 'test_pair'\n",
    "\n",
    "- *Return*: Predicted ratings based on glb mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glb_mean(train_rating, test_pair):\n",
    "    pred = train_rating.mean() * np.ones(len(test_pair))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `user_average`\n",
    "\n",
    "- *Input*: 'train_pair', 'train_rating', 'test_pair'\n",
    "\n",
    "- *Return*: Predicted ratings based on user mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_mean(train_pair, train_rating, test_pair):\n",
    "    n_user = max(train_pair[:,0].max(), test_pair[:,0].max())+1\n",
    "    pred = np.zeros(len(test_pair))\n",
    "    glb_mean_value = train_rating.mean()\n",
    "    for u in range(n_user):\n",
    "        # find the index for both train and test for user_id = u\n",
    "        ind_test = np.where(test_pair[:,0] == u)[0]\n",
    "        ind_train = np.where(train_pair[:,0] == u)[0]\n",
    "        if len(ind_test) == 0:\n",
    "            continue\n",
    "        if len(ind_train) < 3:\n",
    "            pred[ind_test] = glb_mean_value\n",
    "        else:\n",
    "            # predict as user average\n",
    "            pred[ind_test] = train_rating[ind_train].mean()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_mean(train_pair, train_rating, test_pair):\n",
    "    n_item = max(train_pair[:,1].max(), test_pair[:,1].max())+1\n",
    "    pred = np.zeros(len(test_pair))\n",
    "    glb_mean_value = train_rating.mean()\n",
    "    for i in range(n_item):\n",
    "        # find the index for both train and test for item_id = i\n",
    "        ind_test = np.where(test_pair[:,1] == i)[0]\n",
    "        ind_train = np.where(train_pair[:,1] == i)[0]\n",
    "        if len(ind_test) == 0:\n",
    "            continue\n",
    "        if len(ind_train) < 3:\n",
    "            pred[ind_test] = glb_mean_value\n",
    "        else:\n",
    "            # predict as user average\n",
    "            pred[ind_test] = train_rating[ind_train].mean()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize `Evaluation` as a Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return np.sqrt(np.mean((pred - true)**2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "414c3711fdd48b2f544ed65b2d7540fc36858fd70ee4f390e2b75c8d3b465c57"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
