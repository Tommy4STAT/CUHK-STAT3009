{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('shiing': conda)"
  },
  "interpreter": {
   "hash": "414c3711fdd48b2f544ed65b2d7540fc36858fd70ee4f390e2b75c8d3b465c57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook1: Baseline methods for Recommender Systems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Software prepare\n",
    "- `Code Editor`: VS Code; Sublime; or Atom\n",
    "\n",
    "- `Terminal`: Iterm2 in Mac; Deepin terminal in Linux"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating virtual environments\n",
    "- If you have multiple versions of Python on your system, you can select a specific Python version by running python3 or whichever version you want.\n",
    "\n",
    "- To create a virtual environment, decide upon a directory where you want to place it, and run the venv module as a script with the directory path:\n",
    "\n",
    "- How to create and activate a virtual environment, see Section 12.2 in the [Document]((https://docs.python.org/3/tutorial/venv.html)).\n",
    "\n",
    "- Install packages via `pip`, see `Installing packages` section in the [Document]((https://docs.python.org/3/tutorial/venv.html)).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Kaggle competition about recommender systems: user and item can be extended to more general cases.\n",
    "- [Elo Merchant Category Recommendation](https://www.kaggle.com/c/elo-merchant-category-recommendation/data?select=Data+Dictionary.xlsx): `merchant_id` and `card_id`.\n",
    "\n",
    "- [WSDM - KKBox's Music Recommendation Challenge](https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data): `user` and `music`.\n",
    "\n",
    "- [Event Recommendation Engine Challenge](https://www.kaggle.com/c/event-recommendation-engine-challenge/overview/evaluation): `user` and `event`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load dataset into Python\n",
    "- Dowload [Netflix Prize Data](https://www.kaggle.com/netflix-inc/netflix-prize-data).\n",
    "\n",
    "- Load data into Python.\n",
    "\n",
    "- Re-orginize the data structure as a standard form.\n",
    "\n",
    "- For testing set, we hide the real ratings.\n",
    "\n",
    "- We only take the first subset for illustration."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0 (user_id, item_id)   ratings\n",
       "277         1624         (193, 276)  2.000092\n",
       "1483         839            (77, 5) -0.181529\n",
       "969         2177         (544, 380) -6.750653\n",
       "1278         971         (955, 474)  0.123241\n",
       "755         3055         (188, 228)  1.854153"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>(user_id, item_id)</th>\n      <th>ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>277</th>\n      <td>1624</td>\n      <td>(193, 276)</td>\n      <td>2.000092</td>\n    </tr>\n    <tr>\n      <th>1483</th>\n      <td>839</td>\n      <td>(77, 5)</td>\n      <td>-0.181529</td>\n    </tr>\n    <tr>\n      <th>969</th>\n      <td>2177</td>\n      <td>(544, 380)</td>\n      <td>-6.750653</td>\n    </tr>\n    <tr>\n      <th>1278</th>\n      <td>971</td>\n      <td>(955, 474)</td>\n      <td>0.123241</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>3055</td>\n      <td>(188, 228)</td>\n      <td>1.854153</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_demo.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0 (user_id, item_id)\n",
       "607        1911         (353, 155)\n",
       "637        1629         (380, 133)\n",
       "290        2938         (252, 499)\n",
       "601        1454         (311, 349)\n",
       "569         465         (758, 477)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>(user_id, item_id)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>607</th>\n      <td>1911</td>\n      <td>(353, 155)</td>\n    </tr>\n    <tr>\n      <th>637</th>\n      <td>1629</td>\n      <td>(380, 133)</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>2938</td>\n      <td>(252, 499)</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>1454</td>\n      <td>(311, 349)</td>\n    </tr>\n    <tr>\n      <th>569</th>\n      <td>465</td>\n      <td>(758, 477)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dt = pd.read_csv('../dataset/test_demo.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_ratings = dt['ratings']\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dt = dt.drop(columns='ratings')\n",
    "dt.sample(5)"
   ]
  },
  {
   "source": [
    "## Pre-process the data as a standard form\n",
    "- Convert `string` '(user_id, item_id)' -> `np.array` int \\[user_id, item_id\\]\n",
    "\n",
    "- Tutorial: [Reading Data from the Web: Web Scraping & Regular Expressions](https://www.summet.com/dmsi/html/readingTheWeb.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "import re\n",
    "# pre-process for training data\n",
    "train_pair = [re.findall(r'\\d+', tmp) for tmp in df['(user_id, item_id)']]\n",
    "train_pair = np.array(train_pair)\n",
    "train_pair = train_pair.astype(int)\n",
    "# pre-process for testing set\n",
    "test_pair = [re.findall(r'\\d+', tmp) for tmp in dt['(user_id, item_id)']]\n",
    "test_pair = np.array(test_pair)\n",
    "test_pair = test_pair.astype(int)\n",
    "n_user, n_item = train_pair[:,0].max()+1, train_pair[:,1].max()+1\n",
    "ratings = df['ratings'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the pre-process data use `np.save`\n",
    "np.save('../dataset/train_pair.npy', train_pair)\n",
    "np.save('../dataset/test_pair.npy', test_pair)\n",
    "np.save('../dataset/train_ratings.npy', ratings)\n",
    "np.save('../dataset/test_ratings.npy', test_ratings)"
   ]
  },
  {
   "source": [
    "## Implement Baseline methods: global\\_average, user\\_average and item\\_average (For your practice)\n",
    "- Inpout: training set.\n",
    "\n",
    "- Output: return predicted ratings for (user id, item id) user-item pairs in testing set.\n",
    "\n",
    "- Goal: make prediction for testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(len(test_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824 0.16038824\n 0.16038824]\n"
     ]
    }
   ],
   "source": [
    "## Global average\n",
    "global_pred = pred.copy()\n",
    "global_mean = ratings.mean()\n",
    "global_pred = global_mean*np.ones(len(pred))\n",
    "print(global_pred)"
   ]
  },
  {
   "source": [
    "### user\\_average\n",
    "- Loop for all users\n",
    "    - Find all records for this user in both training and testing sets.\n",
    "    - Compute the average ratings for this user in the training set.\n",
    "    - Predict the ratings for this users in the testing set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824 -2.5429363   0.16038824\n  1.49226864  0.16038824  0.16038824  0.16038824 -0.13110104  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824 -0.77525504\n  0.16038824  0.16038824  0.16038824  0.0942186   0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.82904672 -0.22997882  0.16038824\n  0.16038824 -2.5429363  -0.25746757  0.16038824  0.16038824  0.14768756\n  0.16038824  3.89276959  0.16038824  0.16038824  0.64775152  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  1.55805551\n  0.16038824  0.16038824  0.16038824  0.6141957   0.16038824  0.16038824\n  1.82851463  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  1.82881142  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824 -0.54255679  0.16038824 -1.42126489  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  1.05250079  0.16038824 -1.18812478  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.02885956  0.16038824  0.19188861  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.82904672  0.16038824  0.16038824  0.16038824  0.85784413\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  1.79649297  0.97690757  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  1.46449894  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824 -0.8386418\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.72465683  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.72465683 -0.60724905  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824 -0.04112672  0.16038824  0.16038824  1.57443072  0.16038824\n  0.16038824 -2.5429363   0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n -1.44255338  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.5435092   0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n -1.07216488  0.16038824  0.16038824  0.16038824  0.0942186   0.16038824\n  0.16038824  0.16038824  0.5435092   0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.32855385  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.49724755  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824 -0.75736995  0.16038824  0.16038824  0.16038824\n  0.16038824  0.0942186   0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824 -0.2220507   0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  2.5575098   0.16038824  0.16038824  0.16038824\n  0.16038824  1.92554434  0.16038824  1.92853394  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  2.69219273  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  1.25763726  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  1.92554434  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  2.5575098   0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  1.35894284  0.16038824  0.16038824  0.16038824\n -2.00841087  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  1.82851463  0.16038824\n -0.22997882  0.98804114  0.72465683  0.16038824  2.04359103  2.11964554\n  0.16038824  0.16038824  0.16038824  1.2186693   0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  1.236603    0.16038824  0.16038824  0.81177151\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  2.04359103  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.42555962  0.16038824  0.16038824  0.16038824  0.72465683  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.07298499  0.16038824  0.16038824  2.63076512  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  1.03884078  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.59759572  0.16038824  0.28477747 -2.82711357  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824 -1.37111282  0.16038824\n  0.16038824 -0.36927412  0.16038824 -0.04112672  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  1.05250079  0.16038824  1.78124333  0.16038824  0.64775152  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  1.46449894  2.13164358\n  0.16038824  0.16038824 -1.42126489  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.77889884  0.16038824\n  0.16038824  0.16038824  0.16038824  1.79649297  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  1.25763726\n  0.16038824  0.16038824  0.16038824  0.82904672  0.98418049  0.16038824\n  0.16038824 -0.57228607  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.56748069  0.16038824  0.19188861  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n -0.32318204  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.14768756  0.16038824  0.16038824\n  0.16038824  0.16038824 -0.60698467  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.42555962  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824 -0.36927412  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  1.59449082  0.16038824  0.16038824\n  0.16038824  1.51163104  2.39372184  0.16038824  0.16038824  0.16038824\n  0.16038824 -0.18389312  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.62017332  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824  0.16038824\n  0.16038824  0.16038824  1.93715336  0.16038824  0.16038824  0.16038824\n  0.16038824]\n"
     ]
    }
   ],
   "source": [
    "## user average\n",
    "UA_pred = pred.copy()\n",
    "for u in range(n_user):\n",
    "    # find the index for both train and test for user_id = u\n",
    "    ind_test = np.where(test_pair[:,0] == u)[0]\n",
    "    ind_train = np.where(train_pair[:,0] == u)[0]\n",
    "    if len(ind_test) == 0:\n",
    "        continue\n",
    "    if len(ind_train) < 5:\n",
    "        UA_pred[ind_test] = global_mean\n",
    "    else:\n",
    "        # predict as user average\n",
    "        UA_pred[ind_test] = ratings[ind_train].mean()\n",
    "print(UA_pred)"
   ]
  },
  {
   "source": [
    "## Evaluation: compute RMSE for baseline methods\n",
    "- Input: (1) predicted testing ratings (2) real testing ratings\n",
    "\n",
    "- Output: RMSE for the prediction\n",
    "\n",
    "- Goal: evaluate the prediction performance for the method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for GLB average: 2.588\n"
     ]
    }
   ],
   "source": [
    "## RMSE for Global average\n",
    "rmse_glb = np.sqrt(np.mean((global_pred - test_ratings)**2))\n",
    "print('RMSE for GLB average: %.3f' %rmse_glb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for user average: 2.591\n"
     ]
    }
   ],
   "source": [
    "## RMSE for user average\n",
    "rmse_usr = np.sqrt(np.mean((UA_pred - test_ratings)**2))\n",
    "print('RMSE for user average: %.3f' %rmse_usr)"
   ]
  }
 ]
}