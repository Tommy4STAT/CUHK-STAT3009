{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('shiing': venv)"
  },
  "interpreter": {
   "hash": "0ba986c4ce28ee590feb069d7dff47f6c0fdeef1e6e7e0640650ca3a5af9b036"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook4: ALS for Latent Factor Models II"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ALS for Latent factor model\n",
    "\n",
    "- **Parameter**: \n",
    "  - \\#Users: `n`\n",
    "  - \\#Items: `m`\n",
    "  - latent factors for users: `P` \n",
    "  - latent factors for items: `Q`\n",
    "  - tuning parameter: `lam`\n",
    "  - \\#Latent factors: `K`\n",
    "\n",
    "\n",
    "- **Method**:\n",
    "  - `fit`: input: `train_pair`, `train_rating`; output: fitted `P` and `Q`\n",
    "  - `predict`: input: `test_pair`; output: predicted ratings\n",
    "  - `rmse`: input: `test_pair`, `test_rating`; output: RMSE for the predicted ratings\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def rmse(true, pred):\n",
    "\treturn np.sqrt(np.mean((pred - true)**2))\n",
    "\n",
    "class LFM(object):\n",
    "\n",
    "    def __init__(self, n_user, n_item, lam=.001, K=10, iterNum=10, tol=1e-4, verbose=1):\n",
    "        self.P = np.random.randn(n_user, K)\n",
    "        self.Q = np.random.randn(n_item, K)\n",
    "        # self.index_item = []\n",
    "        # self.index_user = []\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.lam = lam\n",
    "        self.K = K\n",
    "        self.iterNum = iterNum\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, train_pair, train_rating):\n",
    "        diff, tol = 1., self.tol\n",
    "        n_user, n_item, n_obs = self.n_user, self.n_item, len(train_pair)\n",
    "        K, iterNum, lam = self.K, self.iterNum, self.lam\n",
    "        ## store user/item index set\n",
    "        self.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "        self.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "        if self.verbose:\n",
    "            print('Fitting Reg-LFM: K: %d, lam: %.5f' %(K, lam))\n",
    "        for i in range(iterNum):\n",
    "            ## item update\n",
    "            score_old = self.rmse(test_pair=train_pair, test_rating=train_rating)\n",
    "            for item_id in range(n_item):\n",
    "                # find all records from `item_id`\n",
    "                index_item_tmp = self.index_item[item_id]\n",
    "                if len(index_item_tmp) == 0:\n",
    "                    # if there is no record for `item_id`, set q_i = 0.\n",
    "                    self.Q[item_id,:] = 0.\n",
    "                    continue\n",
    "                # compute the \\sum p_u p_u^T and \\sum r_{ui} p_u\n",
    "                sum_pu, sum_matrix = np.zeros((K)), np.zeros((K, K))\n",
    "                for record_ind in index_item_tmp:\n",
    "                    ## double-check\n",
    "                    if item_id != train_pair[record_ind][1]:\n",
    "                        raise ValueError('the item_id is waring in updating Q!')\n",
    "                    user_id, rating_tmp = train_pair[record_ind][0], train_rating[record_ind]\n",
    "                    sum_matrix = sum_matrix + np.outer(self.P[user_id,:], self.P[user_id,:])\n",
    "                    sum_pu = sum_pu + rating_tmp * self.P[user_id,:]                    \n",
    "                # compute the q_i as a LSE\n",
    "                self.Q[item_id,:] = np.dot(np.linalg.inv(sum_matrix + lam*n_obs*np.identity(K)), sum_pu)\n",
    "            \n",
    "            for user_id in range(n_user):\n",
    "                index_user_tmp = self.index_user[user_id]\n",
    "                if len(index_user_tmp) == 0:\n",
    "                    self.P[user_id,:] = 0.\n",
    "                    continue\n",
    "                sum_pu, sum_matrix = np.zeros((K)), np.zeros((K, K))\n",
    "                for record_ind in index_user_tmp:\n",
    "                    ## double-check\n",
    "                    if user_id != train_pair[record_ind][0]:\n",
    "                        raise ValueError('the user_id is waring in updating P!')\n",
    "                    item_id, rating_tmp = train_pair[record_ind][1], train_rating[record_ind]\n",
    "                    sum_matrix = sum_matrix + np.outer(self.Q[item_id,:], self.Q[item_id,:])\n",
    "                    sum_pu = sum_pu + rating_tmp * self.Q[item_id,:]                    \n",
    "                self.P[user_id,:] = np.dot(np.linalg.inv(sum_matrix + lam*n_obs*np.identity(K)), sum_pu)\n",
    "            # compute the new rmse score\n",
    "            score_new = self.rmse(test_pair=train_pair, test_rating=train_rating)\n",
    "            diff = abs(score_new - score_old) / score_old\n",
    "            if self.verbose:\n",
    "                print(\"Reg-LFM: ite: %d; diff: %.3f RMSE: %.3f\" %(i, diff, score_new))\n",
    "            if(diff < tol):\n",
    "                break\n",
    "\n",
    "    def predict(self, test_pair):\n",
    "        # predict ratings for user-item pairs\n",
    "        pred_rating = [np.dot(self.P[line[0]], self.Q[line[1]]) for line in test_pair]\n",
    "        return np.array(pred_rating)\n",
    "    \n",
    "    def rmse(self, test_pair, test_rating):\n",
    "        # report the rmse for the fitted `LFM`\n",
    "        pred_rating = self.predict(test_pair=test_pair)\n",
    "        return np.sqrt( np.mean( (pred_rating - test_rating)**2) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and pro-processed dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtrain = pd.read_csv('./dataset/train.csv')\n",
    "dtest = pd.read_csv('./dataset/test.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "\n",
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "# pre-process for training data\n",
    "train_pair = dtrain[['user_id', 'movie_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# pre-process for testing set\n",
    "test_pair = dtest[['user_id', 'movie_id']].values\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit and predict based on `LFM`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# fitting\n",
    "shiing = LFM(n_user, n_item, K=3, lam=.0001)\n",
    "shiing.fit(train_pair=train_pair, train_rating=train_rating)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.227 RMSE: 3.207\n",
      "Reg-LFM: ite: 1; diff: 0.676 RMSE: 1.040\n",
      "Reg-LFM: ite: 2; diff: 0.076 RMSE: 0.961\n",
      "Reg-LFM: ite: 3; diff: 0.024 RMSE: 0.938\n",
      "Reg-LFM: ite: 4; diff: 0.012 RMSE: 0.927\n",
      "Reg-LFM: ite: 5; diff: 0.008 RMSE: 0.920\n",
      "Reg-LFM: ite: 6; diff: 0.005 RMSE: 0.915\n",
      "Reg-LFM: ite: 7; diff: 0.003 RMSE: 0.913\n",
      "Reg-LFM: ite: 8; diff: 0.001 RMSE: 0.911\n",
      "Reg-LFM: ite: 9; diff: 0.001 RMSE: 0.911\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# pediction\n",
    "pred_rating = shiing.predict(test_pair)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# evaluation\n",
    "# rmse(test_rating, pred_rating)\n",
    "# or we can just use\n",
    "shiing.rmse(test_pair, test_rating)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.1655499719771572"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# baseline methods\n",
    "class glb_mean(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.glb_mean = 0\n",
    "\t\n",
    "\tdef fit(self, train_ratings):\n",
    "\t\tself.glb_mean = np.mean(train_ratings)\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))\n",
    "\t\tpred = pred*self.glb_mean\n",
    "\t\treturn pred\n",
    "\n",
    "class user_mean(object):\n",
    "\tdef __init__(self, n_user):\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.user_mean = np.zeros(n_user)\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_ratings):\n",
    "\t\tself.glb_mean = train_ratings.mean()\n",
    "\t\tfor u in range(self.n_user):\n",
    "\t\t\tind_train = np.where(train_pair[:,0] == u)[0]\n",
    "\t\t\tif len(ind_train) == 0:\n",
    "\t\t\t\tself.user_mean[u] = self.glb_mean\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.user_mean[u] = train_ratings[ind_train].mean()\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))*self.glb_mean\n",
    "\t\tj = 0\n",
    "\t\tfor row in test_pair:\n",
    "\t\t\tuser_tmp, item_tmp = row[0], row[1]\n",
    "\t\t\tpred[j] = self.user_mean[user_tmp]\n",
    "\t\t\tj = j + 1\n",
    "\t\treturn pred\n",
    "\n",
    "class item_mean(object):\n",
    "\tdef __init__(self, n_item):\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.item_mean = np.zeros(n_item)\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_ratings):\n",
    "\t\tself.glb_mean = train_ratings.mean()\n",
    "\t\tfor i in range(self.n_item):\n",
    "\t\t\tind_train = np.where(train_pair[:,1] == i)[0]\n",
    "\t\t\tif len(ind_train) == 0:\n",
    "\t\t\t\tself.item_mean[i] = self.glb_mean\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.item_mean[i] = train_ratings[ind_train].mean()\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))*self.glb_mean\n",
    "\t\tj = 0\n",
    "\t\tfor row in test_pair:\n",
    "\t\t\tuser_tmp, item_tmp = row[0], row[1]\n",
    "\t\t\tpred[j] = self.item_mean[item_tmp]\n",
    "\t\t\tj = j + 1\n",
    "\t\treturn pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "## Baseline + LFM\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit LFM RS by residual ratings \n",
    "shiing = LFM(n_user, n_item, K=3, lam=.0001)\n",
    "shiing.fit(train_pair=train_pair, train_rating=train_rating_res)\n",
    "pred = pred + shiing.predict(test_pair)\n",
    "\n",
    "print('RMSE for glb + user_mean + LFM: %.3f' %rmse(test_rating, pred) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.527 RMSE: 0.939\n",
      "Reg-LFM: ite: 1; diff: 0.050 RMSE: 0.892\n",
      "Reg-LFM: ite: 2; diff: 0.042 RMSE: 0.854\n",
      "Reg-LFM: ite: 3; diff: 0.021 RMSE: 0.836\n",
      "Reg-LFM: ite: 4; diff: 0.010 RMSE: 0.828\n",
      "Reg-LFM: ite: 5; diff: 0.006 RMSE: 0.823\n",
      "Reg-LFM: ite: 6; diff: 0.003 RMSE: 0.820\n",
      "Reg-LFM: ite: 7; diff: 0.002 RMSE: 0.819\n",
      "Reg-LFM: ite: 8; diff: 0.001 RMSE: 0.818\n",
      "Reg-LFM: ite: 9; diff: 0.001 RMSE: 0.817\n",
      "RMSE for glb + user_mean + LFM: 0.975\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Which `lam` and `K` is best for prediction?\n",
    "\n",
    "- Grid search based on cross-validation\n",
    "- models with different `lam` and `K`: print CV rmse score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LFM_CV(object):\n",
    "\n",
    "\tdef __init__(self, n_user, n_item, cv=5,\n",
    "\t\t\t\tlams=[.000001,.0001,.001,.01], \n",
    "\t\t\t\tKs=[3,5,10,20], \n",
    "\t\t\t\titerNum=10, tol=1e-4):\n",
    "\t\t# self.index_item = []\n",
    "\t\t# self.index_user = []\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.cv = cv\n",
    "\t\tself.lams = lams\n",
    "\t\tself.Ks = Ks\n",
    "\t\tself.iterNum = iterNum\n",
    "\t\tself.tol = tol\n",
    "\t\tself.best_model = {}\n",
    "\t\tself.cv_result = {'K': [], 'lam': [], 'train_rmse': [], 'valid_rmse': []}\n",
    "\n",
    "\tdef grid_search(self, train_pair, train_rating):\n",
    "\t\t## generate all comb of `K` and `lam`\n",
    "\t\tkf = KFold(n_splits=self.cv, shuffle=True)\n",
    "\t\tfor (K,lam) in itertools.product(self.Ks, self.lams):\n",
    "\t\t\ttrain_rmse_tmp, valid_rmse_tmp = 0., 0.\n",
    "\t\t\tfor train_index, valid_index in kf.split(train_pair):\n",
    "\t\t\t\t# produce training/validation sets\n",
    "\t\t\t\ttrain_pair_cv, train_rating_cv = train_pair[train_index], train_rating[train_index]\n",
    "\t\t\t\tvalid_pair_cv, valid_rating_cv = train_pair[valid_index], train_rating[valid_index]\n",
    "\t\t\t\t# fit the model based on CV data\n",
    "\t\t\t\tmodel_tmp = LFM(self.n_user, self.n_item, K=K, lam=lam, verbose=0)\n",
    "\t\t\t\tmodel_tmp.fit(train_pair=train_pair_cv, train_rating=train_rating_cv)\n",
    "\t\t\t\ttrain_rmse_tmp_cv = model_tmp.rmse(test_pair=train_pair_cv, test_rating=train_rating_cv)\n",
    "\t\t\t\tvalid_rmse_tmp_cv = model_tmp.rmse(test_pair=valid_pair_cv, test_rating=valid_rating_cv)\n",
    "\t\t\t\ttrain_rmse_tmp = train_rmse_tmp + train_rmse_tmp_cv / self.cv\n",
    "\t\t\t\tvalid_rmse_tmp = valid_rmse_tmp + valid_rmse_tmp_cv / self.cv\n",
    "\t\t\t\tprint('%d-Fold CV for K: %d; lam: %.5f: train_rmse: %.3f, valid_rmse: %.3f' \n",
    "\t\t\t\t\t\t%(self.cv, K, lam, train_rmse_tmp_cv, valid_rmse_tmp_cv))\n",
    "\t\t\tself.cv_result['K'].append(K)\n",
    "\t\t\tself.cv_result['lam'].append(lam)\n",
    "\t\t\tself.cv_result['train_rmse'].append(train_rmse_tmp)\n",
    "\t\t\tself.cv_result['valid_rmse'].append(valid_rmse_tmp)\n",
    "\t\tself.cv_result = pd.DataFrame.from_dict(self.cv_result)\n",
    "\t\tbest_ind = self.cv_result['valid_rmse'].argmin()\n",
    "\t\tself.best_model = self.cv_result.loc[best_ind]\n",
    "\t\n",
    "\tdef plot_grid(self, data_source='valid'):\n",
    "\t\tsns.set_theme()\n",
    "\t\tif data_source == 'train':\n",
    "\t\t\tcv_pivot = self.cv_result.pivot(\"K\", \"lam\", \"train_rmse\")\n",
    "\t\telif data_source == 'valid':\n",
    "\t\t\tcv_pivot = self.cv_result.pivot(\"K\", \"lam\", \"valid_rmse\")\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('data_source must be train or valid!')\n",
    "\t\tsns.heatmap(cv_pivot, annot=True, fmt=\".3f\", linewidths=.5, cmap=\"YlGnBu\")\n",
    "\t\tplt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## CV based on `LFM_CV`\n",
    "## Baseline + LFM\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit LFM_CV by residual ratings \n",
    "Ks, lams = [2, 3, 5, 10], 10**np.arange(-6, -2, .5)\n",
    "shiing_cv = LFM_CV(n_user, n_item, cv=3, Ks=Ks, lams=lams)\n",
    "shiing_cv.grid_search(train_pair, train_rating_res)\n",
    "shiing_cv.plot_grid('valid')\n",
    "shiing_cv.plot_grid('train')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 0.797, valid_rmse: 1.282\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 0.789, valid_rmse: 1.266\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 0.792, valid_rmse: 1.250\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 0.767, valid_rmse: 1.074\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 0.768, valid_rmse: 1.093\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 0.775, valid_rmse: 1.094\n",
      "3-Fold CV for K: 2; lam: 0.00001: train_rmse: 0.779, valid_rmse: 1.037\n",
      "3-Fold CV for K: 2; lam: 0.00001: train_rmse: 0.771, valid_rmse: 1.039\n",
      "3-Fold CV for K: 2; lam: 0.00001: train_rmse: 0.778, valid_rmse: 1.020\n",
      "3-Fold CV for K: 2; lam: 0.00003: train_rmse: 0.780, valid_rmse: 0.988\n",
      "3-Fold CV for K: 2; lam: 0.00003: train_rmse: 0.781, valid_rmse: 0.977\n",
      "3-Fold CV for K: 2; lam: 0.00003: train_rmse: 0.788, valid_rmse: 1.002\n",
      "3-Fold CV for K: 2; lam: 0.00010: train_rmse: 0.821, valid_rmse: 0.949\n",
      "3-Fold CV for K: 2; lam: 0.00010: train_rmse: 0.816, valid_rmse: 0.965\n",
      "3-Fold CV for K: 2; lam: 0.00010: train_rmse: 0.831, valid_rmse: 0.957\n",
      "3-Fold CV for K: 2; lam: 0.00032: train_rmse: 0.899, valid_rmse: 0.954\n",
      "3-Fold CV for K: 2; lam: 0.00032: train_rmse: 0.898, valid_rmse: 0.940\n",
      "3-Fold CV for K: 2; lam: 0.00032: train_rmse: 0.903, valid_rmse: 0.955\n",
      "3-Fold CV for K: 2; lam: 0.00100: train_rmse: 0.976, valid_rmse: 0.969\n",
      "3-Fold CV for K: 2; lam: 0.00100: train_rmse: 0.972, valid_rmse: 0.977\n",
      "3-Fold CV for K: 2; lam: 0.00100: train_rmse: 0.973, valid_rmse: 0.975\n",
      "3-Fold CV for K: 2; lam: 0.00316: train_rmse: 0.974, valid_rmse: 0.972\n",
      "3-Fold CV for K: 2; lam: 0.00316: train_rmse: 0.973, valid_rmse: 0.974\n",
      "3-Fold CV for K: 2; lam: 0.00316: train_rmse: 0.973, valid_rmse: 0.975\n",
      "3-Fold CV for K: 3; lam: 0.00000: train_rmse: 0.718, valid_rmse: 1.329\n",
      "3-Fold CV for K: 3; lam: 0.00000: train_rmse: 0.722, valid_rmse: 1.276\n",
      "3-Fold CV for K: 3; lam: 0.00000: train_rmse: 0.699, valid_rmse: 1.251\n",
      "3-Fold CV for K: 3; lam: 0.00000: train_rmse: 0.707, valid_rmse: 1.165\n",
      "3-Fold CV for K: 3; lam: 0.00000: train_rmse: 0.720, valid_rmse: 1.178\n",
      "3-Fold CV for K: 3; lam: 0.00000: train_rmse: 0.697, valid_rmse: 1.140\n",
      "3-Fold CV for K: 3; lam: 0.00001: train_rmse: 0.704, valid_rmse: 1.090\n",
      "3-Fold CV for K: 3; lam: 0.00001: train_rmse: 0.710, valid_rmse: 1.071\n",
      "3-Fold CV for K: 3; lam: 0.00001: train_rmse: 0.710, valid_rmse: 1.080\n",
      "3-Fold CV for K: 3; lam: 0.00003: train_rmse: 0.727, valid_rmse: 1.008\n",
      "3-Fold CV for K: 3; lam: 0.00003: train_rmse: 0.721, valid_rmse: 1.018\n",
      "3-Fold CV for K: 3; lam: 0.00003: train_rmse: 0.726, valid_rmse: 1.047\n",
      "3-Fold CV for K: 3; lam: 0.00010: train_rmse: 0.790, valid_rmse: 0.985\n",
      "3-Fold CV for K: 3; lam: 0.00010: train_rmse: 0.779, valid_rmse: 0.961\n",
      "3-Fold CV for K: 3; lam: 0.00010: train_rmse: 0.784, valid_rmse: 0.990\n",
      "3-Fold CV for K: 3; lam: 0.00032: train_rmse: 0.881, valid_rmse: 0.937\n",
      "3-Fold CV for K: 3; lam: 0.00032: train_rmse: 0.880, valid_rmse: 0.943\n",
      "3-Fold CV for K: 3; lam: 0.00032: train_rmse: 0.876, valid_rmse: 0.949\n",
      "3-Fold CV for K: 3; lam: 0.00100: train_rmse: 0.974, valid_rmse: 0.974\n",
      "3-Fold CV for K: 3; lam: 0.00100: train_rmse: 0.973, valid_rmse: 0.975\n",
      "3-Fold CV for K: 3; lam: 0.00100: train_rmse: 0.974, valid_rmse: 0.972\n",
      "3-Fold CV for K: 3; lam: 0.00316: train_rmse: 0.973, valid_rmse: 0.975\n",
      "3-Fold CV for K: 3; lam: 0.00316: train_rmse: 0.975, valid_rmse: 0.972\n",
      "3-Fold CV for K: 3; lam: 0.00316: train_rmse: 0.974, valid_rmse: 0.974\n",
      "3-Fold CV for K: 5; lam: 0.00000: train_rmse: 0.606, valid_rmse: 1.466\n",
      "3-Fold CV for K: 5; lam: 0.00000: train_rmse: 0.600, valid_rmse: 1.391\n",
      "3-Fold CV for K: 5; lam: 0.00000: train_rmse: 0.613, valid_rmse: 1.393\n",
      "3-Fold CV for K: 5; lam: 0.00000: train_rmse: 0.598, valid_rmse: 1.258\n",
      "3-Fold CV for K: 5; lam: 0.00000: train_rmse: 0.606, valid_rmse: 1.262\n",
      "3-Fold CV for K: 5; lam: 0.00000: train_rmse: 0.598, valid_rmse: 1.258\n",
      "3-Fold CV for K: 5; lam: 0.00001: train_rmse: 0.612, valid_rmse: 1.154\n",
      "3-Fold CV for K: 5; lam: 0.00001: train_rmse: 0.607, valid_rmse: 1.164\n",
      "3-Fold CV for K: 5; lam: 0.00001: train_rmse: 0.603, valid_rmse: 1.157\n",
      "3-Fold CV for K: 5; lam: 0.00003: train_rmse: 0.628, valid_rmse: 1.071\n",
      "3-Fold CV for K: 5; lam: 0.00003: train_rmse: 0.627, valid_rmse: 1.075\n",
      "3-Fold CV for K: 5; lam: 0.00003: train_rmse: 0.631, valid_rmse: 1.079\n",
      "3-Fold CV for K: 5; lam: 0.00010: train_rmse: 0.711, valid_rmse: 0.992\n",
      "3-Fold CV for K: 5; lam: 0.00010: train_rmse: 0.705, valid_rmse: 1.013\n",
      "3-Fold CV for K: 5; lam: 0.00010: train_rmse: 0.710, valid_rmse: 1.002\n",
      "3-Fold CV for K: 5; lam: 0.00032: train_rmse: 0.854, valid_rmse: 0.950\n",
      "3-Fold CV for K: 5; lam: 0.00032: train_rmse: 0.863, valid_rmse: 0.938\n",
      "3-Fold CV for K: 5; lam: 0.00032: train_rmse: 0.862, valid_rmse: 0.945\n",
      "3-Fold CV for K: 5; lam: 0.00100: train_rmse: 0.970, valid_rmse: 0.981\n",
      "3-Fold CV for K: 5; lam: 0.00100: train_rmse: 0.975, valid_rmse: 0.970\n",
      "3-Fold CV for K: 5; lam: 0.00100: train_rmse: 0.976, valid_rmse: 0.970\n",
      "3-Fold CV for K: 5; lam: 0.00316: train_rmse: 0.973, valid_rmse: 0.975\n",
      "3-Fold CV for K: 5; lam: 0.00316: train_rmse: 0.976, valid_rmse: 0.969\n",
      "3-Fold CV for K: 5; lam: 0.00316: train_rmse: 0.972, valid_rmse: 0.977\n",
      "3-Fold CV for K: 10; lam: 0.00000: train_rmse: 0.412, valid_rmse: 1.533\n",
      "3-Fold CV for K: 10; lam: 0.00000: train_rmse: 0.419, valid_rmse: 1.509\n",
      "3-Fold CV for K: 10; lam: 0.00000: train_rmse: 0.411, valid_rmse: 1.566\n",
      "3-Fold CV for K: 10; lam: 0.00000: train_rmse: 0.411, valid_rmse: 1.374\n",
      "3-Fold CV for K: 10; lam: 0.00000: train_rmse: 0.402, valid_rmse: 1.390\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## refit the best model, and make prediction\n",
    "best_K, best_lam = int(shiing_cv.best_model['K']), shiing_cv.best_model['lam']\n",
    "shiing=LFM(n_user, n_item, K=best_K, lam=best_lam)\n",
    "shiing.fit(train_pair, train_rating_res)\n",
    "pred = pred + shiing.predict(test_pair)\n",
    "print('RMSE for glb + user_mean + LFM: %.3f' %rmse(test_rating, pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 10, lam: 0.00032\n",
      "Reg-LFM: ite: 0; diff: 0.709 RMSE: 0.953\n",
      "Reg-LFM: ite: 1; diff: 0.010 RMSE: 0.944\n",
      "Reg-LFM: ite: 2; diff: 0.029 RMSE: 0.916\n",
      "Reg-LFM: ite: 3; diff: 0.016 RMSE: 0.901\n",
      "Reg-LFM: ite: 4; diff: 0.008 RMSE: 0.894\n",
      "Reg-LFM: ite: 5; diff: 0.004 RMSE: 0.891\n",
      "Reg-LFM: ite: 6; diff: 0.003 RMSE: 0.889\n",
      "Reg-LFM: ite: 7; diff: 0.002 RMSE: 0.887\n",
      "Reg-LFM: ite: 8; diff: 0.001 RMSE: 0.886\n",
      "Reg-LFM: ite: 9; diff: 0.001 RMSE: 0.885\n",
      "RMSE for glb + user_mean + LFM: 0.978\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}