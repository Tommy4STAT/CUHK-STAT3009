{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('shiing': conda)"
  },
  "interpreter": {
   "hash": "414c3711fdd48b2f544ed65b2d7540fc36858fd70ee4f390e2b75c8d3b465c57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook4: ALS for Latent Factor Models II"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Object-Oriented Programming (OOP) in Python\n",
    "\n",
    "- define an RS as a `class` with `parameters` in Python\n",
    "- define `fit`, `predict` functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# warm-up with baseline methods\n",
    "\n",
    "class glb_mean(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.glb_mean = 0\n",
    "\t\n",
    "\tdef fit(self, train_ratings):\n",
    "\t\tself.glb_mean = np.mean(train_ratings)\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))\n",
    "\t\tpred = pred*self.glb_mean\n",
    "\t\treturn pred\n",
    "\n",
    "class user_mean(object):\n",
    "\tdef __init__(self, n_user):\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.user_mean = np.zeros(n_user)\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_ratings):\n",
    "\t\tself.glb_mean = train_ratings.mean()\n",
    "\t\tfor u in range(self.n_user):\n",
    "\t\t\tind_train = np.where(train_pair[:,0] == u)[0]\n",
    "\t\t\tif len(ind_train) == 0:\n",
    "\t\t\t\tself.user_mean[u] = self.glb_mean\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.user_mean[u] = train_ratings[ind_train].mean()\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))*self.glb_mean\n",
    "\t\tj = 0\n",
    "\t\tfor row in test_pair:\n",
    "\t\t\tuser_tmp, item_tmp = row[0], row[1]\n",
    "\t\t\tpred[j] = self.user_mean[user_tmp]\n",
    "\t\t\tj = j + 1\n",
    "\t\treturn pred\n",
    "\n",
    "class item_mean(object):\n",
    "\tdef __init__(self, n_item):\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.item_mean = np.zeros(n_item)\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_ratings):\n",
    "\t\tself.glb_mean = train_ratings.mean()\n",
    "\t\tfor i in range(self.n_item):\n",
    "\t\t\tind_train = np.where(train_pair[:,1] == i)[0]\n",
    "\t\t\tif len(ind_train) == 0:\n",
    "\t\t\t\tself.item_mean[i] = self.glb_mean\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.item_mean[i] = train_ratings[ind_train].mean()\n",
    "\t\n",
    "\tdef predict(self, test_pair):\n",
    "\t\tpred = np.ones(len(test_pair))*self.glb_mean\n",
    "\t\tj = 0\n",
    "\t\tfor row in test_pair:\n",
    "\t\t\tuser_tmp, item_tmp = row[0], row[1]\n",
    "\t\t\tpred[j] = self.item_mean[item_tmp]\n",
    "\t\t\tj = j + 1\n",
    "\t\treturn pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# define class for correlation based RS\n",
    "from numpy.linalg import norm\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "class cor_rs_user(object):\n",
    "\tdef __init__(self, n_user):\n",
    "\t\tself.n_user = n_user\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.user_mean = np.zeros(n_user)\n",
    "\t\tself.S = lil_matrix((n_user, n_user))\n",
    "\t\tself.index_item = []\n",
    "\t\tself.index_user = []\n",
    "\t\tself.min_co = 3\n",
    "\t\n",
    "\tdef cossim(self, index_u, index_v, train_pair, train_ratings):\n",
    "\t\titem_u = train_pair[index_u][:,1]\n",
    "\t\titem_v = train_pair[index_v][:,1]\n",
    "\t\t# find co-rating items by `set`\n",
    "\t\titem_co = list(set(item_u).intersection(set(item_v)))\n",
    "\t\tif len(item_co) < self.min_co:\n",
    "\t\t\t# a tuning parameter\n",
    "\t\t\treturn 0.0\n",
    "\t\telse:\n",
    "\t\t\t# find the co-rating vectors by using `np.isin`\n",
    "\t\t\tvec_u, vec_v = train_ratings[index_u], train_ratings[index_v]\n",
    "\t\t\tvec_co_u, vec_co_v = vec_u[np.isin(item_u, item_co)], vec_v[np.isin(item_v, item_co)]\n",
    "\t\t\treturn np.dot(vec_co_u, vec_co_v) / (norm(vec_co_u)+1e-5) / (norm(vec_co_v)+1e-5)\n",
    "\t\n",
    "\tdef sim_mat(self, train_pair, train_ratings):\n",
    "\t\tself.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "\t\tself.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "\t\tfor u in range(self.n_user):\n",
    "\t\t\tfor v in range(u):\n",
    "\t\t\t\tif (len(self.index_user[u]) == 0) or (len(self.index_user[v]) == 0):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tweight_tmp = self.cossim(self.index_user[u],self.index_user[v],train_pair,train_ratings)\n",
    "\t\t\t\tif weight_tmp > 0:\n",
    "\t\t\t\t\tself.S[u,v] = weight_tmp\n",
    "\t\tself.S = self.S + self.S.T\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_ratings):\n",
    "\t\tself.glb_mean = train_ratings.mean()\n",
    "\t\t# use another class to predict the user mean\n",
    "\t\tuser_ave_method = user_mean(self.n_user)\n",
    "\t\tuser_ave_method.fit(train_pair, train_ratings)\n",
    "\t\tself.user_mean = user_ave_method.user_mean\n",
    "\t\tself.sim_mat(train_pair, train_ratings)\n",
    "\t\n",
    "\tdef predict(self, test_pair, train_ratings, top=10):\n",
    "\t\tpred = np.zeros(len(test_pair))\n",
    "\t\tfor j in range(len(test_pair)):\n",
    "\t\t\tuser_tmp, item_tmp = test_pair[j,0], test_pair[j,1]\n",
    "\t\t\tindex_tmp = self.index_item[item_tmp]\n",
    "\t\t\trated_users = train_pair[index_tmp][:,0]\n",
    "\t\t\trated_ratings = train_ratings[index_tmp]\n",
    "\t\t\tsim_weight = self.S[user_tmp, rated_users].toarray()[0]\n",
    "\t\t\t## only keep top 10 closest users\n",
    "\t\t\ttop_ind = sim_weight.argsort()[-top:][::-1]\n",
    "\t\t\tsim_weight_knn = np.zeros(len(sim_weight))\n",
    "\t\t\tsim_weight_knn[top_ind] = sim_weight[top_ind]\n",
    "\t\t\tif (len(rated_users) == 0) or (max(sim_weight_knn) == 0):\n",
    "\t\t\t\t# if no rated users or no similar users\n",
    "\t\t\t\tpred[j] = self.user_mean[user_tmp]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpred[j] = np.sum(sim_weight_knn*rated_ratings) / np.sum(sim_weight_knn)\n",
    "\t\treturn pred\n",
    "\n",
    "\n",
    "class cor_rs_item(object):\n",
    "\tdef __init__(self, n_item):\n",
    "\t\tself.n_item = n_item\n",
    "\t\tself.glb_mean = 0.\n",
    "\t\tself.item_mean = np.zeros(n_item)\n",
    "\t\tself.S = lil_matrix((n_item, n_item))\n",
    "\t\tself.index_item = []\n",
    "\t\tself.index_user = []\n",
    "\t\tself.min_co = 3\n",
    "\n",
    "\tdef cossim(self, index_i, index_j, train_pair, train_ratings):\n",
    "\t\t# index_u = np.where(train_pair[:,0] == u)[0]\n",
    "\t\t# index_v = np.where(train_pair[:,0] == v)[0]\n",
    "\t\tuser_i = train_pair[index_i][:,0]\n",
    "\t\tuser_j = train_pair[index_j][:,0]\n",
    "\t\t# find co-rating items by `set`\n",
    "\t\tuser_co = list(set(user_i).intersection(set(user_j)))\n",
    "\t\tif len(user_co) < self.min_co:\n",
    "\t\t\t# a tuning parameter\n",
    "\t\t\treturn 0.0\n",
    "\t\telse:\n",
    "\t\t\t# find the co-rating vectors by using `np.isin`\n",
    "\t\t\tvec_i, vec_j = train_ratings[index_i], train_ratings[index_j]\n",
    "\t\t\tvec_co_i, vec_co_j = vec_i[np.isin(user_i, user_co)], vec_j[np.isin(user_j, user_co)]\n",
    "\t\t\treturn np.dot(vec_co_i, vec_co_j) / (norm(vec_co_i)+1e-5) / (norm(vec_co_j)+1e-5)\n",
    "\t\n",
    "\tdef sim_mat(self, train_pair, train_ratings):\n",
    "\t\tself.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "\t\tself.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "\t\tfor i in range(self.n_item):\n",
    "\t\t\tfor j in range(i):\n",
    "\t\t\t\tif (len(self.index_item[i]) == 0) or (len(self.index_item[j]) == 0):\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tweight_tmp = self.cossim(self.index_item[i],self.index_item[j],train_pair,train_ratings)\n",
    "\t\t\t\tif weight_tmp > 0:\n",
    "\t\t\t\t\tself.S[i,j] = weight_tmp\n",
    "\t\tself.S = self.S + self.S.T\n",
    "\t\n",
    "\tdef fit(self, train_pair, train_ratings):\n",
    "\t\tself.glb_mean = train_ratings.mean()\n",
    "\t\t# use another class to predict the item mean\n",
    "\t\titem_ave_method = item_mean(self.n_item)\n",
    "\t\titem_ave_method.fit(train_pair, train_ratings)\n",
    "\t\tself.item_mean = item_ave_method.item_mean\n",
    "\t\tself.sim_mat(train_pair, train_ratings)\n",
    "\t\n",
    "\tdef predict(self, test_pair, train_ratings, top=10):\n",
    "\t\tpred = np.zeros(len(test_pair))\n",
    "\t\tfor j in range(len(test_pair)):\n",
    "\t\t\tuser_tmp, item_tmp = test_pair[j,0], test_pair[j,1]\n",
    "\t\t\tindex_tmp = self.index_user[user_tmp]\n",
    "\t\t\trated_items = train_pair[index_tmp][:,1]\n",
    "\t\t\trated_ratings = train_ratings[index_tmp]\n",
    "\t\t\tsim_weight = self.S[item_tmp, rated_items].toarray()[0]\n",
    "\t\t\t## only keep top 10 closest users\n",
    "\t\t\ttop_ind = sim_weight.argsort()[-top:][::-1]\n",
    "\t\t\tsim_weight_knn = np.zeros(len(sim_weight))\n",
    "\t\t\tsim_weight_knn[top_ind] = sim_weight[top_ind]\n",
    "\t\t\tif (len(rated_items) == 0) or (max(sim_weight_knn) == 0):\n",
    "\t\t\t\t# if no rated items or no similar items\n",
    "\t\t\t\tpred[j] = self.item_mean[item_tmp]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpred[j] = np.sum(sim_weight_knn*rated_ratings) / np.sum(sim_weight_knn)\n",
    "\t\treturn pred\n",
    "\n",
    "def rmse(true, pred):\n",
    "\treturn np.sqrt(np.mean((pred - true)**2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and pro-processed dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtrain = pd.read_csv('./dataset/train.csv')\n",
    "dtest = pd.read_csv('./dataset/test.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_ratings = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "\n",
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "# pre-process for training data\n",
    "train_pair = dtrain[['user_id', 'movie_id']].values\n",
    "train_ratings = dtrain['rating'].values\n",
    "# pre-process for testing set\n",
    "test_pair = dtest[['user_id', 'movie_id']].values\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define and training the predictive models based on `class`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## baseline user mean methods\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_ratings)\n",
    "pred_user = user_ave.predict(test_pair)\n",
    "print('RMSE for user_mean: %.3f' %rmse(test_ratings, pred_user) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for user_mean: 1.017\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## baseline item mean methods\n",
    "item_ave = item_mean(n_item=n_item)\n",
    "item_ave.fit(train_pair=train_pair, train_ratings=train_ratings)\n",
    "pred_item = item_ave.predict(test_pair)\n",
    "print('RMSE for item_mean: %.3f' %rmse(test_ratings, pred_item) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for item_mean: 1.052\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## Correlation-based RS (user)\n",
    "cor_user = cor_rs_user(n_user=n_user)\n",
    "cor_user.fit(train_pair=train_pair, train_ratings=train_ratings)\n",
    "pred_cor_user = cor_user.predict(test_pair, train_ratings)\n",
    "print('RMSE for item_mean: %.3f' %rmse(test_ratings, pred_cor_user) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for item_mean: 1.073\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## Correlation-based RS (item)\n",
    "cor_item = cor_rs_item(n_item=n_item)\n",
    "cor_item.fit(train_pair=train_pair, train_ratings=train_ratings)\n",
    "pred_cor_item = cor_item.predict(test_pair, train_ratings)\n",
    "print('RMSE for item_mean: %.3f' %rmse(test_ratings, pred_cor_item) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for item_mean: 1.074\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## Baseline + Correlation-based RS\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_ratings)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_ratings_cm = train_ratings - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_ratings_cm)\n",
    "train_ratings_res = train_ratings_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit correlation-based RS by residual ratings \n",
    "cor_user = cor_rs_user(n_user=n_user)\n",
    "cor_user.fit(train_pair=train_pair, train_ratings=train_ratings_res)\n",
    "pred = pred + cor_user.predict(test_pair, train_ratings_res, top=1000)\n",
    "\n",
    "print('RMSE for glb + user_mean + cor_rs(user): %.3f' %rmse(test_ratings, pred) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for ite\tm_mean: 1.005\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}