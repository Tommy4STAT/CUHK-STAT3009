{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('shiing': venv)"
  },
  "interpreter": {
   "hash": "0ba986c4ce28ee590feb069d7dff47f6c0fdeef1e6e7e0640650ca3a5af9b036"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook5: Latent Factor Models III: SGD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We still focus on the `LFM` class, yet we will change the ALS in `fit` as the gradient descent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def rmse(true, pred):\n",
    "    return np.sqrt(np.mean((pred - true)**2))\n",
    "\n",
    "class LFM(object):\n",
    "\n",
    "    def __init__(self, n_user, n_item, lam=.001, K=10, iterNum=1000, tol=1e-4):\n",
    "        self.P = np.random.randn(n_user, K)\n",
    "        self.Q = np.random.randn(n_item, K)\n",
    "        # self.index_item = []\n",
    "        # self.index_user = []\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.lam = lam\n",
    "        self.K = K\n",
    "        self.iterNum = iterNum\n",
    "        self.tol = tol\n",
    "\n",
    "    def fit(self, train_pair, train_rating, learning_rate=0.0001):\n",
    "        diff, tol = 1., self.tol\n",
    "        n_user, n_item, n_obs = self.n_user, self.n_item, len(train_pair)\n",
    "        K, iterNum, lam = self.K, self.iterNum, self.lam\n",
    "        ## store user/item index set\n",
    "        self.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "        self.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "        print('Fitting Reg-LFM: K: %d, lam: %.5f' %(K, lam))\n",
    "        for i in range(iterNum):\n",
    "            ## item update\n",
    "            score_old = self.rmse(test_pair=train_pair, test_rating=train_rating)\n",
    "            for item_id in range(n_item):\n",
    "                index_item_tmp = self.index_item[item_id]\n",
    "                if len(index_item_tmp) == 0:\n",
    "                    self.Q[item_id,:] = 0.\n",
    "                    continue\n",
    "                sum_pu, sum_matrix = np.zeros((K)), np.zeros((K, K))\n",
    "                for record_ind in index_item_tmp:\n",
    "                    ## double-check\n",
    "                    if item_id != train_pair[record_ind][1]:\n",
    "                        raise ValueError('the item_id is wrong in updating Q!')\n",
    "                    ## Gradient\n",
    "                    user_id, rating_tmp = train_pair[record_ind][0], train_rating[record_ind]\n",
    "                    # r_{ui} - p_u^T q_i\n",
    "                    err_tmp = rating_tmp - np.dot(self.P[user_id], self.Q[item_id])\n",
    "                    # (r_{ui} - p_u^T q_i) p_u\n",
    "                    sum_pu = sum_pu + err_tmp * self.P[user_id,:] / n_obs\n",
    "                self.Q[item_id,:] = self.Q[item_id,:] + 2*learning_rate * sum_pu - 2*learning_rate*lam*self.Q[item_id,:]\n",
    "            \n",
    "            for user_id in range(n_user):\n",
    "                index_user_tmp = self.index_user[user_id]\n",
    "                if len(index_user_tmp) == 0:\n",
    "                    self.P[user_id,:] = 0.\n",
    "                    continue\n",
    "                sum_qi, sum_matrix = np.zeros((K)), np.zeros((K, K))\n",
    "                for record_ind in index_user_tmp:\n",
    "                    ## double-check\n",
    "                    if user_id != train_pair[record_ind][0]:\n",
    "                        raise ValueError('the user_id is waring in updating P!')\n",
    "                    item_id, rating_tmp = train_pair[record_ind][1], train_rating[record_ind]\n",
    "                    # r_{ui} - p_u^T q_i\n",
    "                    err_tmp = rating_tmp - np.dot(self.P[user_id], self.Q[item_id])\n",
    "                    # (r_{ui} - p_u^T q_i) q_i\n",
    "                    sum_qi = sum_qi + err_tmp * self.Q[item_id,:] / n_obs\n",
    "                self.P[user_id,:] = self.P[user_id,:] + 2*learning_rate*sum_qi - 2*learning_rate*lam*self.P[user_id,:]\n",
    "            # compute the new rmse score\n",
    "            score_new = self.rmse(test_pair=train_pair, test_rating=train_rating)\n",
    "            diff = - score_new + score_old\n",
    "            print(\"Reg-LFM: ite: %d; diff: %.3f RMSE: %.3f\" %(i, diff, score_new))\n",
    "            if (diff < tol):\n",
    "                break\n",
    "\n",
    "    def predict(self, test_pair):\n",
    "        # predict ratings for user-item pairs\n",
    "        pred_rating = [np.dot(self.P[line[0]], self.Q[line[1]]) for line in test_pair]\n",
    "        return np.array(pred_rating)\n",
    "    \n",
    "    def rmse(self, test_pair, test_rating):\n",
    "        # report the rmse for the fitted `LFM`\n",
    "        pred_rating = self.predict(test_pair=test_pair)\n",
    "        return np.sqrt( np.mean( (pred_rating - test_rating)**2) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and pro-processed dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtrain = pd.read_csv('./dataset/train.csv')\n",
    "dtest = pd.read_csv('./dataset/test.csv')\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "\n",
    "## convert string to user_id and item_id -> [user_id, item_id, rating]\n",
    "# pre-process for training data\n",
    "train_pair = dtrain[['user_id', 'movie_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# pre-process for testing set\n",
    "test_pair = dtest[['user_id', 'movie_id']].values\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit and predict based on `LFM`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Note that `learning_rate` is a tuning parameter. In practice, we will try a large one and gradually reduce to a small number until the termination condition."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# baseline methods\n",
    "class glb_mean(object):\n",
    "    def __init__(self):\n",
    "        self.glb_mean = 0\n",
    "    \n",
    "    def fit(self, train_ratings):\n",
    "        self.glb_mean = np.mean(train_ratings)\n",
    "    \n",
    "    def predict(self, test_pair):\n",
    "        pred = np.ones(len(test_pair))\n",
    "        pred = pred*self.glb_mean\n",
    "        return pred\n",
    "\n",
    "class user_mean(object):\n",
    "    def __init__(self, n_user):\n",
    "        self.n_user = n_user\n",
    "        self.glb_mean = 0.\n",
    "        self.user_mean = np.zeros(n_user)\n",
    "    \n",
    "    def fit(self, train_pair, train_ratings):\n",
    "        self.glb_mean = train_ratings.mean()\n",
    "        for u in range(self.n_user):\n",
    "            ind_train = np.where(train_pair[:,0] == u)[0]\n",
    "            if len(ind_train) == 0:\n",
    "                self.user_mean[u] = self.glb_mean\n",
    "            else:\n",
    "                self.user_mean[u] = train_ratings[ind_train].mean()\n",
    "    \n",
    "    def predict(self, test_pair):\n",
    "        pred = np.ones(len(test_pair))*self.glb_mean\n",
    "        j = 0\n",
    "        for row in test_pair:\n",
    "            user_tmp, item_tmp = row[0], row[1]\n",
    "            pred[j] = self.user_mean[user_tmp]\n",
    "            j = j + 1\n",
    "        return pred\n",
    "\n",
    "class item_mean(object):\n",
    "    def __init__(self, n_item):\n",
    "        self.n_item = n_item\n",
    "        self.glb_mean = 0.\n",
    "        self.item_mean = np.zeros(n_item)\n",
    "    \n",
    "    def fit(self, train_pair, train_ratings):\n",
    "        self.glb_mean = train_ratings.mean()\n",
    "        for i in range(self.n_item):\n",
    "            ind_train = np.where(train_pair[:,1] == i)[0]\n",
    "            if len(ind_train) == 0:\n",
    "                self.item_mean[i] = self.glb_mean\n",
    "            else:\n",
    "                self.item_mean[i] = train_ratings[ind_train].mean()\n",
    "    \n",
    "    def predict(self, test_pair):\n",
    "        pred = np.ones(len(test_pair))*self.glb_mean\n",
    "        j = 0\n",
    "        for row in test_pair:\n",
    "            user_tmp, item_tmp = row[0], row[1]\n",
    "            pred[j] = self.item_mean[item_tmp]\n",
    "            j = j + 1\n",
    "        return pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## Baseline + LFM\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit correlation-based RS by residual ratings \n",
    "shiing = LFM(n_user, n_item, K=3, lam=.0001)\n",
    "shiing.fit(train_pair=train_pair, train_rating=train_rating_res, learning_rate=100.)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.673 RMSE: 1.325\n",
      "Reg-LFM: ite: 1; diff: 0.149 RMSE: 1.175\n",
      "Reg-LFM: ite: 2; diff: 0.067 RMSE: 1.108\n",
      "Reg-LFM: ite: 3; diff: 0.040 RMSE: 1.068\n",
      "Reg-LFM: ite: 4; diff: 0.027 RMSE: 1.041\n",
      "Reg-LFM: ite: 5; diff: 0.019 RMSE: 1.022\n",
      "Reg-LFM: ite: 6; diff: 0.014 RMSE: 1.008\n",
      "Reg-LFM: ite: 7; diff: 0.011 RMSE: 0.998\n",
      "Reg-LFM: ite: 8; diff: 0.008 RMSE: 0.989\n",
      "Reg-LFM: ite: 9; diff: 0.007 RMSE: 0.983\n",
      "Reg-LFM: ite: 10; diff: 0.005 RMSE: 0.977\n",
      "Reg-LFM: ite: 11; diff: 0.004 RMSE: 0.973\n",
      "Reg-LFM: ite: 12; diff: 0.004 RMSE: 0.969\n",
      "Reg-LFM: ite: 13; diff: 0.003 RMSE: 0.966\n",
      "Reg-LFM: ite: 14; diff: 0.003 RMSE: 0.963\n",
      "Reg-LFM: ite: 15; diff: 0.002 RMSE: 0.961\n",
      "Reg-LFM: ite: 16; diff: 0.002 RMSE: 0.959\n",
      "Reg-LFM: ite: 17; diff: 0.002 RMSE: 0.957\n",
      "Reg-LFM: ite: 18; diff: 0.002 RMSE: 0.955\n",
      "Reg-LFM: ite: 19; diff: 0.001 RMSE: 0.954\n",
      "Reg-LFM: ite: 20; diff: 0.001 RMSE: 0.953\n",
      "Reg-LFM: ite: 21; diff: 0.001 RMSE: 0.952\n",
      "Reg-LFM: ite: 22; diff: 0.001 RMSE: 0.951\n",
      "Reg-LFM: ite: 23; diff: 0.001 RMSE: 0.950\n",
      "Reg-LFM: ite: 24; diff: 0.001 RMSE: 0.949\n",
      "Reg-LFM: ite: 25; diff: 0.001 RMSE: 0.948\n",
      "Reg-LFM: ite: 26; diff: 0.001 RMSE: 0.947\n",
      "Reg-LFM: ite: 27; diff: 0.001 RMSE: 0.946\n",
      "Reg-LFM: ite: 28; diff: 0.001 RMSE: 0.946\n",
      "Reg-LFM: ite: 29; diff: 0.001 RMSE: 0.945\n",
      "Reg-LFM: ite: 30; diff: 0.001 RMSE: 0.944\n",
      "Reg-LFM: ite: 31; diff: 0.001 RMSE: 0.943\n",
      "Reg-LFM: ite: 32; diff: 0.001 RMSE: 0.943\n",
      "Reg-LFM: ite: 33; diff: 0.001 RMSE: 0.942\n",
      "Reg-LFM: ite: 34; diff: 0.001 RMSE: 0.941\n",
      "Reg-LFM: ite: 35; diff: 0.001 RMSE: 0.941\n",
      "Reg-LFM: ite: 36; diff: 0.001 RMSE: 0.940\n",
      "Reg-LFM: ite: 37; diff: 0.001 RMSE: 0.939\n",
      "Reg-LFM: ite: 38; diff: 0.001 RMSE: 0.938\n",
      "Reg-LFM: ite: 39; diff: 0.001 RMSE: 0.937\n",
      "Reg-LFM: ite: 40; diff: 0.001 RMSE: 0.936\n",
      "Reg-LFM: ite: 41; diff: 0.001 RMSE: 0.935\n",
      "Reg-LFM: ite: 42; diff: 0.001 RMSE: 0.934\n",
      "Reg-LFM: ite: 43; diff: 0.001 RMSE: 0.933\n",
      "Reg-LFM: ite: 44; diff: 0.001 RMSE: 0.932\n",
      "Reg-LFM: ite: 45; diff: 0.001 RMSE: 0.931\n",
      "Reg-LFM: ite: 46; diff: 0.001 RMSE: 0.930\n",
      "Reg-LFM: ite: 47; diff: 0.001 RMSE: 0.929\n",
      "Reg-LFM: ite: 48; diff: 0.001 RMSE: 0.927\n",
      "Reg-LFM: ite: 49; diff: 0.001 RMSE: 0.926\n",
      "Reg-LFM: ite: 50; diff: 0.001 RMSE: 0.924\n",
      "Reg-LFM: ite: 51; diff: 0.001 RMSE: 0.923\n",
      "Reg-LFM: ite: 52; diff: 0.002 RMSE: 0.921\n",
      "Reg-LFM: ite: 53; diff: 0.002 RMSE: 0.920\n",
      "Reg-LFM: ite: 54; diff: 0.002 RMSE: 0.918\n",
      "Reg-LFM: ite: 55; diff: 0.002 RMSE: 0.917\n",
      "Reg-LFM: ite: 56; diff: 0.002 RMSE: 0.915\n",
      "Reg-LFM: ite: 57; diff: 0.002 RMSE: 0.913\n",
      "Reg-LFM: ite: 58; diff: 0.002 RMSE: 0.912\n",
      "Reg-LFM: ite: 59; diff: 0.002 RMSE: 0.910\n",
      "Reg-LFM: ite: 60; diff: 0.002 RMSE: 0.908\n",
      "Reg-LFM: ite: 61; diff: 0.002 RMSE: 0.907\n",
      "Reg-LFM: ite: 62; diff: 0.002 RMSE: 0.905\n",
      "Reg-LFM: ite: 63; diff: 0.002 RMSE: 0.903\n",
      "Reg-LFM: ite: 64; diff: 0.002 RMSE: 0.902\n",
      "Reg-LFM: ite: 65; diff: 0.002 RMSE: 0.900\n",
      "Reg-LFM: ite: 66; diff: 0.002 RMSE: 0.898\n",
      "Reg-LFM: ite: 67; diff: 0.002 RMSE: 0.897\n",
      "Reg-LFM: ite: 68; diff: 0.002 RMSE: 0.895\n",
      "Reg-LFM: ite: 69; diff: 0.002 RMSE: 0.894\n",
      "Reg-LFM: ite: 70; diff: 0.002 RMSE: 0.892\n",
      "Reg-LFM: ite: 71; diff: 0.002 RMSE: 0.891\n",
      "Reg-LFM: ite: 72; diff: 0.001 RMSE: 0.889\n",
      "Reg-LFM: ite: 73; diff: 0.001 RMSE: 0.888\n",
      "Reg-LFM: ite: 74; diff: 0.001 RMSE: 0.886\n",
      "Reg-LFM: ite: 75; diff: 0.001 RMSE: 0.885\n",
      "Reg-LFM: ite: 76; diff: 0.001 RMSE: 0.883\n",
      "Reg-LFM: ite: 77; diff: 0.001 RMSE: 0.882\n",
      "Reg-LFM: ite: 78; diff: 0.001 RMSE: 0.881\n",
      "Reg-LFM: ite: 79; diff: 0.001 RMSE: 0.879\n",
      "Reg-LFM: ite: 80; diff: 0.001 RMSE: 0.878\n",
      "Reg-LFM: ite: 81; diff: 0.001 RMSE: 0.877\n",
      "Reg-LFM: ite: 82; diff: 0.001 RMSE: 0.876\n",
      "Reg-LFM: ite: 83; diff: 0.001 RMSE: 0.874\n",
      "Reg-LFM: ite: 84; diff: 0.001 RMSE: 0.873\n",
      "Reg-LFM: ite: 85; diff: 0.001 RMSE: 0.872\n",
      "Reg-LFM: ite: 86; diff: 0.001 RMSE: 0.871\n",
      "Reg-LFM: ite: 87; diff: 0.001 RMSE: 0.870\n",
      "Reg-LFM: ite: 88; diff: 0.001 RMSE: 0.869\n",
      "Reg-LFM: ite: 89; diff: 0.001 RMSE: 0.867\n",
      "Reg-LFM: ite: 90; diff: 0.001 RMSE: 0.866\n",
      "Reg-LFM: ite: 91; diff: 0.001 RMSE: 0.865\n",
      "Reg-LFM: ite: 92; diff: 0.001 RMSE: 0.864\n",
      "Reg-LFM: ite: 93; diff: 0.001 RMSE: 0.863\n",
      "Reg-LFM: ite: 94; diff: 0.001 RMSE: 0.862\n",
      "Reg-LFM: ite: 95; diff: 0.001 RMSE: 0.861\n",
      "Reg-LFM: ite: 96; diff: 0.001 RMSE: 0.860\n",
      "Reg-LFM: ite: 97; diff: 0.001 RMSE: 0.859\n",
      "Reg-LFM: ite: 98; diff: 0.001 RMSE: 0.858\n",
      "Reg-LFM: ite: 99; diff: 0.001 RMSE: 0.857\n",
      "Reg-LFM: ite: 100; diff: 0.001 RMSE: 0.856\n",
      "Reg-LFM: ite: 101; diff: 0.001 RMSE: 0.855\n",
      "Reg-LFM: ite: 102; diff: 0.001 RMSE: 0.854\n",
      "Reg-LFM: ite: 103; diff: 0.001 RMSE: 0.853\n",
      "Reg-LFM: ite: 104; diff: 0.001 RMSE: 0.852\n",
      "Reg-LFM: ite: 105; diff: 0.001 RMSE: 0.852\n",
      "Reg-LFM: ite: 106; diff: 0.001 RMSE: 0.851\n",
      "Reg-LFM: ite: 107; diff: 0.001 RMSE: 0.850\n",
      "Reg-LFM: ite: 108; diff: 0.001 RMSE: 0.849\n",
      "Reg-LFM: ite: 109; diff: 0.001 RMSE: 0.848\n",
      "Reg-LFM: ite: 110; diff: 0.001 RMSE: 0.848\n",
      "Reg-LFM: ite: 111; diff: 0.001 RMSE: 0.847\n",
      "Reg-LFM: ite: 112; diff: 0.001 RMSE: 0.846\n",
      "Reg-LFM: ite: 113; diff: 0.001 RMSE: 0.846\n",
      "Reg-LFM: ite: 114; diff: 0.001 RMSE: 0.845\n",
      "Reg-LFM: ite: 115; diff: 0.001 RMSE: 0.844\n",
      "Reg-LFM: ite: 116; diff: 0.001 RMSE: 0.844\n",
      "Reg-LFM: ite: 117; diff: 0.001 RMSE: 0.843\n",
      "Reg-LFM: ite: 118; diff: 0.001 RMSE: 0.843\n",
      "Reg-LFM: ite: 119; diff: 0.001 RMSE: 0.842\n",
      "Reg-LFM: ite: 120; diff: 0.001 RMSE: 0.841\n",
      "Reg-LFM: ite: 121; diff: 0.001 RMSE: 0.841\n",
      "Reg-LFM: ite: 122; diff: 0.001 RMSE: 0.840\n",
      "Reg-LFM: ite: 123; diff: 0.001 RMSE: 0.840\n",
      "Reg-LFM: ite: 124; diff: 0.000 RMSE: 0.839\n",
      "Reg-LFM: ite: 125; diff: 0.000 RMSE: 0.839\n",
      "Reg-LFM: ite: 126; diff: 0.000 RMSE: 0.838\n",
      "Reg-LFM: ite: 127; diff: 0.000 RMSE: 0.838\n",
      "Reg-LFM: ite: 128; diff: 0.000 RMSE: 0.838\n",
      "Reg-LFM: ite: 129; diff: 0.000 RMSE: 0.837\n",
      "Reg-LFM: ite: 130; diff: 0.000 RMSE: 0.837\n",
      "Reg-LFM: ite: 131; diff: 0.000 RMSE: 0.836\n",
      "Reg-LFM: ite: 132; diff: 0.000 RMSE: 0.836\n",
      "Reg-LFM: ite: 133; diff: 0.000 RMSE: 0.836\n",
      "Reg-LFM: ite: 134; diff: 0.000 RMSE: 0.835\n",
      "Reg-LFM: ite: 135; diff: 0.000 RMSE: 0.835\n",
      "Reg-LFM: ite: 136; diff: 0.000 RMSE: 0.834\n",
      "Reg-LFM: ite: 137; diff: 0.000 RMSE: 0.834\n",
      "Reg-LFM: ite: 138; diff: 0.000 RMSE: 0.834\n",
      "Reg-LFM: ite: 139; diff: 0.000 RMSE: 0.833\n",
      "Reg-LFM: ite: 140; diff: 0.000 RMSE: 0.833\n",
      "Reg-LFM: ite: 141; diff: 0.000 RMSE: 0.833\n",
      "Reg-LFM: ite: 142; diff: 0.000 RMSE: 0.833\n",
      "Reg-LFM: ite: 143; diff: 0.000 RMSE: 0.832\n",
      "Reg-LFM: ite: 144; diff: 0.000 RMSE: 0.832\n",
      "Reg-LFM: ite: 145; diff: 0.000 RMSE: 0.832\n",
      "Reg-LFM: ite: 146; diff: 0.000 RMSE: 0.831\n",
      "Reg-LFM: ite: 147; diff: 0.000 RMSE: 0.831\n",
      "Reg-LFM: ite: 148; diff: 0.000 RMSE: 0.831\n",
      "Reg-LFM: ite: 149; diff: 0.000 RMSE: 0.831\n",
      "Reg-LFM: ite: 150; diff: 0.000 RMSE: 0.830\n",
      "Reg-LFM: ite: 151; diff: 0.000 RMSE: 0.830\n",
      "Reg-LFM: ite: 152; diff: 0.000 RMSE: 0.830\n",
      "Reg-LFM: ite: 153; diff: 0.000 RMSE: 0.830\n",
      "Reg-LFM: ite: 154; diff: 0.000 RMSE: 0.830\n",
      "Reg-LFM: ite: 155; diff: 0.000 RMSE: 0.829\n",
      "Reg-LFM: ite: 156; diff: 0.000 RMSE: 0.829\n",
      "Reg-LFM: ite: 157; diff: 0.000 RMSE: 0.829\n",
      "Reg-LFM: ite: 158; diff: 0.000 RMSE: 0.829\n",
      "Reg-LFM: ite: 159; diff: 0.000 RMSE: 0.829\n",
      "Reg-LFM: ite: 160; diff: 0.000 RMSE: 0.828\n",
      "Reg-LFM: ite: 161; diff: 0.000 RMSE: 0.828\n",
      "Reg-LFM: ite: 162; diff: 0.000 RMSE: 0.828\n",
      "Reg-LFM: ite: 163; diff: 0.000 RMSE: 0.828\n",
      "Reg-LFM: ite: 164; diff: 0.000 RMSE: 0.828\n",
      "Reg-LFM: ite: 165; diff: 0.000 RMSE: 0.827\n",
      "Reg-LFM: ite: 166; diff: 0.000 RMSE: 0.827\n",
      "Reg-LFM: ite: 167; diff: 0.000 RMSE: 0.827\n",
      "Reg-LFM: ite: 168; diff: 0.000 RMSE: 0.827\n",
      "Reg-LFM: ite: 169; diff: 0.000 RMSE: 0.827\n",
      "Reg-LFM: ite: 170; diff: 0.000 RMSE: 0.827\n",
      "Reg-LFM: ite: 171; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 172; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 173; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 174; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 175; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 176; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 177; diff: 0.000 RMSE: 0.826\n",
      "Reg-LFM: ite: 178; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 179; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 180; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 181; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 182; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 183; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 184; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 185; diff: 0.000 RMSE: 0.825\n",
      "Reg-LFM: ite: 186; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 187; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 188; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 189; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 190; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 191; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 192; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 193; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 194; diff: 0.000 RMSE: 0.824\n",
      "Reg-LFM: ite: 195; diff: 0.000 RMSE: 0.823\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Note that in `ite: 7`, `diff` = - 0.124, the loss function is getting worse, which means that `learning_rate` = 100 is too large now."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "shiing.fit(train_pair=train_pair, train_rating=train_rating_res, learning_rate=50.)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.000 RMSE: 0.823\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pred = pred + shiing.predict(test_pair)\n",
    "\n",
    "print('RMSE for glb + user_mean + LFM: %.3f' %rmse(test_rating, pred) )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for glb + user_mean + LFM: 0.972\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model with stochastic gradient descent (**SGD**)?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "class LFM(object):\n",
    "\n",
    "    def __init__(self, n_user, n_item, lam=.001, K=10, iterNum=1000, tol=1e-4):\n",
    "        self.P = np.random.randn(n_user, K)\n",
    "        self.Q = np.random.randn(n_item, K)\n",
    "        # self.index_item = []\n",
    "        # self.index_user = []\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.lam = lam\n",
    "        self.K = K\n",
    "        self.iterNum = iterNum\n",
    "        self.tol = tol\n",
    "\n",
    "    def fit(self, train_pair, train_rating, learning_rate=0.0001):\n",
    "        diff, tol = 1., self.tol\n",
    "        n_user, n_item, n_obs = self.n_user, self.n_item, len(train_pair)\n",
    "        K, iterNum, lam = self.K, self.iterNum, self.lam\n",
    "        ## store user/item index set\n",
    "        self.index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "        self.index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "        print('Fitting Reg-LFM: K: %d, lam: %.5f' %(K, lam))\n",
    "        for i in range(iterNum):\n",
    "            ## item update\n",
    "            score_old = self.rmse(test_pair=train_pair, test_rating=train_rating)\n",
    "            for j in range(n_obs):\n",
    "                user_id, item_id, rating_tmp = train_pair[j,0], train_pair[j,1], train_rating[j]\n",
    "                err_tmp = rating_tmp - np.dot(self.P[user_id,:], self.Q[item_id,:])\n",
    "                self.Q[item_id,:] = self.Q[item_id,:] + 2*learning_rate*err_tmp*self.P[user_id,:] - 2*learning_rate*lam*self.Q[item_id,:]\n",
    "                err_tmp = rating_tmp - np.dot(self.P[user_id,:], self.Q[item_id,:])\n",
    "                self.P[user_id,:] = self.P[user_id,:] + 2*learning_rate*self.Q[item_id,:] - 2*learning_rate*lam*self.P[user_id,:]\n",
    "            # compute the new rmse score\n",
    "            score_new = self.rmse(test_pair=train_pair, test_rating=train_rating)\n",
    "            diff = - score_new + score_old\n",
    "            print(\"Reg-LFM: ite: %d; diff: %.3f RMSE: %.3f\" %(i, diff, score_new))\n",
    "            if (diff < tol):\n",
    "                break\n",
    "\n",
    "    def predict(self, test_pair):\n",
    "        # predict ratings for user-item pairs\n",
    "        pred_rating = [np.dot(self.P[line[0]], self.Q[line[1]]) for line in test_pair]\n",
    "        return np.array(pred_rating)\n",
    "    \n",
    "    def rmse(self, test_pair, test_rating):\n",
    "        # report the rmse for the fitted `LFM`\n",
    "        pred_rating = self.predict(test_pair=test_pair)\n",
    "        return np.sqrt( np.mean( (pred_rating - test_rating)**2) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "## Baseline + LFM\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit correlation-based RS by residual ratings \n",
    "shiing = LFM(n_user, n_item, K=3, lam=.0001)\n",
    "shiing.fit(train_pair=train_pair, train_rating=train_rating_res, learning_rate=.01)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.731 RMSE: 1.217\n",
      "Reg-LFM: ite: 1; diff: 0.109 RMSE: 1.108\n",
      "Reg-LFM: ite: 2; diff: 0.051 RMSE: 1.057\n",
      "Reg-LFM: ite: 3; diff: 0.030 RMSE: 1.027\n",
      "Reg-LFM: ite: 4; diff: 0.020 RMSE: 1.007\n",
      "Reg-LFM: ite: 5; diff: 0.014 RMSE: 0.993\n",
      "Reg-LFM: ite: 6; diff: 0.010 RMSE: 0.983\n",
      "Reg-LFM: ite: 7; diff: 0.008 RMSE: 0.975\n",
      "Reg-LFM: ite: 8; diff: 0.006 RMSE: 0.969\n",
      "Reg-LFM: ite: 9; diff: 0.005 RMSE: 0.964\n",
      "Reg-LFM: ite: 10; diff: 0.005 RMSE: 0.959\n",
      "Reg-LFM: ite: 11; diff: 0.004 RMSE: 0.955\n",
      "Reg-LFM: ite: 12; diff: 0.003 RMSE: 0.952\n",
      "Reg-LFM: ite: 13; diff: 0.003 RMSE: 0.949\n",
      "Reg-LFM: ite: 14; diff: 0.002 RMSE: 0.946\n",
      "Reg-LFM: ite: 15; diff: 0.002 RMSE: 0.944\n",
      "Reg-LFM: ite: 16; diff: 0.002 RMSE: 0.943\n",
      "Reg-LFM: ite: 17; diff: 0.001 RMSE: 0.941\n",
      "Reg-LFM: ite: 18; diff: 0.001 RMSE: 0.940\n",
      "Reg-LFM: ite: 19; diff: 0.001 RMSE: 0.939\n",
      "Reg-LFM: ite: 20; diff: 0.001 RMSE: 0.939\n",
      "Reg-LFM: ite: 21; diff: 0.001 RMSE: 0.938\n",
      "Reg-LFM: ite: 22; diff: 0.000 RMSE: 0.938\n",
      "Reg-LFM: ite: 23; diff: 0.000 RMSE: 0.937\n",
      "Reg-LFM: ite: 24; diff: 0.000 RMSE: 0.937\n",
      "Reg-LFM: ite: 25; diff: 0.000 RMSE: 0.936\n",
      "Reg-LFM: ite: 26; diff: 0.001 RMSE: 0.936\n",
      "Reg-LFM: ite: 27; diff: 0.000 RMSE: 0.935\n",
      "Reg-LFM: ite: 28; diff: 0.000 RMSE: 0.935\n",
      "Reg-LFM: ite: 29; diff: 0.000 RMSE: 0.935\n",
      "Reg-LFM: ite: 30; diff: 0.000 RMSE: 0.935\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "shiing.fit(train_pair=train_pair, train_rating=train_rating_res, learning_rate=.001)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.006 RMSE: 0.929\n",
      "Reg-LFM: ite: 1; diff: 0.002 RMSE: 0.927\n",
      "Reg-LFM: ite: 2; diff: 0.001 RMSE: 0.926\n",
      "Reg-LFM: ite: 3; diff: 0.001 RMSE: 0.925\n",
      "Reg-LFM: ite: 4; diff: 0.000 RMSE: 0.925\n",
      "Reg-LFM: ite: 5; diff: 0.000 RMSE: 0.925\n",
      "Reg-LFM: ite: 6; diff: 0.000 RMSE: 0.925\n",
      "Reg-LFM: ite: 7; diff: 0.000 RMSE: 0.925\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "shiing.fit(train_pair=train_pair, train_rating=train_rating_res, learning_rate=.0001)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting Reg-LFM: K: 3, lam: 0.00010\n",
      "Reg-LFM: ite: 0; diff: 0.000 RMSE: 0.925\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "pred = pred + shiing.predict(test_pair)\n",
    "print('RMSE for glb + user_mean + LFM: %.3f' %rmse(test_rating, pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE for glb + user_mean + LFM: 1.590\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}