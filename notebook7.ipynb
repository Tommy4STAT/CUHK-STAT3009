{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('shiing': venv)"
  },
  "interpreter": {
   "hash": "0ba986c4ce28ee590feb069d7dff47f6c0fdeef1e6e7e0640650ca3a5af9b036"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook7: Neural Collaborative Filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install ``TensorFlow`` and ``Keras``\n",
    "- TensorFlow: https://www.tensorflow.org/install\n",
    "- Keras: Keras comes packaged with TensorFlow 2 as tensorflow.keras (https://keras.io/about/)\n",
    "- If you use Apple M1: https://naturale0.github.io/2021/01/29/setting-up-m1-mac-for-both-tensorflow-and-pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Credit: The notebook is adapted from https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recommender/neural_collaborative_filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to Deep learning with Keras\n",
    "\t- Model: input -> layers -> output\n",
    "\t- Loss: find an appropriate loss function for your problem\n",
    "\t- Algo: SGD, Adam, ...\n",
    "\t- Data: Define the model, then feed the data\n",
    "\t- metric: final evaluation or something you care"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1: [Imbalanced classification: credit card fraud detection](https://keras.io/examples/structured_data/imbalanced_classification/)\n",
    "\n",
    "- Author: fchollet\n",
    "- Date created: 2019/05/28\n",
    "- Last modified: 2020/04/17\n",
    "- Description: Demonstration of how to handle highly imbalanced classification problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# https://keras.io/examples/structured_data/imbalanced_classification/\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"/home/ben/dataset/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "## Build binary classifcation model\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "metrics = [\n",
    "    keras.metrics.BinaryAccuracy(name='acc'),\n",
    "    keras.metrics.AUC(name='auc')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping( \n",
    "    monitor='val_auc', min_delta=0, patience=5, verbose=1, \n",
    "    mode='auto', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 2s - loss: 2.2655e-06 - acc: 6.5834e-04 - auc: 0.9531 - val_loss: 0.0754 - val_acc: 0.0000e+00 - val_auc: 0.9815\n",
      "Epoch 2/30\n",
      "112/112 - 2s - loss: 1.3744e-06 - acc: 6.9345e-04 - auc: 0.9813 - val_loss: 0.0928 - val_acc: 2.4578e-04 - val_auc: 0.9878\n",
      "Epoch 3/30\n",
      "112/112 - 2s - loss: 1.1540e-06 - acc: 7.0662e-04 - auc: 0.9859 - val_loss: 0.3780 - val_acc: 6.6712e-04 - val_auc: 0.9864\n",
      "Epoch 4/30\n",
      "112/112 - 2s - loss: 1.1425e-06 - acc: 8.1634e-04 - auc: 0.9882 - val_loss: 0.1672 - val_acc: 4.9156e-04 - val_auc: 0.9861\n",
      "Epoch 5/30\n",
      "112/112 - 2s - loss: 9.6454e-07 - acc: 9.1729e-04 - auc: 0.9919 - val_loss: 0.0197 - val_acc: 6.6712e-04 - val_auc: 0.9834\n",
      "Epoch 6/30\n",
      "112/112 - 2s - loss: 1.1569e-06 - acc: 0.0012 - auc: 0.9911 - val_loss: 0.0520 - val_acc: 1.4045e-04 - val_auc: 0.9860\n",
      "Epoch 7/30\n",
      "112/112 - 2s - loss: 8.4055e-07 - acc: 8.3390e-04 - auc: 0.9945 - val_loss: 0.0449 - val_acc: 5.0912e-04 - val_auc: 0.9838\n",
      "Epoch 8/30\n",
      "112/112 - 2s - loss: 9.3953e-07 - acc: 0.0012 - auc: 0.9940 - val_loss: 0.1239 - val_acc: 5.2668e-04 - val_auc: 0.9880\n",
      "Epoch 9/30\n",
      "112/112 - 2s - loss: 8.0069e-07 - acc: 9.4801e-04 - auc: 0.9943 - val_loss: 0.0487 - val_acc: 4.9156e-04 - val_auc: 0.9880\n",
      "Epoch 10/30\n",
      "112/112 - 2s - loss: 5.8387e-07 - acc: 8.7340e-04 - auc: 0.9973 - val_loss: 0.0433 - val_acc: 4.3890e-04 - val_auc: 0.9782\n",
      "Epoch 11/30\n",
      "112/112 - 2s - loss: 4.2561e-07 - acc: 0.0013 - auc: 0.9981 - val_loss: 0.0318 - val_acc: 0.0012 - val_auc: 0.9601\n",
      "Epoch 12/30\n",
      "112/112 - 2s - loss: 6.0197e-07 - acc: 0.0013 - auc: 0.9969 - val_loss: 0.0254 - val_acc: 5.2668e-04 - val_auc: 0.9714\n",
      "Epoch 13/30\n",
      "112/112 - 2s - loss: 5.9971e-07 - acc: 0.0012 - auc: 0.9970 - val_loss: 0.0255 - val_acc: 8.4268e-04 - val_auc: 0.9593\n",
      "Epoch 14/30\n",
      "112/112 - 2s - loss: 5.0824e-07 - acc: 0.0015 - auc: 0.9978 - val_loss: 0.0178 - val_acc: 0.0016 - val_auc: 0.9489\n",
      "Epoch 15/30\n",
      "112/112 - 2s - loss: 3.9594e-07 - acc: 0.0020 - auc: 0.9984 - val_loss: 0.0103 - val_acc: 0.0034 - val_auc: 0.9377\n",
      "Epoch 16/30\n",
      "112/112 - 2s - loss: 3.2577e-07 - acc: 0.0031 - auc: 0.9988 - val_loss: 0.0179 - val_acc: 0.0035 - val_auc: 0.9608\n",
      "Epoch 17/30\n",
      "112/112 - 2s - loss: 3.6784e-07 - acc: 0.0033 - auc: 0.9988 - val_loss: 0.0496 - val_acc: 0.0044 - val_auc: 0.9540\n",
      "Epoch 18/30\n",
      "112/112 - 2s - loss: 4.2987e-07 - acc: 0.0045 - auc: 0.9982 - val_loss: 0.0834 - val_acc: 0.0037 - val_auc: 0.9727\n",
      "Epoch 19/30\n",
      "112/112 - 2s - loss: 5.8415e-07 - acc: 0.0041 - auc: 0.9967 - val_loss: 0.0098 - val_acc: 0.0073 - val_auc: 0.9515\n",
      "Epoch 20/30\n",
      "112/112 - 2s - loss: 4.0153e-07 - acc: 0.0043 - auc: 0.9986 - val_loss: 0.0135 - val_acc: 0.0073 - val_auc: 0.9696\n",
      "Epoch 21/30\n",
      "112/112 - 2s - loss: 2.7529e-07 - acc: 0.0069 - auc: 0.9990 - val_loss: 0.0319 - val_acc: 0.0093 - val_auc: 0.9689\n",
      "Epoch 22/30\n",
      "112/112 - 2s - loss: 2.3609e-07 - acc: 0.0105 - auc: 0.9991 - val_loss: 0.0317 - val_acc: 0.0110 - val_auc: 0.9691\n",
      "Epoch 23/30\n",
      "112/112 - 2s - loss: 2.9100e-06 - acc: 0.0047 - auc: 0.9900 - val_loss: 0.0955 - val_acc: 0.0010 - val_auc: 0.9697\n",
      "Epoch 24/30\n",
      "112/112 - 2s - loss: 8.8223e-07 - acc: 0.0016 - auc: 0.9970 - val_loss: 0.0249 - val_acc: 0.0022 - val_auc: 0.9440\n",
      "Epoch 25/30\n",
      "112/112 - 2s - loss: 5.8087e-07 - acc: 0.0018 - auc: 0.9982 - val_loss: 0.0201 - val_acc: 8.9535e-04 - val_auc: 0.9561\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4ec439f40>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Back to array\n",
    "pred_prob = model.predict(val_features)\n",
    "pred_label = 1*(pred_prob > .5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2: [Collaborative Filtering for Movie Recommendations](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
    "\n",
    "- Author: Siddhartha Banerjee\n",
    "- Date created: 2020/05/24\n",
    "- Last modified: 2020/05/24\n",
    "- Description: Recommending movies using a model trained on Movielens dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process the ML-100K raw data\n",
    "- check the `user_id` and `item_id`: mapping `item_id` to a continuous sequence based on `sklean.preprocessing`\n",
    "- use `sklearn.model_selection.train_test_split` to generate `train` and `test` dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset/ml-latest-small/ratings.csv')\n",
    "del df['timestamp']\n",
    "## mapping \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['movieId'] = le.fit_transform(df['movieId'])\n",
    "df['userId'] = le.fit_transform(df['userId'])\n",
    "## generate train / test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dtrain, dtest = train_test_split(df, test_size=0.33, random_state=42)\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# tran_pair, train_rating\n",
    "train_pair = dtrain[['userId', 'movieId']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# test_pair\n",
    "test_pair = dtest[['userId', 'movieId']].values\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the model\n",
    "We embed both users and movies in to 50-dimensional vectors.\n",
    "\n",
    "The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "class LFactorNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(LFactorNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.glb_bias = tf.Variable(0., trainable=True) \n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias + self.glb_bias\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "model = LFactorNet(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3), \n",
    "    loss=tf.keras.losses.MeanSquaredError(), \n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping( \n",
    "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
    "    mode='auto', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_pair,\n",
    "    y=train_rating,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_split=.2,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "845/845 [==============================] - 4s 4ms/step - loss: 6.2727 - mae: 2.0559 - rmse: 2.5045 - val_loss: 1.1799 - val_mae: 0.8613 - val_rmse: 1.0861\n",
      "Epoch 2/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 1.0903 - mae: 0.8272 - rmse: 1.0440 - val_loss: 1.8135 - val_mae: 1.1489 - val_rmse: 1.3465\n",
      "Epoch 3/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9792 - mae: 0.7829 - rmse: 0.9894 - val_loss: 1.5752 - val_mae: 1.0604 - val_rmse: 1.2549\n",
      "Epoch 4/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9154 - mae: 0.7513 - rmse: 0.9565 - val_loss: 1.4885 - val_mae: 1.0277 - val_rmse: 1.2199\n",
      "Epoch 5/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8820 - mae: 0.7349 - rmse: 0.9389 - val_loss: 1.4202 - val_mae: 0.9997 - val_rmse: 1.1915\n",
      "Epoch 6/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8815 - mae: 0.7341 - rmse: 0.9385 - val_loss: 1.2981 - val_mae: 0.9423 - val_rmse: 1.1390\n",
      "Epoch 7/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8874 - mae: 0.7367 - rmse: 0.9416 - val_loss: 1.3224 - val_mae: 0.9537 - val_rmse: 1.1496\n",
      "Epoch 8/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8896 - mae: 0.7387 - rmse: 0.9427 - val_loss: 1.4351 - val_mae: 0.9993 - val_rmse: 1.1975\n",
      "Epoch 9/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9220 - mae: 0.7514 - rmse: 0.9596 - val_loss: 1.3113 - val_mae: 0.9437 - val_rmse: 1.1446\n",
      "Epoch 10/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9399 - mae: 0.7590 - rmse: 0.9688 - val_loss: 1.5110 - val_mae: 1.0282 - val_rmse: 1.2287\n",
      "Epoch 11/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9262 - mae: 0.7535 - rmse: 0.9616 - val_loss: 1.4428 - val_mae: 0.9978 - val_rmse: 1.2005\n",
      "Epoch 12/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9075 - mae: 0.7457 - rmse: 0.9518 - val_loss: 1.3343 - val_mae: 0.9542 - val_rmse: 1.1544\n",
      "Epoch 13/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9144 - mae: 0.7472 - rmse: 0.9554 - val_loss: 1.3080 - val_mae: 0.9417 - val_rmse: 1.1429\n",
      "Epoch 14/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9229 - mae: 0.7518 - rmse: 0.9597 - val_loss: 1.2103 - val_mae: 0.9003 - val_rmse: 1.0993\n",
      "Epoch 15/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8991 - mae: 0.7423 - rmse: 0.9472 - val_loss: 1.3433 - val_mae: 0.9599 - val_rmse: 1.1581\n",
      "Epoch 16/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9053 - mae: 0.7443 - rmse: 0.9504 - val_loss: 1.2855 - val_mae: 0.9276 - val_rmse: 1.1329\n",
      "Epoch 17/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9050 - mae: 0.7418 - rmse: 0.9501 - val_loss: 1.2211 - val_mae: 0.8967 - val_rmse: 1.1040\n",
      "Epoch 18/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8991 - mae: 0.7405 - rmse: 0.9470 - val_loss: 1.3009 - val_mae: 0.9312 - val_rmse: 1.1395\n",
      "Epoch 19/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8746 - mae: 0.7306 - rmse: 0.9339 - val_loss: 1.2249 - val_mae: 0.8991 - val_rmse: 1.1056\n",
      "Epoch 20/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8954 - mae: 0.7394 - rmse: 0.9449 - val_loss: 1.2378 - val_mae: 0.9029 - val_rmse: 1.1114\n",
      "Epoch 21/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8962 - mae: 0.7407 - rmse: 0.9453 - val_loss: 1.3878 - val_mae: 0.9689 - val_rmse: 1.1769\n",
      "Epoch 22/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8884 - mae: 0.7366 - rmse: 0.9411 - val_loss: 1.2716 - val_mae: 0.9186 - val_rmse: 1.1264\n",
      "Epoch 23/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8929 - mae: 0.7382 - rmse: 0.9434 - val_loss: 1.2797 - val_mae: 0.9232 - val_rmse: 1.1299\n",
      "Epoch 24/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8700 - mae: 0.7288 - rmse: 0.9311 - val_loss: 1.2133 - val_mae: 0.8953 - val_rmse: 1.1001\n",
      "Epoch 25/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8856 - mae: 0.7349 - rmse: 0.9394 - val_loss: 1.3066 - val_mae: 0.9363 - val_rmse: 1.1417\n",
      "Epoch 26/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8529 - mae: 0.7204 - rmse: 0.9218 - val_loss: 1.1922 - val_mae: 0.8854 - val_rmse: 1.0904\n",
      "Epoch 27/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8718 - mae: 0.7269 - rmse: 0.9319 - val_loss: 1.1964 - val_mae: 0.8870 - val_rmse: 1.0923\n",
      "Epoch 28/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.9030 - mae: 0.7444 - rmse: 0.9484 - val_loss: 1.2834 - val_mae: 0.9236 - val_rmse: 1.1313\n",
      "Epoch 29/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8732 - mae: 0.7305 - rmse: 0.9325 - val_loss: 1.1608 - val_mae: 0.8674 - val_rmse: 1.0757\n",
      "Epoch 30/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8698 - mae: 0.7292 - rmse: 0.9307 - val_loss: 1.2349 - val_mae: 0.9028 - val_rmse: 1.1096\n",
      "Epoch 31/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8906 - mae: 0.7367 - rmse: 0.9417 - val_loss: 1.1393 - val_mae: 0.8617 - val_rmse: 1.0656\n",
      "Epoch 32/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8907 - mae: 0.7373 - rmse: 0.9417 - val_loss: 1.0969 - val_mae: 0.8410 - val_rmse: 1.0455\n",
      "Epoch 33/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8693 - mae: 0.7267 - rmse: 0.9302 - val_loss: 1.1109 - val_mae: 0.8480 - val_rmse: 1.0521\n",
      "Epoch 34/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8702 - mae: 0.7278 - rmse: 0.9307 - val_loss: 1.1285 - val_mae: 0.8561 - val_rmse: 1.0604\n",
      "Epoch 35/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8671 - mae: 0.7262 - rmse: 0.9289 - val_loss: 1.0258 - val_mae: 0.8039 - val_rmse: 1.0107\n",
      "Epoch 36/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8705 - mae: 0.7240 - rmse: 0.9307 - val_loss: 1.3749 - val_mae: 0.9647 - val_rmse: 1.1707\n",
      "Epoch 37/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9066 - mae: 0.7457 - rmse: 0.9499 - val_loss: 1.0693 - val_mae: 0.8259 - val_rmse: 1.0319\n",
      "Epoch 38/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8996 - mae: 0.7395 - rmse: 0.9461 - val_loss: 1.2933 - val_mae: 0.9277 - val_rmse: 1.1353\n",
      "Epoch 39/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.9054 - mae: 0.7423 - rmse: 0.9492 - val_loss: 1.2039 - val_mae: 0.8888 - val_rmse: 1.0952\n",
      "Epoch 40/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8858 - mae: 0.7337 - rmse: 0.9387 - val_loss: 1.1587 - val_mae: 0.8672 - val_rmse: 1.0743\n",
      "Epoch 41/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8986 - mae: 0.7404 - rmse: 0.9454 - val_loss: 1.1342 - val_mae: 0.8571 - val_rmse: 1.0627\n",
      "Epoch 42/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8654 - mae: 0.7239 - rmse: 0.9277 - val_loss: 1.2057 - val_mae: 0.8898 - val_rmse: 1.0958\n",
      "Epoch 43/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8874 - mae: 0.7365 - rmse: 0.9394 - val_loss: 1.1656 - val_mae: 0.8689 - val_rmse: 1.0774\n",
      "Epoch 44/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9018 - mae: 0.7416 - rmse: 0.9470 - val_loss: 1.0893 - val_mae: 0.8351 - val_rmse: 1.0413\n",
      "Epoch 45/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8762 - mae: 0.7283 - rmse: 0.9333 - val_loss: 1.0179 - val_mae: 0.8009 - val_rmse: 1.0064\n",
      "Epoch 46/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8674 - mae: 0.7251 - rmse: 0.9286 - val_loss: 1.2023 - val_mae: 0.8890 - val_rmse: 1.0941\n",
      "Epoch 47/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8572 - mae: 0.7226 - rmse: 0.9230 - val_loss: 1.1393 - val_mae: 0.8582 - val_rmse: 1.0649\n",
      "Epoch 48/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8798 - mae: 0.7309 - rmse: 0.9352 - val_loss: 1.0849 - val_mae: 0.8314 - val_rmse: 1.0390\n",
      "Epoch 49/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8741 - mae: 0.7277 - rmse: 0.9321 - val_loss: 1.1531 - val_mae: 0.8630 - val_rmse: 1.0713\n",
      "Epoch 50/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8828 - mae: 0.7322 - rmse: 0.9366 - val_loss: 1.2252 - val_mae: 0.8943 - val_rmse: 1.1044\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "## make prediction\n",
    "pred_rating = model.predict(test_pair).flatten()\n",
    "print(pred_rating)\n",
    "print('rmse: LFactorNet: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.9852332  1.7486626  0.33845353 ... 2.354248   1.447402   2.3437057 ]\n",
      "rmse: LFactorNet: 1.920\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 3: Neural Collaborative Filtering in MovieLens dataset\n",
    "\n",
    "\tCredit: The notebook is adapted from https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recommender/neural_collaborative_filtering"
   ],
   "metadata": {}
  }
 ]
}