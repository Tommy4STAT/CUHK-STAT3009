{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('shiing': venv)"
  },
  "interpreter": {
   "hash": "0ba986c4ce28ee590feb069d7dff47f6c0fdeef1e6e7e0640650ca3a5af9b036"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CUHK [STAT3009](https://www.bendai.org/STAT3009/) Notebook7: Neural Collaborative Filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install ``TensorFlow`` and ``Keras``\n",
    "- TensorFlow: https://www.tensorflow.org/install\n",
    "- Keras: Keras comes packaged with TensorFlow 2 as tensorflow.keras (https://keras.io/about/)\n",
    "- If you use Apple M1: https://naturale0.github.io/2021/01/29/setting-up-m1-mac-for-both-tensorflow-and-pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Credit: The notebook is adapted from https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recommender/neural_collaborative_filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to Deep learning with Keras\n",
    "\t- Model: input -> layers -> output\n",
    "\t- Loss: find an appropriate loss function for your problem\n",
    "\t- Algo: SGD, Adam, ...\n",
    "\t- Data: Define the model, then feed the data\n",
    "\t- metric: final evaluation or something you care"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1: [Imbalanced classification: credit card fraud detection](https://keras.io/examples/structured_data/imbalanced_classification/)\n",
    "\n",
    "- Author: fchollet\n",
    "- Date created: 2019/05/28\n",
    "- Last modified: 2020/04/17\n",
    "- Description: Demonstration of how to handle highly imbalanced classification problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# https://keras.io/examples/structured_data/imbalanced_classification/\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"/home/ben/dataset/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## Build binary classifcation model\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "metrics = [\n",
    "    keras.metrics.BinaryAccuracy(name='acc'),\n",
    "    keras.metrics.AUC(name='auc')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping( \n",
    "    monitor='val_auc', min_delta=0, patience=5, verbose=1, \n",
    "    mode='auto', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 2s - loss: 0.0152 - acc: 0.9960 - auc: 0.8984 - val_loss: 0.0031 - val_acc: 0.9995 - val_auc: 0.9262\n",
      "Epoch 2/30\n",
      "112/112 - 1s - loss: 0.0036 - acc: 0.9992 - auc: 0.9592 - val_loss: 0.0036 - val_acc: 0.9996 - val_auc: 0.8998\n",
      "Epoch 3/30\n",
      "112/112 - 1s - loss: 0.0031 - acc: 0.9993 - auc: 0.9571 - val_loss: 0.0033 - val_acc: 0.9996 - val_auc: 0.9130\n",
      "Epoch 4/30\n",
      "112/112 - 2s - loss: 0.0029 - acc: 0.9993 - auc: 0.9668 - val_loss: 0.0035 - val_acc: 0.9996 - val_auc: 0.8997\n",
      "Epoch 5/30\n",
      "112/112 - 1s - loss: 0.0028 - acc: 0.9993 - auc: 0.9704 - val_loss: 0.0034 - val_acc: 0.9996 - val_auc: 0.8865\n",
      "Epoch 6/30\n",
      "112/112 - 1s - loss: 0.0026 - acc: 0.9993 - auc: 0.9730 - val_loss: 0.0026 - val_acc: 0.9996 - val_auc: 0.9329\n",
      "Epoch 7/30\n",
      "112/112 - 1s - loss: 0.0025 - acc: 0.9994 - auc: 0.9718 - val_loss: 0.0044 - val_acc: 0.9996 - val_auc: 0.8998\n",
      "Epoch 8/30\n",
      "112/112 - 1s - loss: 0.0026 - acc: 0.9994 - auc: 0.9730 - val_loss: 0.0028 - val_acc: 0.9996 - val_auc: 0.9128\n",
      "Epoch 9/30\n",
      "112/112 - 1s - loss: 0.0024 - acc: 0.9994 - auc: 0.9695 - val_loss: 0.0036 - val_acc: 0.9996 - val_auc: 0.9065\n",
      "Epoch 10/30\n",
      "112/112 - 1s - loss: 0.0027 - acc: 0.9994 - auc: 0.9706 - val_loss: 0.0037 - val_acc: 0.9996 - val_auc: 0.9130\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff65bdb07f0>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Back to array\n",
    "pred_prob = model.predict(val_features)\n",
    "pred_label = 1*(pred_prob > .5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2: [Collaborative Filtering for Movie Recommendations](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
    "\n",
    "- Author: Siddhartha Banerjee\n",
    "- Date created: 2020/05/24\n",
    "- Last modified: 2020/05/24\n",
    "- Description: Recommending movies using a model trained on Movielens dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process the ML-100K raw data\n",
    "- check the `user_id` and `item_id`: mapping `item_id` to a continuous sequence based on `sklean.preprocessing`\n",
    "- use `sklearn.model_selection.train_test_split` to generate `train` and `test` dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset/ml-latest-small/ratings.csv')\n",
    "del df['timestamp']\n",
    "## mapping \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['movieId'] = le.fit_transform(df['movieId'])\n",
    "df['userId'] = le.fit_transform(df['userId'])\n",
    "## generate train / test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dtrain, dtest = train_test_split(df, test_size=0.33, random_state=42)\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# tran_pair, train_rating\n",
    "train_pair = dtrain[['userId', 'movieId']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# test_pair\n",
    "test_pair = dtest[['userId', 'movieId']].values\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the model\n",
    "We embed both users and movies in to 50-dimensional vectors.\n",
    "\n",
    "The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class LFactorNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(LFactorNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.glb_bias = tf.Variable(0., trainable=True) \n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias + self.glb_bias\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = LFactorNet(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3), \n",
    "    loss=tf.keras.losses.MeanSquaredError(), \n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping( \n",
    "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
    "    mode='auto', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_pair,\n",
    "    y=train_rating,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_split=.2,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 6.1625 - mae: 1.8174 - rmse: 2.2690 - val_loss: 2.2280 - val_mae: 0.8652 - val_rmse: 1.0799\n",
      "Epoch 2/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 1.9292 - mae: 0.8411 - rmse: 1.0469 - val_loss: 1.8998 - val_mae: 0.8542 - val_rmse: 1.0609\n",
      "Epoch 3/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 1.7552 - mae: 0.8094 - rmse: 1.0124 - val_loss: 1.7486 - val_mae: 0.8173 - val_rmse: 1.0202\n",
      "Epoch 4/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 1.6177 - mae: 0.7777 - rmse: 0.9757 - val_loss: 1.6147 - val_mae: 0.7753 - val_rmse: 0.9823\n",
      "Epoch 5/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 1.4673 - mae: 0.7475 - rmse: 0.9413 - val_loss: 1.4885 - val_mae: 0.7733 - val_rmse: 0.9716\n",
      "Epoch 6/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 1.3111 - mae: 0.7206 - rmse: 0.9118 - val_loss: 1.3167 - val_mae: 0.7412 - val_rmse: 0.9408\n",
      "Epoch 7/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 1.1561 - mae: 0.7000 - rmse: 0.8887 - val_loss: 1.1763 - val_mae: 0.7303 - val_rmse: 0.9273\n",
      "Epoch 8/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 1.0003 - mae: 0.6805 - rmse: 0.8670 - val_loss: 1.0214 - val_mae: 0.7163 - val_rmse: 0.9120\n",
      "Epoch 9/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8548 - mae: 0.6653 - rmse: 0.8508 - val_loss: 0.8878 - val_mae: 0.7071 - val_rmse: 0.9027\n",
      "Epoch 10/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.7321 - mae: 0.6494 - rmse: 0.8363 - val_loss: 0.8006 - val_mae: 0.6921 - val_rmse: 0.8924\n",
      "Epoch 11/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6841 - mae: 0.6365 - rmse: 0.8266 - val_loss: 0.7910 - val_mae: 0.6866 - val_rmse: 0.8894\n",
      "Epoch 12/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6736 - mae: 0.6300 - rmse: 0.8207 - val_loss: 0.7880 - val_mae: 0.6854 - val_rmse: 0.8877\n",
      "Epoch 13/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6656 - mae: 0.6253 - rmse: 0.8158 - val_loss: 0.7858 - val_mae: 0.6832 - val_rmse: 0.8865\n",
      "Epoch 14/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6588 - mae: 0.6209 - rmse: 0.8116 - val_loss: 0.7843 - val_mae: 0.6826 - val_rmse: 0.8856\n",
      "Epoch 15/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6528 - mae: 0.6174 - rmse: 0.8079 - val_loss: 0.7834 - val_mae: 0.6821 - val_rmse: 0.8850\n",
      "Epoch 16/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6477 - mae: 0.6143 - rmse: 0.8046 - val_loss: 0.7832 - val_mae: 0.6811 - val_rmse: 0.8847\n",
      "Epoch 17/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6433 - mae: 0.6113 - rmse: 0.8017 - val_loss: 0.7831 - val_mae: 0.6814 - val_rmse: 0.8846\n",
      "Epoch 18/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6396 - mae: 0.6089 - rmse: 0.7991 - val_loss: 0.7835 - val_mae: 0.6811 - val_rmse: 0.8844\n",
      "Epoch 19/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6350 - mae: 0.6065 - rmse: 0.7966 - val_loss: 0.7826 - val_mae: 0.6803 - val_rmse: 0.8845\n",
      "Epoch 20/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6331 - mae: 0.6044 - rmse: 0.7945 - val_loss: 0.7829 - val_mae: 0.6805 - val_rmse: 0.8846\n",
      "Epoch 21/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6289 - mae: 0.6025 - rmse: 0.7925 - val_loss: 0.7833 - val_mae: 0.6807 - val_rmse: 0.8847\n",
      "Epoch 22/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6268 - mae: 0.6007 - rmse: 0.7907 - val_loss: 0.7835 - val_mae: 0.6808 - val_rmse: 0.8848\n",
      "Epoch 23/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6239 - mae: 0.5990 - rmse: 0.7889 - val_loss: 0.7847 - val_mae: 0.6813 - val_rmse: 0.8851\n",
      "Epoch 24/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6215 - mae: 0.5976 - rmse: 0.7874 - val_loss: 0.7851 - val_mae: 0.6805 - val_rmse: 0.8854\n",
      "Epoch 25/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6191 - mae: 0.5958 - rmse: 0.7859 - val_loss: 0.7851 - val_mae: 0.6822 - val_rmse: 0.8858\n",
      "Epoch 26/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6170 - mae: 0.5948 - rmse: 0.7846 - val_loss: 0.7859 - val_mae: 0.6811 - val_rmse: 0.8860\n",
      "Epoch 27/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6152 - mae: 0.5934 - rmse: 0.7834 - val_loss: 0.7868 - val_mae: 0.6818 - val_rmse: 0.8863\n",
      "Epoch 28/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6132 - mae: 0.5923 - rmse: 0.7822 - val_loss: 0.7877 - val_mae: 0.6819 - val_rmse: 0.8866\n",
      "Epoch 29/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6114 - mae: 0.5911 - rmse: 0.7811 - val_loss: 0.7879 - val_mae: 0.6821 - val_rmse: 0.8869\n",
      "Epoch 30/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6096 - mae: 0.5900 - rmse: 0.7801 - val_loss: 0.7898 - val_mae: 0.6824 - val_rmse: 0.8872\n",
      "Epoch 31/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6084 - mae: 0.5890 - rmse: 0.7792 - val_loss: 0.7893 - val_mae: 0.6832 - val_rmse: 0.8877\n",
      "Epoch 32/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6075 - mae: 0.5882 - rmse: 0.7783 - val_loss: 0.7902 - val_mae: 0.6829 - val_rmse: 0.8881\n",
      "Epoch 33/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6053 - mae: 0.5872 - rmse: 0.7774 - val_loss: 0.7915 - val_mae: 0.6837 - val_rmse: 0.8885\n",
      "Epoch 34/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6052 - mae: 0.5864 - rmse: 0.7766 - val_loss: 0.7902 - val_mae: 0.6840 - val_rmse: 0.8889\n",
      "Epoch 35/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6029 - mae: 0.5855 - rmse: 0.7758 - val_loss: 0.7933 - val_mae: 0.6850 - val_rmse: 0.8894\n",
      "Epoch 36/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6023 - mae: 0.5851 - rmse: 0.7751 - val_loss: 0.7923 - val_mae: 0.6835 - val_rmse: 0.8897\n",
      "Epoch 37/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6011 - mae: 0.5841 - rmse: 0.7745 - val_loss: 0.7949 - val_mae: 0.6843 - val_rmse: 0.8900\n",
      "Epoch 38/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.6006 - mae: 0.5834 - rmse: 0.7738 - val_loss: 0.7932 - val_mae: 0.6851 - val_rmse: 0.8904\n",
      "Epoch 39/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5990 - mae: 0.5829 - rmse: 0.7733 - val_loss: 0.7967 - val_mae: 0.6844 - val_rmse: 0.8907\n",
      "Epoch 40/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5989 - mae: 0.5821 - rmse: 0.7727 - val_loss: 0.7946 - val_mae: 0.6853 - val_rmse: 0.8913\n",
      "Epoch 41/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5971 - mae: 0.5817 - rmse: 0.7722 - val_loss: 0.7975 - val_mae: 0.6852 - val_rmse: 0.8916\n",
      "Epoch 42/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5970 - mae: 0.5811 - rmse: 0.7716 - val_loss: 0.7977 - val_mae: 0.6850 - val_rmse: 0.8920\n",
      "Epoch 43/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5966 - mae: 0.5805 - rmse: 0.7712 - val_loss: 0.7981 - val_mae: 0.6857 - val_rmse: 0.8923\n",
      "Epoch 44/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5948 - mae: 0.5799 - rmse: 0.7707 - val_loss: 0.7994 - val_mae: 0.6864 - val_rmse: 0.8927\n",
      "Epoch 45/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5953 - mae: 0.5794 - rmse: 0.7703 - val_loss: 0.8013 - val_mae: 0.6871 - val_rmse: 0.8932\n",
      "Epoch 46/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5934 - mae: 0.5790 - rmse: 0.7699 - val_loss: 0.7994 - val_mae: 0.6867 - val_rmse: 0.8934\n",
      "Epoch 47/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5940 - mae: 0.5785 - rmse: 0.7695 - val_loss: 0.7998 - val_mae: 0.6872 - val_rmse: 0.8938\n",
      "Epoch 48/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5933 - mae: 0.5780 - rmse: 0.7691 - val_loss: 0.8005 - val_mae: 0.6872 - val_rmse: 0.8942\n",
      "Epoch 49/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5925 - mae: 0.5777 - rmse: 0.7688 - val_loss: 0.8006 - val_mae: 0.6877 - val_rmse: 0.8946\n",
      "Epoch 50/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.5913 - mae: 0.5772 - rmse: 0.7685 - val_loss: 0.8017 - val_mae: 0.6880 - val_rmse: 0.8948\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "## make prediction\n",
    "pred_rating = model.predict(test_pair).flatten()\n",
    "print(pred_rating)\n",
    "print('rmse: LFactorNet: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.749611  3.44922   2.1344523 ... 4.125555  3.2430491 4.173697 ]\n",
      "rmse: LFactorNet: 0.892\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 3: Neural Collaborative Filtering in MovieLens dataset\n",
    "\n",
    "Credit: The notebook is adapted from https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recommender/neural_collaborative_filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process the ML-100K raw data\n",
    "- check the `user_id` and `item_id`: mapping `item_id` to a continuous sequence based on `sklean.preprocessing`\n",
    "- use `sklearn.model_selection.train_test_split` to generate `train` and `test` dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset/ml-latest-small/ratings.csv')\n",
    "del df['timestamp']\n",
    "## mapping \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['movieId'] = le.fit_transform(df['movieId'])\n",
    "df['userId'] = le.fit_transform(df['userId'])\n",
    "## generate train / test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dtrain, dtest = train_test_split(df, test_size=0.33, random_state=42)\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tran_pair, train_rating\n",
    "train_pair = dtrain[['userId', 'movieId']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "# test_pair\n",
    "test_pair = dtest[['userId', 'movieId']].values\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create NCF Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Input, Dropout, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import SVG\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "class NCF(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(NCF, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
    "        )\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
    "        )\n",
    "        self.concatenate = layers.Concatenate()\n",
    "        self.dense1 = layers.Dense(100, name='fc-1', activation='relu')\n",
    "        self.dense2 = layers.Dense(50, name='fc-2', activation='relu')\n",
    "        self.dense3 = layers.Dense(1, name='fc-3', activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        concatted_vec = self.concatenate([user_vector, movie_vector])\n",
    "        fc_1 = self.dense1(concatted_vec)\n",
    "        fc_2 = self.dense2(fc_1)\n",
    "        fc_3 = self.dense3(fc_2)\n",
    "        return fc_3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select `loss function`, `metrics`, `algorithm`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "model = NCF(num_users=n_user, num_movies=n_item, embedding_size=50)\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3), \n",
    "    loss=tf.keras.losses.MeanSquaredError(), \n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping( \n",
    "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
    "    mode='auto', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_pair,\n",
    "    y=train_rating,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_split=.2,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "845/845 [==============================] - 4s 4ms/step - loss: 1.5728 - mae: 0.8344 - rmse: 1.1406 - val_loss: 0.9819 - val_mae: 0.7092 - val_rmse: 0.9188\n",
      "Epoch 2/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.9226 - mae: 0.6944 - rmse: 0.8945 - val_loss: 0.9458 - val_mae: 0.7053 - val_rmse: 0.9121\n",
      "Epoch 3/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8897 - mae: 0.6843 - rmse: 0.8827 - val_loss: 0.9183 - val_mae: 0.6914 - val_rmse: 0.9046\n",
      "Epoch 4/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8638 - mae: 0.6737 - rmse: 0.8697 - val_loss: 0.9091 - val_mae: 0.6895 - val_rmse: 0.8987\n",
      "Epoch 5/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8588 - mae: 0.6692 - rmse: 0.8629 - val_loss: 0.9031 - val_mae: 0.6912 - val_rmse: 0.8931\n",
      "Epoch 6/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8476 - mae: 0.6616 - rmse: 0.8542 - val_loss: 0.9075 - val_mae: 0.6873 - val_rmse: 0.8906\n",
      "Epoch 7/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8412 - mae: 0.6542 - rmse: 0.8460 - val_loss: 0.9103 - val_mae: 0.6788 - val_rmse: 0.8870\n",
      "Epoch 8/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8249 - mae: 0.6488 - rmse: 0.8381 - val_loss: 0.9106 - val_mae: 0.6817 - val_rmse: 0.8893\n",
      "Epoch 9/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8197 - mae: 0.6453 - rmse: 0.8341 - val_loss: 0.9049 - val_mae: 0.6803 - val_rmse: 0.8849\n",
      "Epoch 10/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8154 - mae: 0.6416 - rmse: 0.8295 - val_loss: 0.9182 - val_mae: 0.6802 - val_rmse: 0.8863\n",
      "Epoch 11/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8122 - mae: 0.6396 - rmse: 0.8260 - val_loss: 0.9183 - val_mae: 0.6930 - val_rmse: 0.8904\n",
      "Epoch 12/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8097 - mae: 0.6383 - rmse: 0.8253 - val_loss: 0.9038 - val_mae: 0.6793 - val_rmse: 0.8842\n",
      "Epoch 13/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8060 - mae: 0.6355 - rmse: 0.8218 - val_loss: 0.8984 - val_mae: 0.6805 - val_rmse: 0.8811\n",
      "Epoch 14/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8054 - mae: 0.6347 - rmse: 0.8199 - val_loss: 0.9155 - val_mae: 0.6795 - val_rmse: 0.8818\n",
      "Epoch 15/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8020 - mae: 0.6326 - rmse: 0.8174 - val_loss: 0.9124 - val_mae: 0.6750 - val_rmse: 0.8845\n",
      "Epoch 16/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.7991 - mae: 0.6322 - rmse: 0.8160 - val_loss: 0.9134 - val_mae: 0.6737 - val_rmse: 0.8837\n",
      "Epoch 17/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.8004 - mae: 0.6287 - rmse: 0.8126 - val_loss: 0.9231 - val_mae: 0.6761 - val_rmse: 0.8891\n",
      "Epoch 18/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7950 - mae: 0.6271 - rmse: 0.8099 - val_loss: 0.9284 - val_mae: 0.6752 - val_rmse: 0.8868\n",
      "Epoch 19/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7911 - mae: 0.6264 - rmse: 0.8085 - val_loss: 0.9544 - val_mae: 0.6821 - val_rmse: 0.9015\n",
      "Epoch 20/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.7907 - mae: 0.6245 - rmse: 0.8064 - val_loss: 0.9175 - val_mae: 0.6802 - val_rmse: 0.8841\n",
      "Epoch 21/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.7919 - mae: 0.6231 - rmse: 0.8053 - val_loss: 0.9337 - val_mae: 0.6864 - val_rmse: 0.8885\n",
      "Epoch 22/50\n",
      "845/845 [==============================] - 3s 3ms/step - loss: 0.7909 - mae: 0.6227 - rmse: 0.8038 - val_loss: 0.9356 - val_mae: 0.6763 - val_rmse: 0.8869\n",
      "Epoch 23/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7868 - mae: 0.6196 - rmse: 0.8017 - val_loss: 0.9341 - val_mae: 0.6818 - val_rmse: 0.8888\n",
      "Epoch 24/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7945 - mae: 0.6203 - rmse: 0.8014 - val_loss: 0.9521 - val_mae: 0.6801 - val_rmse: 0.8945\n",
      "Epoch 25/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7887 - mae: 0.6191 - rmse: 0.7988 - val_loss: 0.9378 - val_mae: 0.6844 - val_rmse: 0.8859\n",
      "Epoch 26/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7890 - mae: 0.6187 - rmse: 0.7980 - val_loss: 0.9582 - val_mae: 0.6794 - val_rmse: 0.8958\n",
      "Epoch 27/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7815 - mae: 0.6165 - rmse: 0.7955 - val_loss: 0.9491 - val_mae: 0.6759 - val_rmse: 0.8919\n",
      "Epoch 28/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7840 - mae: 0.6167 - rmse: 0.7968 - val_loss: 0.9514 - val_mae: 0.6779 - val_rmse: 0.8894\n",
      "Epoch 29/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7836 - mae: 0.6148 - rmse: 0.7958 - val_loss: 0.9401 - val_mae: 0.6810 - val_rmse: 0.8885\n",
      "Epoch 30/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7830 - mae: 0.6150 - rmse: 0.7945 - val_loss: 0.9625 - val_mae: 0.6798 - val_rmse: 0.8985\n",
      "Epoch 31/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7846 - mae: 0.6150 - rmse: 0.7950 - val_loss: 0.9492 - val_mae: 0.6765 - val_rmse: 0.8892\n",
      "Epoch 32/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7796 - mae: 0.6129 - rmse: 0.7927 - val_loss: 0.9498 - val_mae: 0.6788 - val_rmse: 0.8892\n",
      "Epoch 33/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7778 - mae: 0.6124 - rmse: 0.7917 - val_loss: 0.9527 - val_mae: 0.6810 - val_rmse: 0.8907\n",
      "Epoch 34/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7882 - mae: 0.6142 - rmse: 0.7936 - val_loss: 0.9727 - val_mae: 0.6909 - val_rmse: 0.8976\n",
      "Epoch 35/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7829 - mae: 0.6122 - rmse: 0.7920 - val_loss: 0.9717 - val_mae: 0.6803 - val_rmse: 0.8929\n",
      "Epoch 36/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7841 - mae: 0.6119 - rmse: 0.7909 - val_loss: 0.9565 - val_mae: 0.6785 - val_rmse: 0.8928\n",
      "Epoch 37/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7836 - mae: 0.6110 - rmse: 0.7903 - val_loss: 0.9770 - val_mae: 0.6856 - val_rmse: 0.8956\n",
      "Epoch 38/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7883 - mae: 0.6103 - rmse: 0.7892 - val_loss: 0.9915 - val_mae: 0.6835 - val_rmse: 0.9048\n",
      "Epoch 39/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7904 - mae: 0.6095 - rmse: 0.7892 - val_loss: 0.9820 - val_mae: 0.6824 - val_rmse: 0.8983\n",
      "Epoch 40/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7905 - mae: 0.6081 - rmse: 0.7875 - val_loss: 0.9802 - val_mae: 0.6854 - val_rmse: 0.8950\n",
      "Epoch 41/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7956 - mae: 0.6083 - rmse: 0.7870 - val_loss: 0.9729 - val_mae: 0.6806 - val_rmse: 0.8933\n",
      "Epoch 42/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.7986 - mae: 0.6073 - rmse: 0.7849 - val_loss: 0.9889 - val_mae: 0.6880 - val_rmse: 0.8948\n",
      "Epoch 43/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8016 - mae: 0.6087 - rmse: 0.7869 - val_loss: 0.9925 - val_mae: 0.6792 - val_rmse: 0.8960\n",
      "Epoch 44/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8006 - mae: 0.6059 - rmse: 0.7838 - val_loss: 1.0127 - val_mae: 0.6798 - val_rmse: 0.9018\n",
      "Epoch 45/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8014 - mae: 0.6065 - rmse: 0.7851 - val_loss: 1.0064 - val_mae: 0.6899 - val_rmse: 0.9028\n",
      "Epoch 46/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8070 - mae: 0.6049 - rmse: 0.7832 - val_loss: 1.0114 - val_mae: 0.6826 - val_rmse: 0.8975\n",
      "Epoch 47/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8061 - mae: 0.6058 - rmse: 0.7841 - val_loss: 1.0253 - val_mae: 0.6902 - val_rmse: 0.9003\n",
      "Epoch 48/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8059 - mae: 0.6043 - rmse: 0.7824 - val_loss: 1.0253 - val_mae: 0.6872 - val_rmse: 0.9090\n",
      "Epoch 49/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8032 - mae: 0.6055 - rmse: 0.7832 - val_loss: 1.0035 - val_mae: 0.6953 - val_rmse: 0.9010\n",
      "Epoch 50/50\n",
      "845/845 [==============================] - 3s 4ms/step - loss: 0.8015 - mae: 0.6034 - rmse: 0.7816 - val_loss: 1.0006 - val_mae: 0.6821 - val_rmse: 0.8937\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "## make prediction\n",
    "pred_rating = model.predict(test_pair).flatten()\n",
    "print(pred_rating)\n",
    "print('rmse: LFactorNet: %.3f' %np.sqrt(np.mean((pred_rating - test_rating)**2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.9420114 3.3594353 2.0358317 ... 3.8942363 3.1720738 3.9475594]\n",
      "rmse: LFactorNet: 0.882\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}